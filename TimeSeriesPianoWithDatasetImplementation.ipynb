{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "wLez1Slaaydy"
      },
      "outputs": [],
      "source": [
        "from music21 import converter, instrument, note, chord, stream\n",
        "import numpy\n",
        "from matplotlib import pyplot as plt\n",
        "import keras\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from keras import Sequential, Model\n",
        "from keras.layers import LSTM, Dropout, Dense, Activation, Input, concatenate\n",
        "import pandas as pd\n",
        "from tensorflow.keras.layers import Input, Dense, Dropout\n",
        "import os\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import MultiHeadAttention, LayerNormalization, Embedding\n",
        "import tensorflow as tf\n",
        "from tqdm import tqdm\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip dataset.zip"
      ],
      "metadata": {
        "id": "jMOiwvUEduhe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_notes(midi):\n",
        "  notes = []\n",
        "  for element in midi.flatten().notesAndRests:\n",
        "    if isinstance(element , note.Note):\n",
        "      notes.append((float(element.offset), float(element.volume.velocity),float(element.seconds), str(element.pitch)))\n",
        "    elif isinstance(element, chord.Chord):\n",
        "      notes.append((float(element.offset), float(element.volume.velocity), float(element.seconds), '+'.join(str(n) for n in element.normalOrder)))\n",
        "    elif isinstance(element, note.Rest):\n",
        "        # Bizarre car main gauche et droite flatten (réunie)\n",
        "        # Voir autre implémentation\n",
        "        notes.append((float(element.offset), 0,float(element.seconds), \"REST\"))\n",
        "  return notes\n",
        "\n"
      ],
      "metadata": {
        "id": "ltEonII2gWg0"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_note, output_note = [], []\n",
        "input_offset, output_offset = [], []\n",
        "input_volume, output_volume = [], []\n",
        "input_duration, output_duration = [], []\n",
        "\n",
        "\n",
        "\n",
        "sequence_length = 50\n",
        "note_all_songs = []\n",
        "for folder in tqdm(os.walk(\"dataset\")):\n",
        "    if len(folder) != 3:\n",
        "      continue\n",
        "    else:\n",
        "      for file in folder[2][:5]:\n",
        "        file_path = str(folder[0])+\"/\"+file\n",
        "\n",
        "        # convertit la piste midi\n",
        "        midi = converter.parse(file_path)\n",
        "\n",
        "        # récupère les notes, volume, dureées...\n",
        "        notes = get_notes(midi)\n",
        "\n",
        "        # ajoute à une liste globale\n",
        "        note_all_songs.append(notes)"
      ],
      "metadata": {
        "id": "nUvY0NWPd79V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# fais un dataframe à partir de toutes les notes (sans distinctions)\n",
        "df = pd.DataFrame([], columns=['debut_note','volume','durée(s)', 'pitch/chord'])\n",
        "df = df.reset_index(drop=True)\n",
        "for elem in note_all_songs:\n",
        "    df2 = pd.DataFrame(elem, columns=['debut_note','volume','durée(s)', 'pitch/chord'])\n",
        "    df2 = df2.reset_index(drop=True)\n",
        "    df =pd.concat([df,df2])\n",
        "    df = df.reset_index(drop=True)"
      ],
      "metadata": {
        "id": "_bRdnkH6OdJA"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#train les encoders pour les notes, volumes et durées en catégorielles (one hot)\n",
        "# sur intégralité des données (obligé)\n",
        "oh_notes =  OneHotEncoder().fit(df[['pitch/chord']])\n",
        "\n",
        "\n",
        "# seuil/catégories modifiable\n",
        "df[\"volume_class\"] = pd.cut(df[\"volume\"], bins=[0,10,30,50,70,90,127], labels=[\"very low\", \"low\", \"low medium\", \"medium\", \"high\", \"very high\"])\n",
        "oh_volume =  OneHotEncoder().fit(df[['volume_class']])\n",
        "\n",
        "df[\"duration_class\"] = pd.cut(df[\"durée(s)\"], bins=[0, 0.1, 0.25, 0.5, 0.75, 1, 1.5,df[\"durée(s)\"].max()], labels=[\"very short\", \"short\", \"medium\", \"medium-long\", \"long\", \"very long\", \"super mega long\"])\n",
        "oh_duration =  OneHotEncoder().fit(df[['duration_class']])\n"
      ],
      "metadata": {
        "id": "sJ6s6EG-UTLz"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def prepare_sequence(data, sequence_length, network_input, network_output):\n",
        "  # create input sequences and the corresponding outputs\n",
        "  for i in range(0, len(data) - sequence_length, 1):\n",
        "      sequence_in = data[i:i + sequence_length]\n",
        "      sequence_out = data[i + sequence_length]\n",
        "      network_input.append(sequence_in)\n",
        "      network_output.append(sequence_out)\n",
        "  return (network_input, network_output)\n",
        "\n",
        "def reshape_array_input(array_tensor, sequence_length):\n",
        "  n_patterns = len(array_tensor)\n",
        "  array_reshaped = numpy.reshape(array_tensor, (n_patterns, sequence_length, -1))\n",
        "  return array_reshaped\n",
        "\n",
        "def reshape_array_output(array_tensor, sequence_length):\n",
        "  n_patterns = len(array_tensor)\n",
        "  array_reshaped = numpy.reshape(array_tensor, (len(array_tensor), -1))\n",
        "  return array_reshaped\n"
      ],
      "metadata": {
        "id": "2Z_CqsKBicHH"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sequence_length = 100"
      ],
      "metadata": {
        "id": "tqK33V-UjsOn"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_note, output_note = [], []\n",
        "input_volume, output_volume = [], []\n",
        "input_duration, output_duration = [], []\n",
        "\n",
        "# pour chaque music, on la transforme en dataframe, transforme les notes, durées et volumes\n",
        "for music in note_all_songs:\n",
        "  df_music = pd.DataFrame(music, columns=['debut_note','volume','durée(s)', 'pitch/chord'])\n",
        "\n",
        "  # encode le volume et la durée\n",
        "  df_music[\"duration_class\"] = pd.cut(df_music[\"durée(s)\"], bins=[0, 0.1, 0.25, 0.5, 0.75, 1, 1.5,10], labels=[\"very short\", \"short\", \"medium\", \"medium-long\", \"long\", \"very long\", \"super mega long\"])\n",
        "  df_music[\"volume_class\"] = pd.cut(df_music[\"volume\"], bins=[0,10,30,50,70,90,127], labels=[\"very low\", \"low\", \"low medium\", \"medium\", \"high\", \"very high\"])\n",
        "\n",
        "  # transform en one hot à partir des modèles entrainés\n",
        "  notes_encoded = oh_notes.transform(df_music[['pitch/chord']]).toarray()\n",
        "  volume_encoded = oh_volume.transform(df_music[['volume_class']]).toarray()\n",
        "  duration_encoded = oh_duration.transform(df_music[['duration_class']]).toarray()\n",
        "\n",
        "  # prépare les input (longeur = sequence_length) pour chaque morceau\n",
        "  # garde certaine cohérence au morceau même\n",
        "  input_note, output_note = prepare_sequence(notes_encoded, sequence_length, input_note, output_note)\n",
        "  input_volume, output_volume = prepare_sequence(volume_encoded, sequence_length, input_volume, output_volume)\n",
        "  input_duration, output_duration = prepare_sequence(duration_encoded, sequence_length, input_duration, output_duration)"
      ],
      "metadata": {
        "id": "1lpnB-spixTZ"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# on reshape tout\n",
        "input_note_reshaped= reshape_array_input(input_note, sequence_length)\n",
        "output_note_reshaped = reshape_array_output(output_note, sequence_length)\n",
        "\n",
        "input_volume_reshaped= reshape_array_input(input_volume, sequence_length)\n",
        "output_volume_reshaped = reshape_array_output(output_volume, sequence_length)\n",
        "\n",
        "input_duration_reshaped= reshape_array_input(input_duration, sequence_length)\n",
        "output_duration_reshaped = reshape_array_output(output_duration, sequence_length)\n"
      ],
      "metadata": {
        "id": "AzX_ofZZj1vY"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#création du modèle (à alléger si overfitting)\n",
        "inputNotes_layer = Input(shape=(input_note_reshaped.shape[1], input_note_reshaped.shape[2]))\n",
        "inputNotes = LSTM(\n",
        "        128,\n",
        "        input_shape=(input_note_reshaped.shape[1], input_note_reshaped.shape[2]),\n",
        "        return_sequences=True\n",
        "    )(inputNotes_layer)\n",
        "\n",
        "inputVolume_layer = Input(shape=(input_volume_reshaped.shape[1], input_volume_reshaped.shape[2]))\n",
        "inputVolume = LSTM(\n",
        "        128,\n",
        "        input_shape=(input_volume_reshaped.shape[1], input_volume_reshaped.shape[2]),\n",
        "        return_sequences=True\n",
        "    )(inputVolume_layer)\n",
        "\n",
        "inputDuration_layer = Input(shape=(input_duration_reshaped.shape[1], input_duration_reshaped.shape[2]))\n",
        "inputDuration = LSTM(\n",
        "        128,\n",
        "        input_shape=(input_duration_reshaped.shape[1], input_duration_reshaped.shape[2]),\n",
        "        return_sequences=True\n",
        "    )(inputDuration_layer)\n",
        "\n",
        "inputs = concatenate([inputNotes, inputVolume, inputDuration])\n",
        "x = LSTM(256, return_sequences=True)(inputs)\n",
        "x = Dropout(0.3)(x)\n",
        "x = LSTM(256)(inputs)\n",
        "x = Dropout(0.3)(x)\n",
        "x = Dense(256, activation='relu')(x)\n",
        "\n",
        "outputNotes = Dense(256, activation='relu')(x)\n",
        "outputNotes = Dense(output_note_reshaped.shape[1], activation='softmax', name=\"Note\")(outputNotes)\n",
        "\n",
        "outputVolume = Dense(256, activation='relu')(x)\n",
        "outputVolume = Dense(output_volume_reshaped.shape[1], activation='softmax', name=\"Volume\")(outputVolume)\n",
        "\n",
        "outputDuration = Dense(256, activation='relu')(x)\n",
        "outputDuration = Dense(output_duration_reshaped.shape[1], activation='softmax', name=\"Duration\")(outputDuration)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "model = Model(inputs=[inputNotes_layer, inputVolume_layer, inputDuration_layer], outputs=[outputNotes, outputVolume, outputDuration])\n",
        "\n",
        "#Adam seems to be faster than RMSProp and learns better too\n",
        "model.compile(loss=['categorical_crossentropy', \"mean_squared_error\", \"categorical_crossentropy\", \"categorical_crossentropy\"], optimizer='adam')"
      ],
      "metadata": {
        "id": "NyzHblQ7kfw0"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "id": "q_4pFN5EihPj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7360cdaa-673d-4358-bd4c-919bd7fa6037"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)        [(None, 100, 295)]           0         []                            \n",
            "                                                                                                  \n",
            " input_2 (InputLayer)        [(None, 100, 6)]             0         []                            \n",
            "                                                                                                  \n",
            " input_3 (InputLayer)        [(None, 100, 7)]             0         []                            \n",
            "                                                                                                  \n",
            " lstm (LSTM)                 (None, 100, 128)             217088    ['input_1[0][0]']             \n",
            "                                                                                                  \n",
            " lstm_1 (LSTM)               (None, 100, 128)             69120     ['input_2[0][0]']             \n",
            "                                                                                                  \n",
            " lstm_2 (LSTM)               (None, 100, 128)             69632     ['input_3[0][0]']             \n",
            "                                                                                                  \n",
            " concatenate (Concatenate)   (None, 100, 384)             0         ['lstm[0][0]',                \n",
            "                                                                     'lstm_1[0][0]',              \n",
            "                                                                     'lstm_2[0][0]']              \n",
            "                                                                                                  \n",
            " lstm_4 (LSTM)               (None, 256)                  656384    ['concatenate[0][0]']         \n",
            "                                                                                                  \n",
            " dropout_1 (Dropout)         (None, 256)                  0         ['lstm_4[0][0]']              \n",
            "                                                                                                  \n",
            " dense (Dense)               (None, 256)                  65792     ['dropout_1[0][0]']           \n",
            "                                                                                                  \n",
            " dense_1 (Dense)             (None, 256)                  65792     ['dense[0][0]']               \n",
            "                                                                                                  \n",
            " dense_2 (Dense)             (None, 256)                  65792     ['dense[0][0]']               \n",
            "                                                                                                  \n",
            " dense_3 (Dense)             (None, 256)                  65792     ['dense[0][0]']               \n",
            "                                                                                                  \n",
            " Note (Dense)                (None, 295)                  75815     ['dense_1[0][0]']             \n",
            "                                                                                                  \n",
            " Volume (Dense)              (None, 6)                    1542      ['dense_2[0][0]']             \n",
            "                                                                                                  \n",
            " Duration (Dense)            (None, 7)                    1799      ['dense_3[0][0]']             \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 1354548 (5.17 MB)\n",
            "Trainable params: 1354548 (5.17 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "cp_callback = keras.callbacks.ModelCheckpoint(\n",
        "    'model_weights_epoch.h5',  # Nom du fichier de sauvegarde avec un espace réservé pour le numéro de l'époque\n",
        "    save_best_only=True,  # Sauvegarder à chaque époque, pas seulement les meilleurs modèles\n",
        "    save_weights_only=True,  # Sauvegarder uniquement les poids, pas l'ensemble du modèle\n",
        "    verbose=1  # Afficher un message lors de la sauvegarde\n",
        "    )"
      ],
      "metadata": {
        "id": "YB2DV7zy3om5"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit([input_note_reshaped, input_volume_reshaped, input_duration_reshaped], [output_note_reshaped, output_volume_reshaped, output_duration_reshaped], epochs=400, callbacks=[cp_callback], validation_split=0.2, batch_size=128)"
      ],
      "metadata": {
        "id": "d7w5ODUnf8B8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#prend une séquence de notes, volume, durées\n",
        "pattern_note = input_note[-1]\n",
        "pattern_volume = input_volume[-1]\n",
        "pattern_duration = input_duration[-1]"
      ],
      "metadata": {
        "id": "S7L6Fyy1pFBa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prediction time\n",
        "prediction_output = []\n",
        "\n",
        "for i in tqdm(range(200)):\n",
        "\n",
        "    #on reshape les input à prédire\n",
        "    note_prediction_input = numpy.reshape(pattern_note, (1, len(pattern_note), -1))\n",
        "    volume_prediction_input = numpy.reshape(pattern_volume, (1, len(pattern_volume), -1))\n",
        "    duration_prediction_input = numpy.reshape(pattern_duration, (1, len(pattern_duration), -1))\n",
        "\n",
        "    #prédit ici\n",
        "    prediction = model.predict([note_prediction_input, volume_prediction_input, duration_prediction_input], verbose=0)\n",
        "\n",
        "    # prédis la note en récupérant l'index max du softmax et en faisant la transofr inverse\n",
        "    # à partir du one hot train sur les notes\n",
        "    notes_pred = np.zeros(len(pattern_note[0]))\n",
        "    notes_pred[np.argmax(prediction[0])] = 1\n",
        "    result_note = oh_notes.inverse_transform(notes_pred.reshape(1, -1))\n",
        "    pattern_note = numpy.concatenate([pattern_note, prediction[0]])\n",
        "    pattern_note = pattern_note[1:]\n",
        "\n",
        "    # la même avec le volume\n",
        "    volume_pred = np.zeros(len(pattern_volume[1]))\n",
        "    volume_pred[np.argmax(prediction[1])] = 1\n",
        "    result_volume = oh_volume.inverse_transform(volume_pred.reshape(1, -1))\n",
        "    pattern_volume = numpy.concatenate([pattern_volume, prediction[1]])\n",
        "    pattern_volume = pattern_volume[1:]\n",
        "\n",
        "    # la même avec la durée\n",
        "    duration_pred = np.zeros(len(pattern_duration[0]))\n",
        "    duration_pred[np.argmax(prediction[2])] = 1\n",
        "    result_duration = oh_duration.inverse_transform(duration_pred.reshape(1, -1))\n",
        "    pattern_duration = numpy.concatenate([pattern_duration, prediction[2]])\n",
        "    pattern_duration = pattern_duration[1:]\n",
        "\n",
        "    # comme on prédit un mot associé au volume, on associe au mot une valeur/intensité\n",
        "    #(manque des catégories)\n",
        "    volume_encoded = result_volume[0][0]\n",
        "    volume_decoded = 0\n",
        "    if volume_encoded == \"low\":\n",
        "      volume_decoded = 30\n",
        "    if volume_encoded == \"medium\":\n",
        "      volume_decoded = 60\n",
        "    if volume_encoded == \"high\":\n",
        "      volume_decoded = 90\n",
        "\n",
        "    # la même avec la durée\n",
        "    #(manque des catégories)\n",
        "    duration_encoded = result_duration[0][0]\n",
        "    duration_encoded = 0\n",
        "    if volume_encoded == \"short\":\n",
        "      duration_encoded = 0.25\n",
        "    if volume_encoded == \"medium\":\n",
        "      duration_encoded = 0.5\n",
        "    if volume_encoded == \"high\":\n",
        "      duration_encoded = 0.75\n",
        "\n",
        "    #on ajoute la note, le volyme et la durée\n",
        "    prediction_output.append([result_note[0][0], volume_decoded, duration_encoded])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1C2Vt-MH0nm_",
        "outputId": "28359c66-670b-4c53-baa0-30fa3c0fd67f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 200/200 [00:15<00:00, 12.57it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from music21.duration import Duration\n"
      ],
      "metadata": {
        "id": "91w43lwl5urg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "offset = 0\n",
        "output_notes = []\n",
        "# on passes des prédicitons à un format écoutable à l'oreille\n",
        "\n",
        "# pour chaque note prédite\n",
        "for note_p in prediction_output:\n",
        "    pattern = note_p[0]\n",
        "    # si note = chord\n",
        "    if ('+' in pattern) or pattern.isdigit():\n",
        "        notes_in_chord = pattern.split('+')\n",
        "        notes = []\n",
        "        for current_note in notes_in_chord:\n",
        "            new_note = note.Note(int(current_note))\n",
        "            new_note.storedInstrument = instrument.Piano()\n",
        "            notes.append(new_note)\n",
        "        new_chord = chord.Chord(notes)\n",
        "        new_chord.offset = offset\n",
        "        # met le volume associé\n",
        "        new_chord.volume.velocity = note_p[1]\n",
        "        # met la durée associée\n",
        "        new_chord.duration = Duration(note_p[2])\n",
        "        output_notes.append(new_chord)\n",
        "    # si note est un rest\n",
        "    elif('REST'in pattern):\n",
        "      note_rest = note.Rest()\n",
        "      note_rest.offset = offset\n",
        "      # durée associée (pas de volume car silencieux)\n",
        "      note_rest.duration = Duration(note_p[2])\n",
        "      output_notes.append(note_rest)\n",
        "    else:\n",
        "        new_note = note.Note(pattern)\n",
        "        new_note.offset = offset\n",
        "        new_note.volume.velocity = note_p[1]\n",
        "        new_note.duration = Duration(note_p[2])\n",
        "        new_note.storedInstrument = instrument.Piano()\n",
        "        output_notes.append(new_note)\n",
        "\n",
        "    # increase offset each iteration so that notes do not stack\n",
        "    offset += 0.5"
      ],
      "metadata": {
        "id": "BxktumUV0H22"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#into midi\n",
        "midi_stream = stream.Stream(output_notes)\n",
        "midi_stream.write('midi', fp='test_outputminecraft.mid')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "I5W_QMyyn7BA",
        "outputId": "57dbdcf5-b78b-44f2-ffe6-66ef0745cd39"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'test_outputminecraft.mid'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    }
  ]
}