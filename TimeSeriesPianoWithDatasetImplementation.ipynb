{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  },
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "#!pip install --upgrade pip\n",
    "\n",
    "#!pip install music21\n",
    "#!pip install numpy\n",
    "#!pip install matplotlib\n",
    "#!pip install keras\n",
    "#!pip install scikit-learn\n",
    "#!pip install pandas\n",
    "#!pip install tensorflow\n",
    "#!pip install tqdm\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-22T20:57:14.349951500Z",
     "start_time": "2023-10-22T20:57:14.286952800Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "wLez1Slaaydy",
    "ExecuteTime": {
     "end_time": "2023-10-22T20:57:15.941954300Z",
     "start_time": "2023-10-22T20:57:14.294951400Z"
    }
   },
   "outputs": [],
   "source": [
    "from music21 import converter, instrument, note, chord, stream\n",
    "import numpy\n",
    "from matplotlib import pyplot as plt\n",
    "import keras\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from keras import Sequential, Model\n",
    "from keras.layers import LSTM, Dropout, Dense, Activation, Input, concatenate\n",
    "import pandas as pd\n",
    "from tensorflow.keras.layers import Input, Dense, Dropout\n",
    "import os\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import MultiHeadAttention, LayerNormalization, Embedding\n",
    "import tensorflow as tf\n",
    "from tqdm import tqdm\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "!unzip dataset.zip"
   ],
   "metadata": {
    "id": "jMOiwvUEduhe",
    "ExecuteTime": {
     "end_time": "2023-10-22T20:57:15.997952Z",
     "start_time": "2023-10-22T20:57:15.940953800Z"
    }
   },
   "execution_count": 15,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'unzip' n'est pas reconnu en tant que commande interne\n",
      "ou externe, un programme ex‚cutable ou un fichier de commandes.\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "def get_notes(midi):\n",
    "  notes = []\n",
    "  for element in midi.flatten().notesAndRests:\n",
    "    if isinstance(element , note.Note):\n",
    "      notes.append((float(element.offset), float(element.volume.velocity),float(element.seconds), str(element.pitch)))\n",
    "    elif isinstance(element, chord.Chord):\n",
    "      notes.append((float(element.offset), float(element.volume.velocity), float(element.seconds), '+'.join(str(n) for n in element.normalOrder)))\n",
    "    elif isinstance(element, note.Rest):\n",
    "        # Bizarre car main gauche et droite flatten (réunie)\n",
    "        # Voir autre implémentation\n",
    "        notes.append((float(element.offset), 0,float(element.seconds), \"REST\"))\n",
    "  return notes\n",
    "\n"
   ],
   "metadata": {
    "id": "ltEonII2gWg0",
    "ExecuteTime": {
     "end_time": "2023-10-22T20:57:16.056950900Z",
     "start_time": "2023-10-22T20:57:16.006952Z"
    }
   },
   "execution_count": 16,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "input_note, output_note = [], []\n",
    "input_offset, output_offset = [], []\n",
    "input_volume, output_volume = [], []\n",
    "input_duration, output_duration = [], []\n",
    "\n",
    "\n",
    "\n",
    "sequence_length = 50\n",
    "note_all_songs = []\n",
    "for folder in tqdm(os.walk(\"dataset\")):\n",
    "    if len(folder) != 3:\n",
    "      continue\n",
    "    else:\n",
    "      for file in folder[2][:5]:\n",
    "        file_path = str(folder[0])+\"/\"+file\n",
    "\n",
    "        # convertit la piste midi\n",
    "        midi = converter.parse(file_path)\n",
    "\n",
    "        # récupère les notes, volume, dureées...\n",
    "        notes = get_notes(midi)\n",
    "\n",
    "        # ajoute à une liste globale\n",
    "        note_all_songs.append(notes)"
   ],
   "metadata": {
    "id": "nUvY0NWPd79V",
    "ExecuteTime": {
     "end_time": "2023-10-22T20:58:17.059127400Z",
     "start_time": "2023-10-22T20:57:16.034951700Z"
    }
   },
   "execution_count": 17,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]E:\\Users\\Asus\\Documents\\GitHub\\HarmonicAI\\venv\\lib\\site-packages\\music21\\midi\\translate.py:874: TranslateWarning: Unable to determine instrument from <music21.midi.MidiEvent SEQUENCE_TRACK_NAME, track=4, channel=None, data=b'Copyright \\xa9 2002 by Bernd Krueger'>; getting generic Instrument\n",
      "  warnings.warn(\n",
      "2it [00:06,  3.01s/it]E:\\Users\\Asus\\Documents\\GitHub\\HarmonicAI\\venv\\lib\\site-packages\\music21\\midi\\translate.py:874: TranslateWarning: Unable to determine instrument from <music21.midi.MidiEvent SEQUENCE_TRACK_NAME, track=5, channel=None, data=b'Copyright \\xa9 2009 by Bernd Krueger'>; getting generic Instrument\n",
      "  warnings.warn(\n",
      "E:\\Users\\Asus\\Documents\\GitHub\\HarmonicAI\\venv\\lib\\site-packages\\music21\\midi\\translate.py:874: TranslateWarning: Unable to determine instrument from <music21.midi.MidiEvent SEQUENCE_TRACK_NAME, track=5, channel=None, data=b'Copyright \\xa9 2010 by Bernd Krueger'>; getting generic Instrument\n",
      "  warnings.warn(\n",
      "E:\\Users\\Asus\\Documents\\GitHub\\HarmonicAI\\venv\\lib\\site-packages\\music21\\midi\\translate.py:874: TranslateWarning: Unable to determine instrument from <music21.midi.MidiEvent SEQUENCE_TRACK_NAME, track=5, channel=None, data=b'Copyright \\xa9 2007 by Bernd Krueger'>; getting generic Instrument\n",
      "  warnings.warn(\n",
      "3it [01:01, 20.33s/it]\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# fais un dataframe à partir de toutes les notes (sans distinctions)\n",
    "df = pd.DataFrame([], columns=['debut_note','volume','durée(s)', 'pitch/chord'])\n",
    "df = df.reset_index(drop=True)\n",
    "for elem in note_all_songs:\n",
    "    df2 = pd.DataFrame(elem, columns=['debut_note','volume','durée(s)', 'pitch/chord'])\n",
    "    df2 = df2.reset_index(drop=True)\n",
    "    df =pd.concat([df,df2])\n",
    "    df = df.reset_index(drop=True)"
   ],
   "metadata": {
    "id": "_bRdnkH6OdJA",
    "ExecuteTime": {
     "end_time": "2023-10-22T20:58:17.106380500Z",
     "start_time": "2023-10-22T20:58:17.059127400Z"
    }
   },
   "execution_count": 18,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Asus\\AppData\\Local\\Temp\\ipykernel_2036\\3451272356.py:7: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df =pd.concat([df,df2])\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "#train les encoders pour les notes, volumes et durées en catégorielles (one hot)\n",
    "# sur intégralité des données (obligé)\n",
    "oh_notes =  OneHotEncoder().fit(df[['pitch/chord']])\n",
    "\n",
    "\n",
    "# seuil/catégories modifiable\n",
    "df[\"volume_class\"] = pd.cut(df[\"volume\"], bins=[0,10,30,50,70,90,127], labels=[\"very low\", \"low\", \"low medium\", \"medium\", \"high\", \"very high\"])\n",
    "oh_volume =  OneHotEncoder().fit(df[['volume_class']])\n",
    "\n",
    "df[\"duration_class\"] = pd.cut(df[\"durée(s)\"], bins=[0, 0.1, 0.25, 0.5, 0.75, 1, 1.5,df[\"durée(s)\"].max()], labels=[\"very short\", \"short\", \"medium\", \"medium-long\", \"long\", \"very long\", \"super mega long\"])\n",
    "oh_duration =  OneHotEncoder().fit(df[['duration_class']])\n"
   ],
   "metadata": {
    "id": "sJ6s6EG-UTLz",
    "ExecuteTime": {
     "end_time": "2023-10-22T20:58:17.155380200Z",
     "start_time": "2023-10-22T20:58:17.108381Z"
    }
   },
   "execution_count": 19,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def prepare_sequence(data, sequence_length, network_input, network_output):\n",
    "  # create input sequences and the corresponding outputs\n",
    "  for i in range(0, len(data) - sequence_length, 1):\n",
    "      sequence_in = data[i:i + sequence_length]\n",
    "      sequence_out = data[i + sequence_length]\n",
    "      network_input.append(sequence_in)\n",
    "      network_output.append(sequence_out)\n",
    "  return (network_input, network_output)\n",
    "\n",
    "def reshape_array_input(array_tensor, sequence_length):\n",
    "  n_patterns = len(array_tensor)\n",
    "  array_reshaped = numpy.reshape(array_tensor, (n_patterns, sequence_length, -1))\n",
    "  return array_reshaped\n",
    "\n",
    "def reshape_array_output(array_tensor, sequence_length):\n",
    "  n_patterns = len(array_tensor)\n",
    "  array_reshaped = numpy.reshape(array_tensor, (len(array_tensor), -1))\n",
    "  return array_reshaped\n"
   ],
   "metadata": {
    "id": "2Z_CqsKBicHH",
    "ExecuteTime": {
     "end_time": "2023-10-22T20:58:17.171380600Z",
     "start_time": "2023-10-22T20:58:17.155380200Z"
    }
   },
   "execution_count": 20,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "sequence_length = 100"
   ],
   "metadata": {
    "id": "tqK33V-UjsOn",
    "ExecuteTime": {
     "end_time": "2023-10-22T20:58:17.187381300Z",
     "start_time": "2023-10-22T20:58:17.172380600Z"
    }
   },
   "execution_count": 21,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "input_note, output_note = [], []\n",
    "input_volume, output_volume = [], []\n",
    "input_duration, output_duration = [], []\n",
    "\n",
    "# pour chaque music, on la transforme en dataframe, transforme les notes, durées et volumes\n",
    "for music in note_all_songs:\n",
    "  df_music = pd.DataFrame(music, columns=['debut_note','volume','durée(s)', 'pitch/chord'])\n",
    "\n",
    "  # encode le volume et la durée\n",
    "  df_music[\"duration_class\"] = pd.cut(df_music[\"durée(s)\"], bins=[0, 0.1, 0.25, 0.5, 0.75, 1, 1.5,10], labels=[\"very short\", \"short\", \"medium\", \"medium-long\", \"long\", \"very long\", \"super mega long\"])\n",
    "  df_music[\"volume_class\"] = pd.cut(df_music[\"volume\"], bins=[0,10,30,50,70,90,127], labels=[\"very low\", \"low\", \"low medium\", \"medium\", \"high\", \"very high\"])\n",
    "\n",
    "  # transform en one hot à partir des modèles entrainés\n",
    "  notes_encoded = oh_notes.transform(df_music[['pitch/chord']]).toarray()\n",
    "  volume_encoded = oh_volume.transform(df_music[['volume_class']]).toarray()\n",
    "  duration_encoded = oh_duration.transform(df_music[['duration_class']]).toarray()\n",
    "\n",
    "  # prépare les input (longeur = sequence_length) pour chaque morceau\n",
    "  # garde certaine cohérence au morceau même\n",
    "  input_note, output_note = prepare_sequence(notes_encoded, sequence_length, input_note, output_note)\n",
    "  input_volume, output_volume = prepare_sequence(volume_encoded, sequence_length, input_volume, output_volume)\n",
    "  input_duration, output_duration = prepare_sequence(duration_encoded, sequence_length, input_duration, output_duration)"
   ],
   "metadata": {
    "id": "1lpnB-spixTZ",
    "ExecuteTime": {
     "end_time": "2023-10-22T20:58:17.299379900Z",
     "start_time": "2023-10-22T20:58:17.189380600Z"
    }
   },
   "execution_count": 22,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# on reshape tout\n",
    "input_note_reshaped= reshape_array_input(input_note, sequence_length)\n",
    "output_note_reshaped = reshape_array_output(output_note, sequence_length)\n",
    "\n",
    "input_volume_reshaped= reshape_array_input(input_volume, sequence_length)\n",
    "output_volume_reshaped = reshape_array_output(output_volume, sequence_length)\n",
    "\n",
    "input_duration_reshaped= reshape_array_input(input_duration, sequence_length)\n",
    "output_duration_reshaped = reshape_array_output(output_duration, sequence_length)\n"
   ],
   "metadata": {
    "id": "AzX_ofZZj1vY",
    "ExecuteTime": {
     "end_time": "2023-10-22T20:58:35.533186100Z",
     "start_time": "2023-10-22T20:58:17.301380300Z"
    }
   },
   "execution_count": 23,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "#création du modèle (à alléger si overfitting)\n",
    "inputNotes_layer = Input(shape=(input_note_reshaped.shape[1], input_note_reshaped.shape[2]))\n",
    "inputNotes = LSTM(\n",
    "        128,\n",
    "        input_shape=(input_note_reshaped.shape[1], input_note_reshaped.shape[2]),\n",
    "        return_sequences=True\n",
    "    )(inputNotes_layer)\n",
    "\n",
    "inputVolume_layer = Input(shape=(input_volume_reshaped.shape[1], input_volume_reshaped.shape[2]))\n",
    "inputVolume = LSTM(\n",
    "        128,\n",
    "        input_shape=(input_volume_reshaped.shape[1], input_volume_reshaped.shape[2]),\n",
    "        return_sequences=True\n",
    "    )(inputVolume_layer)\n",
    "\n",
    "inputDuration_layer = Input(shape=(input_duration_reshaped.shape[1], input_duration_reshaped.shape[2]))\n",
    "inputDuration = LSTM(\n",
    "        128,\n",
    "        input_shape=(input_duration_reshaped.shape[1], input_duration_reshaped.shape[2]),\n",
    "        return_sequences=True\n",
    "    )(inputDuration_layer)\n",
    "\n",
    "inputs = concatenate([inputNotes, inputVolume, inputDuration])\n",
    "x = LSTM(256, return_sequences=True)(inputs)\n",
    "x = Dropout(0.3)(x)\n",
    "x = LSTM(256)(inputs)\n",
    "x = Dropout(0.3)(x)\n",
    "x = Dense(256, activation='relu')(x)\n",
    "\n",
    "outputNotes = Dense(256, activation='relu')(x)\n",
    "outputNotes = Dense(output_note_reshaped.shape[1], activation='softmax', name=\"Note\")(outputNotes)\n",
    "\n",
    "outputVolume = Dense(256, activation='relu')(x)\n",
    "outputVolume = Dense(output_volume_reshaped.shape[1], activation='softmax', name=\"Volume\")(outputVolume)\n",
    "\n",
    "outputDuration = Dense(256, activation='relu')(x)\n",
    "outputDuration = Dense(output_duration_reshaped.shape[1], activation='softmax', name=\"Duration\")(outputDuration)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "model = Model(inputs=[inputNotes_layer, inputVolume_layer, inputDuration_layer], outputs=[outputNotes, outputVolume, outputDuration])\n",
    "\n",
    "#Adam seems to be faster than RMSProp and learns better too\n",
    "model.compile(loss=['categorical_crossentropy', \"mean_squared_error\", \"categorical_crossentropy\", \"categorical_crossentropy\"], optimizer='adam')"
   ],
   "metadata": {
    "id": "NyzHblQ7kfw0",
    "ExecuteTime": {
     "end_time": "2023-10-22T20:59:17.017573800Z",
     "start_time": "2023-10-22T20:58:37.894587300Z"
    }
   },
   "execution_count": 24,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "model.summary()"
   ],
   "metadata": {
    "id": "q_4pFN5EihPj",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "7360cdaa-673d-4358-bd4c-919bd7fa6037",
    "ExecuteTime": {
     "end_time": "2023-10-22T20:59:17.088581700Z",
     "start_time": "2023-10-22T20:59:17.026574200Z"
    }
   },
   "execution_count": 25,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)        [(None, 100, 303)]           0         []                            \n",
      "                                                                                                  \n",
      " input_2 (InputLayer)        [(None, 100, 6)]             0         []                            \n",
      "                                                                                                  \n",
      " input_3 (InputLayer)        [(None, 100, 7)]             0         []                            \n",
      "                                                                                                  \n",
      " lstm (LSTM)                 (None, 100, 128)             221184    ['input_1[0][0]']             \n",
      "                                                                                                  \n",
      " lstm_1 (LSTM)               (None, 100, 128)             69120     ['input_2[0][0]']             \n",
      "                                                                                                  \n",
      " lstm_2 (LSTM)               (None, 100, 128)             69632     ['input_3[0][0]']             \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)   (None, 100, 384)             0         ['lstm[0][0]',                \n",
      "                                                                     'lstm_1[0][0]',              \n",
      "                                                                     'lstm_2[0][0]']              \n",
      "                                                                                                  \n",
      " lstm_4 (LSTM)               (None, 256)                  656384    ['concatenate[0][0]']         \n",
      "                                                                                                  \n",
      " dropout_1 (Dropout)         (None, 256)                  0         ['lstm_4[0][0]']              \n",
      "                                                                                                  \n",
      " dense (Dense)               (None, 256)                  65792     ['dropout_1[0][0]']           \n",
      "                                                                                                  \n",
      " dense_1 (Dense)             (None, 256)                  65792     ['dense[0][0]']               \n",
      "                                                                                                  \n",
      " dense_2 (Dense)             (None, 256)                  65792     ['dense[0][0]']               \n",
      "                                                                                                  \n",
      " dense_3 (Dense)             (None, 256)                  65792     ['dense[0][0]']               \n",
      "                                                                                                  \n",
      " Note (Dense)                (None, 303)                  77871     ['dense_1[0][0]']             \n",
      "                                                                                                  \n",
      " Volume (Dense)              (None, 6)                    1542      ['dense_2[0][0]']             \n",
      "                                                                                                  \n",
      " Duration (Dense)            (None, 7)                    1799      ['dense_3[0][0]']             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 1360700 (5.19 MB)\n",
      "Trainable params: 1360700 (5.19 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "import os\n",
    "\n",
    "cp_callback = keras.callbacks.ModelCheckpoint(\n",
    "    'model_weights_epoch.h5',  # Nom du fichier de sauvegarde avec un espace réservé pour le numéro de l'époque\n",
    "    save_best_only=True,  # Sauvegarder à chaque époque, pas seulement les meilleurs modèles\n",
    "    save_weights_only=True,  # Sauvegarder uniquement les poids, pas l'ensemble du modèle\n",
    "    verbose=1  # Afficher un message lors de la sauvegarde\n",
    "    )"
   ],
   "metadata": {
    "id": "YB2DV7zy3om5",
    "ExecuteTime": {
     "end_time": "2023-10-22T20:59:17.175093200Z",
     "start_time": "2023-10-22T20:59:17.155582500Z"
    }
   },
   "execution_count": 26,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "model.fit([input_note_reshaped, input_volume_reshaped, input_duration_reshaped], [output_note_reshaped, output_volume_reshaped, output_duration_reshaped], epochs=400, callbacks=[cp_callback], validation_split=0.2, batch_size=128)"
   ],
   "metadata": {
    "id": "d7w5ODUnf8B8",
    "ExecuteTime": {
     "end_time": "2023-10-22T23:31:52.717303900Z",
     "start_time": "2023-10-22T20:59:17.175093200Z"
    }
   },
   "execution_count": 27,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/400\n",
      "191/191 [==============================] - ETA: 0s - loss: 5.3063 - Note_loss: 4.2580 - Volume_loss: 0.1109 - Duration_loss: 0.9373\n",
      "Epoch 1: val_loss improved from inf to 5.16115, saving model to model_weights_epoch.h5\n",
      "191/191 [==============================] - 292s 1s/step - loss: 5.3063 - Note_loss: 4.2580 - Volume_loss: 0.1109 - Duration_loss: 0.9373 - val_loss: 5.1612 - val_Note_loss: 4.2647 - val_Volume_loss: 0.1209 - val_Duration_loss: 0.7756\n",
      "Epoch 2/400\n",
      "191/191 [==============================] - ETA: 0s - loss: 4.6043 - Note_loss: 3.6756 - Volume_loss: 0.1021 - Duration_loss: 0.8267\n",
      "Epoch 2: val_loss improved from 5.16115 to 5.01792, saving model to model_weights_epoch.h5\n",
      "191/191 [==============================] - 233s 1s/step - loss: 4.6043 - Note_loss: 3.6756 - Volume_loss: 0.1021 - Duration_loss: 0.8267 - val_loss: 5.0179 - val_Note_loss: 4.0906 - val_Volume_loss: 0.1162 - val_Duration_loss: 0.8111\n",
      "Epoch 3/400\n",
      "191/191 [==============================] - ETA: 0s - loss: 4.2738 - Note_loss: 3.3914 - Volume_loss: 0.0985 - Duration_loss: 0.7839\n",
      "Epoch 3: val_loss improved from 5.01792 to 4.86057, saving model to model_weights_epoch.h5\n",
      "191/191 [==============================] - 226s 1s/step - loss: 4.2738 - Note_loss: 3.3914 - Volume_loss: 0.0985 - Duration_loss: 0.7839 - val_loss: 4.8606 - val_Note_loss: 3.8820 - val_Volume_loss: 0.1269 - val_Duration_loss: 0.8516\n",
      "Epoch 4/400\n",
      "191/191 [==============================] - ETA: 0s - loss: 4.0089 - Note_loss: 3.1702 - Volume_loss: 0.0955 - Duration_loss: 0.7432\n",
      "Epoch 4: val_loss did not improve from 4.86057\n",
      "191/191 [==============================] - 220s 1s/step - loss: 4.0089 - Note_loss: 3.1702 - Volume_loss: 0.0955 - Duration_loss: 0.7432 - val_loss: 4.8806 - val_Note_loss: 3.9269 - val_Volume_loss: 0.1188 - val_Duration_loss: 0.8348\n",
      "Epoch 5/400\n",
      "191/191 [==============================] - ETA: 0s - loss: 3.7652 - Note_loss: 2.9679 - Volume_loss: 0.0912 - Duration_loss: 0.7062\n",
      "Epoch 5: val_loss did not improve from 4.86057\n",
      "191/191 [==============================] - 235s 1s/step - loss: 3.7652 - Note_loss: 2.9679 - Volume_loss: 0.0912 - Duration_loss: 0.7062 - val_loss: 4.9936 - val_Note_loss: 3.9988 - val_Volume_loss: 0.1205 - val_Duration_loss: 0.8743\n",
      "Epoch 6/400\n",
      "191/191 [==============================] - ETA: 0s - loss: 3.5433 - Note_loss: 2.7892 - Volume_loss: 0.0865 - Duration_loss: 0.6677\n",
      "Epoch 6: val_loss did not improve from 4.86057\n",
      "191/191 [==============================] - 251s 1s/step - loss: 3.5433 - Note_loss: 2.7892 - Volume_loss: 0.0865 - Duration_loss: 0.6677 - val_loss: 5.0801 - val_Note_loss: 4.0804 - val_Volume_loss: 0.1178 - val_Duration_loss: 0.8818\n",
      "Epoch 7/400\n",
      "191/191 [==============================] - ETA: 0s - loss: 3.3198 - Note_loss: 2.6197 - Volume_loss: 0.0824 - Duration_loss: 0.6177\n",
      "Epoch 7: val_loss did not improve from 4.86057\n",
      "191/191 [==============================] - 244s 1s/step - loss: 3.3198 - Note_loss: 2.6197 - Volume_loss: 0.0824 - Duration_loss: 0.6177 - val_loss: 5.1494 - val_Note_loss: 4.1181 - val_Volume_loss: 0.1186 - val_Duration_loss: 0.9128\n",
      "Epoch 8/400\n",
      "191/191 [==============================] - ETA: 0s - loss: 3.1170 - Note_loss: 2.4596 - Volume_loss: 0.0782 - Duration_loss: 0.5791\n",
      "Epoch 8: val_loss did not improve from 4.86057\n",
      "191/191 [==============================] - 228s 1s/step - loss: 3.1170 - Note_loss: 2.4596 - Volume_loss: 0.0782 - Duration_loss: 0.5791 - val_loss: 5.3528 - val_Note_loss: 4.3029 - val_Volume_loss: 0.1196 - val_Duration_loss: 0.9304\n",
      "Epoch 9/400\n",
      "191/191 [==============================] - ETA: 0s - loss: 2.9393 - Note_loss: 2.3308 - Volume_loss: 0.0749 - Duration_loss: 0.5336\n",
      "Epoch 9: val_loss did not improve from 4.86057\n",
      "191/191 [==============================] - 238s 1s/step - loss: 2.9393 - Note_loss: 2.3308 - Volume_loss: 0.0749 - Duration_loss: 0.5336 - val_loss: 5.4266 - val_Note_loss: 4.3405 - val_Volume_loss: 0.1164 - val_Duration_loss: 0.9697\n",
      "Epoch 10/400\n",
      "191/191 [==============================] - ETA: 0s - loss: 2.7601 - Note_loss: 2.1918 - Volume_loss: 0.0718 - Duration_loss: 0.4964\n",
      "Epoch 10: val_loss did not improve from 4.86057\n",
      "191/191 [==============================] - 222s 1s/step - loss: 2.7601 - Note_loss: 2.1918 - Volume_loss: 0.0718 - Duration_loss: 0.4964 - val_loss: 5.5740 - val_Note_loss: 4.4477 - val_Volume_loss: 0.1199 - val_Duration_loss: 1.0064\n",
      "Epoch 11/400\n",
      "191/191 [==============================] - ETA: 0s - loss: 2.5953 - Note_loss: 2.0675 - Volume_loss: 0.0684 - Duration_loss: 0.4595\n",
      "Epoch 11: val_loss did not improve from 4.86057\n",
      "191/191 [==============================] - 206s 1s/step - loss: 2.5953 - Note_loss: 2.0675 - Volume_loss: 0.0684 - Duration_loss: 0.4595 - val_loss: 5.8537 - val_Note_loss: 4.6664 - val_Volume_loss: 0.1238 - val_Duration_loss: 1.0635\n",
      "Epoch 12/400\n",
      "191/191 [==============================] - ETA: 0s - loss: 2.4456 - Note_loss: 1.9537 - Volume_loss: 0.0650 - Duration_loss: 0.4269\n",
      "Epoch 12: val_loss did not improve from 4.86057\n",
      "191/191 [==============================] - 231s 1s/step - loss: 2.4456 - Note_loss: 1.9537 - Volume_loss: 0.0650 - Duration_loss: 0.4269 - val_loss: 5.9978 - val_Note_loss: 4.8091 - val_Volume_loss: 0.1258 - val_Duration_loss: 1.0629\n",
      "Epoch 13/400\n",
      "191/191 [==============================] - ETA: 0s - loss: 2.3253 - Note_loss: 1.8580 - Volume_loss: 0.0627 - Duration_loss: 0.4046\n",
      "Epoch 13: val_loss did not improve from 4.86057\n",
      "191/191 [==============================] - 225s 1s/step - loss: 2.3253 - Note_loss: 1.8580 - Volume_loss: 0.0627 - Duration_loss: 0.4046 - val_loss: 6.0497 - val_Note_loss: 4.9158 - val_Volume_loss: 0.1268 - val_Duration_loss: 1.0072\n",
      "Epoch 14/400\n",
      "191/191 [==============================] - ETA: 0s - loss: 2.1321 - Note_loss: 1.7074 - Volume_loss: 0.0596 - Duration_loss: 0.3651\n",
      "Epoch 14: val_loss did not improve from 4.86057\n",
      "191/191 [==============================] - 239s 1s/step - loss: 2.1321 - Note_loss: 1.7074 - Volume_loss: 0.0596 - Duration_loss: 0.3651 - val_loss: 6.3745 - val_Note_loss: 5.1348 - val_Volume_loss: 0.1305 - val_Duration_loss: 1.1092\n",
      "Epoch 15/400\n",
      "191/191 [==============================] - ETA: 0s - loss: 2.0235 - Note_loss: 1.6214 - Volume_loss: 0.0577 - Duration_loss: 0.3444\n",
      "Epoch 15: val_loss did not improve from 4.86057\n",
      "191/191 [==============================] - 230s 1s/step - loss: 2.0235 - Note_loss: 1.6214 - Volume_loss: 0.0577 - Duration_loss: 0.3444 - val_loss: 6.6354 - val_Note_loss: 5.2565 - val_Volume_loss: 0.1309 - val_Duration_loss: 1.2480\n",
      "Epoch 16/400\n",
      "191/191 [==============================] - ETA: 0s - loss: 1.8754 - Note_loss: 1.5085 - Volume_loss: 0.0553 - Duration_loss: 0.3116\n",
      "Epoch 16: val_loss did not improve from 4.86057\n",
      "191/191 [==============================] - 240s 1s/step - loss: 1.8754 - Note_loss: 1.5085 - Volume_loss: 0.0553 - Duration_loss: 0.3116 - val_loss: 6.7289 - val_Note_loss: 5.4073 - val_Volume_loss: 0.1283 - val_Duration_loss: 1.1933\n",
      "Epoch 17/400\n",
      "191/191 [==============================] - ETA: 0s - loss: 1.7859 - Note_loss: 1.4336 - Volume_loss: 0.0536 - Duration_loss: 0.2987\n",
      "Epoch 17: val_loss did not improve from 4.86057\n",
      "191/191 [==============================] - 211s 1s/step - loss: 1.7859 - Note_loss: 1.4336 - Volume_loss: 0.0536 - Duration_loss: 0.2987 - val_loss: 6.9189 - val_Note_loss: 5.4525 - val_Volume_loss: 0.1280 - val_Duration_loss: 1.3383\n",
      "Epoch 18/400\n",
      "191/191 [==============================] - ETA: 0s - loss: 1.6805 - Note_loss: 1.3506 - Volume_loss: 0.0520 - Duration_loss: 0.2778\n",
      "Epoch 18: val_loss did not improve from 4.86057\n",
      "191/191 [==============================] - 221s 1s/step - loss: 1.6805 - Note_loss: 1.3506 - Volume_loss: 0.0520 - Duration_loss: 0.2778 - val_loss: 6.9740 - val_Note_loss: 5.5165 - val_Volume_loss: 0.1294 - val_Duration_loss: 1.3281\n",
      "Epoch 19/400\n",
      "191/191 [==============================] - ETA: 0s - loss: 1.5881 - Note_loss: 1.2786 - Volume_loss: 0.0495 - Duration_loss: 0.2599\n",
      "Epoch 19: val_loss did not improve from 4.86057\n",
      "191/191 [==============================] - 225s 1s/step - loss: 1.5881 - Note_loss: 1.2786 - Volume_loss: 0.0495 - Duration_loss: 0.2599 - val_loss: 7.3166 - val_Note_loss: 5.8628 - val_Volume_loss: 0.1356 - val_Duration_loss: 1.3181\n",
      "Epoch 20/400\n",
      "191/191 [==============================] - ETA: 0s - loss: 1.4981 - Note_loss: 1.2011 - Volume_loss: 0.0485 - Duration_loss: 0.2485\n",
      "Epoch 20: val_loss did not improve from 4.86057\n",
      "191/191 [==============================] - 214s 1s/step - loss: 1.4981 - Note_loss: 1.2011 - Volume_loss: 0.0485 - Duration_loss: 0.2485 - val_loss: 7.6472 - val_Note_loss: 6.1568 - val_Volume_loss: 0.1334 - val_Duration_loss: 1.3570\n",
      "Epoch 21/400\n",
      "191/191 [==============================] - ETA: 0s - loss: 1.4084 - Note_loss: 1.1295 - Volume_loss: 0.0473 - Duration_loss: 0.2316\n",
      "Epoch 21: val_loss did not improve from 4.86057\n",
      "191/191 [==============================] - 238s 1s/step - loss: 1.4084 - Note_loss: 1.1295 - Volume_loss: 0.0473 - Duration_loss: 0.2316 - val_loss: 7.6409 - val_Note_loss: 6.0687 - val_Volume_loss: 0.1336 - val_Duration_loss: 1.4386\n",
      "Epoch 22/400\n",
      "191/191 [==============================] - ETA: 0s - loss: 1.3257 - Note_loss: 1.0622 - Volume_loss: 0.0456 - Duration_loss: 0.2178\n",
      "Epoch 22: val_loss did not improve from 4.86057\n",
      "191/191 [==============================] - 247s 1s/step - loss: 1.3257 - Note_loss: 1.0622 - Volume_loss: 0.0456 - Duration_loss: 0.2178 - val_loss: 7.9270 - val_Note_loss: 6.3235 - val_Volume_loss: 0.1330 - val_Duration_loss: 1.4705\n",
      "Epoch 23/400\n",
      "191/191 [==============================] - ETA: 0s - loss: 1.2643 - Note_loss: 1.0158 - Volume_loss: 0.0450 - Duration_loss: 0.2035\n",
      "Epoch 23: val_loss did not improve from 4.86057\n",
      "191/191 [==============================] - 278s 1s/step - loss: 1.2643 - Note_loss: 1.0158 - Volume_loss: 0.0450 - Duration_loss: 0.2035 - val_loss: 8.3515 - val_Note_loss: 6.6934 - val_Volume_loss: 0.1363 - val_Duration_loss: 1.5218\n",
      "Epoch 24/400\n",
      "191/191 [==============================] - ETA: 0s - loss: 1.1893 - Note_loss: 0.9534 - Volume_loss: 0.0430 - Duration_loss: 0.1929\n",
      "Epoch 24: val_loss did not improve from 4.86057\n",
      "191/191 [==============================] - 276s 1s/step - loss: 1.1893 - Note_loss: 0.9534 - Volume_loss: 0.0430 - Duration_loss: 0.1929 - val_loss: 8.2939 - val_Note_loss: 6.6447 - val_Volume_loss: 0.1357 - val_Duration_loss: 1.5135\n",
      "Epoch 25/400\n",
      "191/191 [==============================] - ETA: 0s - loss: 1.1319 - Note_loss: 0.9068 - Volume_loss: 0.0426 - Duration_loss: 0.1825\n",
      "Epoch 25: val_loss did not improve from 4.86057\n",
      "191/191 [==============================] - 258s 1s/step - loss: 1.1319 - Note_loss: 0.9068 - Volume_loss: 0.0426 - Duration_loss: 0.1825 - val_loss: 8.6254 - val_Note_loss: 6.8673 - val_Volume_loss: 0.1360 - val_Duration_loss: 1.6221\n",
      "Epoch 26/400\n",
      "191/191 [==============================] - ETA: 0s - loss: 1.0546 - Note_loss: 0.8415 - Volume_loss: 0.0411 - Duration_loss: 0.1720\n",
      "Epoch 26: val_loss did not improve from 4.86057\n",
      "191/191 [==============================] - 235s 1s/step - loss: 1.0546 - Note_loss: 0.8415 - Volume_loss: 0.0411 - Duration_loss: 0.1720 - val_loss: 8.8929 - val_Note_loss: 7.1748 - val_Volume_loss: 0.1412 - val_Duration_loss: 1.5768\n",
      "Epoch 27/400\n",
      "191/191 [==============================] - ETA: 0s - loss: 1.0079 - Note_loss: 0.8067 - Volume_loss: 0.0404 - Duration_loss: 0.1608\n",
      "Epoch 27: val_loss did not improve from 4.86057\n",
      "191/191 [==============================] - 253s 1s/step - loss: 1.0079 - Note_loss: 0.8067 - Volume_loss: 0.0404 - Duration_loss: 0.1608 - val_loss: 9.0645 - val_Note_loss: 7.3102 - val_Volume_loss: 0.1431 - val_Duration_loss: 1.6112\n",
      "Epoch 28/400\n",
      "191/191 [==============================] - ETA: 0s - loss: 0.9699 - Note_loss: 0.7728 - Volume_loss: 0.0401 - Duration_loss: 0.1570\n",
      "Epoch 28: val_loss did not improve from 4.86057\n",
      "191/191 [==============================] - 232s 1s/step - loss: 0.9699 - Note_loss: 0.7728 - Volume_loss: 0.0401 - Duration_loss: 0.1570 - val_loss: 9.2938 - val_Note_loss: 7.4969 - val_Volume_loss: 0.1411 - val_Duration_loss: 1.6559\n",
      "Epoch 29/400\n",
      "191/191 [==============================] - ETA: 0s - loss: 0.9079 - Note_loss: 0.7198 - Volume_loss: 0.0386 - Duration_loss: 0.1496\n",
      "Epoch 29: val_loss did not improve from 4.86057\n",
      "191/191 [==============================] - 223s 1s/step - loss: 0.9079 - Note_loss: 0.7198 - Volume_loss: 0.0386 - Duration_loss: 0.1496 - val_loss: 9.5735 - val_Note_loss: 7.7563 - val_Volume_loss: 0.1423 - val_Duration_loss: 1.6749\n",
      "Epoch 30/400\n",
      "191/191 [==============================] - ETA: 0s - loss: 0.8612 - Note_loss: 0.6797 - Volume_loss: 0.0379 - Duration_loss: 0.1436\n",
      "Epoch 30: val_loss did not improve from 4.86057\n",
      "191/191 [==============================] - 229s 1s/step - loss: 0.8612 - Note_loss: 0.6797 - Volume_loss: 0.0379 - Duration_loss: 0.1436 - val_loss: 9.8496 - val_Note_loss: 7.9842 - val_Volume_loss: 0.1408 - val_Duration_loss: 1.7247\n",
      "Epoch 31/400\n",
      "191/191 [==============================] - ETA: 0s - loss: 0.8338 - Note_loss: 0.6602 - Volume_loss: 0.0376 - Duration_loss: 0.1360\n",
      "Epoch 31: val_loss did not improve from 4.86057\n",
      "191/191 [==============================] - 238s 1s/step - loss: 0.8338 - Note_loss: 0.6602 - Volume_loss: 0.0376 - Duration_loss: 0.1360 - val_loss: 9.6674 - val_Note_loss: 7.8054 - val_Volume_loss: 0.1410 - val_Duration_loss: 1.7210\n",
      "Epoch 32/400\n",
      "191/191 [==============================] - ETA: 0s - loss: 0.7795 - Note_loss: 0.6129 - Volume_loss: 0.0366 - Duration_loss: 0.1300\n",
      "Epoch 32: val_loss did not improve from 4.86057\n",
      "191/191 [==============================] - 234s 1s/step - loss: 0.7795 - Note_loss: 0.6129 - Volume_loss: 0.0366 - Duration_loss: 0.1300 - val_loss: 10.3149 - val_Note_loss: 8.3313 - val_Volume_loss: 0.1423 - val_Duration_loss: 1.8413\n",
      "Epoch 33/400\n",
      "191/191 [==============================] - ETA: 0s - loss: 0.7515 - Note_loss: 0.5896 - Volume_loss: 0.0365 - Duration_loss: 0.1255\n",
      "Epoch 33: val_loss did not improve from 4.86057\n",
      "191/191 [==============================] - 224s 1s/step - loss: 0.7515 - Note_loss: 0.5896 - Volume_loss: 0.0365 - Duration_loss: 0.1255 - val_loss: 10.7695 - val_Note_loss: 8.5470 - val_Volume_loss: 0.1419 - val_Duration_loss: 2.0806\n",
      "Epoch 34/400\n",
      "191/191 [==============================] - ETA: 0s - loss: 0.7045 - Note_loss: 0.5507 - Volume_loss: 0.0357 - Duration_loss: 0.1181\n",
      "Epoch 34: val_loss did not improve from 4.86057\n",
      "191/191 [==============================] - 223s 1s/step - loss: 0.7045 - Note_loss: 0.5507 - Volume_loss: 0.0357 - Duration_loss: 0.1181 - val_loss: 10.7077 - val_Note_loss: 8.6246 - val_Volume_loss: 0.1431 - val_Duration_loss: 1.9401\n",
      "Epoch 35/400\n",
      "191/191 [==============================] - ETA: 0s - loss: 0.6764 - Note_loss: 0.5325 - Volume_loss: 0.0346 - Duration_loss: 0.1092\n",
      "Epoch 35: val_loss did not improve from 4.86057\n",
      "191/191 [==============================] - 214s 1s/step - loss: 0.6764 - Note_loss: 0.5325 - Volume_loss: 0.0346 - Duration_loss: 0.1092 - val_loss: 11.0427 - val_Note_loss: 8.9619 - val_Volume_loss: 0.1437 - val_Duration_loss: 1.9371\n",
      "Epoch 36/400\n",
      "191/191 [==============================] - ETA: 0s - loss: 0.6479 - Note_loss: 0.5044 - Volume_loss: 0.0340 - Duration_loss: 0.1094\n",
      "Epoch 36: val_loss did not improve from 4.86057\n",
      "191/191 [==============================] - 213s 1s/step - loss: 0.6479 - Note_loss: 0.5044 - Volume_loss: 0.0340 - Duration_loss: 0.1094 - val_loss: 11.0083 - val_Note_loss: 8.8945 - val_Volume_loss: 0.1471 - val_Duration_loss: 1.9668\n",
      "Epoch 37/400\n",
      "191/191 [==============================] - ETA: 0s - loss: 0.6307 - Note_loss: 0.4896 - Volume_loss: 0.0335 - Duration_loss: 0.1076\n",
      "Epoch 37: val_loss did not improve from 4.86057\n",
      "191/191 [==============================] - 221s 1s/step - loss: 0.6307 - Note_loss: 0.4896 - Volume_loss: 0.0335 - Duration_loss: 0.1076 - val_loss: 11.0145 - val_Note_loss: 8.9538 - val_Volume_loss: 0.1446 - val_Duration_loss: 1.9161\n",
      "Epoch 38/400\n",
      "180/191 [===========================>..] - ETA: 13s - loss: 0.5843 - Note_loss: 0.4543 - Volume_loss: 0.0333 - Duration_loss: 0.0968"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[27], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m \u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43m[\u001B[49m\u001B[43minput_note_reshaped\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minput_volume_reshaped\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minput_duration_reshaped\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m[\u001B[49m\u001B[43moutput_note_reshaped\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43moutput_volume_reshaped\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43moutput_duration_reshaped\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mepochs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m400\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcallbacks\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m[\u001B[49m\u001B[43mcp_callback\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mvalidation_split\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m0.2\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbatch_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m128\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mE:\\Users\\Asus\\Documents\\GitHub\\HarmonicAI\\venv\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:65\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m     63\u001B[0m filtered_tb \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m     64\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m---> 65\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m fn(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m     66\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m     67\u001B[0m     filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n",
      "File \u001B[1;32mE:\\Users\\Asus\\Documents\\GitHub\\HarmonicAI\\venv\\lib\\site-packages\\keras\\src\\engine\\training.py:1783\u001B[0m, in \u001B[0;36mModel.fit\u001B[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001B[0m\n\u001B[0;32m   1775\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m tf\u001B[38;5;241m.\u001B[39mprofiler\u001B[38;5;241m.\u001B[39mexperimental\u001B[38;5;241m.\u001B[39mTrace(\n\u001B[0;32m   1776\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtrain\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m   1777\u001B[0m     epoch_num\u001B[38;5;241m=\u001B[39mepoch,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   1780\u001B[0m     _r\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m,\n\u001B[0;32m   1781\u001B[0m ):\n\u001B[0;32m   1782\u001B[0m     callbacks\u001B[38;5;241m.\u001B[39mon_train_batch_begin(step)\n\u001B[1;32m-> 1783\u001B[0m     tmp_logs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrain_function\u001B[49m\u001B[43m(\u001B[49m\u001B[43miterator\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1784\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m data_handler\u001B[38;5;241m.\u001B[39mshould_sync:\n\u001B[0;32m   1785\u001B[0m         context\u001B[38;5;241m.\u001B[39masync_wait()\n",
      "File \u001B[1;32mE:\\Users\\Asus\\Documents\\GitHub\\HarmonicAI\\venv\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    148\u001B[0m filtered_tb \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m    149\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m--> 150\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m fn(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m    151\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m    152\u001B[0m   filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n",
      "File \u001B[1;32mE:\\Users\\Asus\\Documents\\GitHub\\HarmonicAI\\venv\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:831\u001B[0m, in \u001B[0;36mFunction.__call__\u001B[1;34m(self, *args, **kwds)\u001B[0m\n\u001B[0;32m    828\u001B[0m compiler \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mxla\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_jit_compile \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mnonXla\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    830\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m OptionalXlaContext(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_jit_compile):\n\u001B[1;32m--> 831\u001B[0m   result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_call(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwds)\n\u001B[0;32m    833\u001B[0m new_tracing_count \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mexperimental_get_tracing_count()\n\u001B[0;32m    834\u001B[0m without_tracing \u001B[38;5;241m=\u001B[39m (tracing_count \u001B[38;5;241m==\u001B[39m new_tracing_count)\n",
      "File \u001B[1;32mE:\\Users\\Asus\\Documents\\GitHub\\HarmonicAI\\venv\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:867\u001B[0m, in \u001B[0;36mFunction._call\u001B[1;34m(self, *args, **kwds)\u001B[0m\n\u001B[0;32m    864\u001B[0m   \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_lock\u001B[38;5;241m.\u001B[39mrelease()\n\u001B[0;32m    865\u001B[0m   \u001B[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001B[39;00m\n\u001B[0;32m    866\u001B[0m   \u001B[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001B[39;00m\n\u001B[1;32m--> 867\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mtracing_compilation\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcall_function\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    868\u001B[0m \u001B[43m      \u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkwds\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_no_variable_creation_config\u001B[49m\n\u001B[0;32m    869\u001B[0m \u001B[43m  \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    870\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_variable_creation_config \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m    871\u001B[0m   \u001B[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001B[39;00m\n\u001B[0;32m    872\u001B[0m   \u001B[38;5;66;03m# in parallel.\u001B[39;00m\n\u001B[0;32m    873\u001B[0m   \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_lock\u001B[38;5;241m.\u001B[39mrelease()\n",
      "File \u001B[1;32mE:\\Users\\Asus\\Documents\\GitHub\\HarmonicAI\\venv\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compilation.py:139\u001B[0m, in \u001B[0;36mcall_function\u001B[1;34m(args, kwargs, tracing_options)\u001B[0m\n\u001B[0;32m    137\u001B[0m bound_args \u001B[38;5;241m=\u001B[39m function\u001B[38;5;241m.\u001B[39mfunction_type\u001B[38;5;241m.\u001B[39mbind(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m    138\u001B[0m flat_inputs \u001B[38;5;241m=\u001B[39m function\u001B[38;5;241m.\u001B[39mfunction_type\u001B[38;5;241m.\u001B[39munpack_inputs(bound_args)\n\u001B[1;32m--> 139\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfunction\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_flat\u001B[49m\u001B[43m(\u001B[49m\u001B[43m  \u001B[49m\u001B[38;5;66;43;03m# pylint: disable=protected-access\u001B[39;49;00m\n\u001B[0;32m    140\u001B[0m \u001B[43m    \u001B[49m\u001B[43mflat_inputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcaptured_inputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mfunction\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcaptured_inputs\u001B[49m\n\u001B[0;32m    141\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mE:\\Users\\Asus\\Documents\\GitHub\\HarmonicAI\\venv\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\concrete_function.py:1264\u001B[0m, in \u001B[0;36mConcreteFunction._call_flat\u001B[1;34m(self, tensor_inputs, captured_inputs)\u001B[0m\n\u001B[0;32m   1260\u001B[0m possible_gradient_type \u001B[38;5;241m=\u001B[39m gradients_util\u001B[38;5;241m.\u001B[39mPossibleTapeGradientTypes(args)\n\u001B[0;32m   1261\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m (possible_gradient_type \u001B[38;5;241m==\u001B[39m gradients_util\u001B[38;5;241m.\u001B[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001B[0;32m   1262\u001B[0m     \u001B[38;5;129;01mand\u001B[39;00m executing_eagerly):\n\u001B[0;32m   1263\u001B[0m   \u001B[38;5;66;03m# No tape is watching; skip to running the function.\u001B[39;00m\n\u001B[1;32m-> 1264\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_inference_function\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mflat_call\u001B[49m\u001B[43m(\u001B[49m\u001B[43margs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1265\u001B[0m forward_backward \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_select_forward_and_backward_functions(\n\u001B[0;32m   1266\u001B[0m     args,\n\u001B[0;32m   1267\u001B[0m     possible_gradient_type,\n\u001B[0;32m   1268\u001B[0m     executing_eagerly)\n\u001B[0;32m   1269\u001B[0m forward_function, args_with_tangents \u001B[38;5;241m=\u001B[39m forward_backward\u001B[38;5;241m.\u001B[39mforward()\n",
      "File \u001B[1;32mE:\\Users\\Asus\\Documents\\GitHub\\HarmonicAI\\venv\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:217\u001B[0m, in \u001B[0;36mAtomicFunction.flat_call\u001B[1;34m(self, args)\u001B[0m\n\u001B[0;32m    215\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mflat_call\u001B[39m(\u001B[38;5;28mself\u001B[39m, args: Sequence[core\u001B[38;5;241m.\u001B[39mTensor]) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Any:\n\u001B[0;32m    216\u001B[0m \u001B[38;5;250m  \u001B[39m\u001B[38;5;124;03m\"\"\"Calls with tensor inputs and returns the structured output.\"\"\"\u001B[39;00m\n\u001B[1;32m--> 217\u001B[0m   flat_outputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    218\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfunction_type\u001B[38;5;241m.\u001B[39mpack_output(flat_outputs)\n",
      "File \u001B[1;32mE:\\Users\\Asus\\Documents\\GitHub\\HarmonicAI\\venv\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:252\u001B[0m, in \u001B[0;36mAtomicFunction.__call__\u001B[1;34m(self, *args)\u001B[0m\n\u001B[0;32m    250\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m record\u001B[38;5;241m.\u001B[39mstop_recording():\n\u001B[0;32m    251\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_bound_context\u001B[38;5;241m.\u001B[39mexecuting_eagerly():\n\u001B[1;32m--> 252\u001B[0m     outputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_bound_context\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcall_function\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    253\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mname\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    254\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43mlist\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43margs\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    255\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43mlen\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfunction_type\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mflat_outputs\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    256\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    257\u001B[0m   \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    258\u001B[0m     outputs \u001B[38;5;241m=\u001B[39m make_call_op_in_graph(\n\u001B[0;32m    259\u001B[0m         \u001B[38;5;28mself\u001B[39m,\n\u001B[0;32m    260\u001B[0m         \u001B[38;5;28mlist\u001B[39m(args),\n\u001B[0;32m    261\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_bound_context\u001B[38;5;241m.\u001B[39mfunction_call_options\u001B[38;5;241m.\u001B[39mas_attrs(),\n\u001B[0;32m    262\u001B[0m     )\n",
      "File \u001B[1;32mE:\\Users\\Asus\\Documents\\GitHub\\HarmonicAI\\venv\\lib\\site-packages\\tensorflow\\python\\eager\\context.py:1479\u001B[0m, in \u001B[0;36mContext.call_function\u001B[1;34m(self, name, tensor_inputs, num_outputs)\u001B[0m\n\u001B[0;32m   1477\u001B[0m cancellation_context \u001B[38;5;241m=\u001B[39m cancellation\u001B[38;5;241m.\u001B[39mcontext()\n\u001B[0;32m   1478\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m cancellation_context \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m-> 1479\u001B[0m   outputs \u001B[38;5;241m=\u001B[39m \u001B[43mexecute\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mexecute\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   1480\u001B[0m \u001B[43m      \u001B[49m\u001B[43mname\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdecode\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mutf-8\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1481\u001B[0m \u001B[43m      \u001B[49m\u001B[43mnum_outputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mnum_outputs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1482\u001B[0m \u001B[43m      \u001B[49m\u001B[43minputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtensor_inputs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1483\u001B[0m \u001B[43m      \u001B[49m\u001B[43mattrs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mattrs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1484\u001B[0m \u001B[43m      \u001B[49m\u001B[43mctx\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1485\u001B[0m \u001B[43m  \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1486\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m   1487\u001B[0m   outputs \u001B[38;5;241m=\u001B[39m execute\u001B[38;5;241m.\u001B[39mexecute_with_cancellation(\n\u001B[0;32m   1488\u001B[0m       name\u001B[38;5;241m.\u001B[39mdecode(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mutf-8\u001B[39m\u001B[38;5;124m\"\u001B[39m),\n\u001B[0;32m   1489\u001B[0m       num_outputs\u001B[38;5;241m=\u001B[39mnum_outputs,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   1493\u001B[0m       cancellation_manager\u001B[38;5;241m=\u001B[39mcancellation_context,\n\u001B[0;32m   1494\u001B[0m   )\n",
      "File \u001B[1;32mE:\\Users\\Asus\\Documents\\GitHub\\HarmonicAI\\venv\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:60\u001B[0m, in \u001B[0;36mquick_execute\u001B[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001B[0m\n\u001B[0;32m     53\u001B[0m   \u001B[38;5;66;03m# Convert any objects of type core_types.Tensor to Tensor.\u001B[39;00m\n\u001B[0;32m     54\u001B[0m   inputs \u001B[38;5;241m=\u001B[39m [\n\u001B[0;32m     55\u001B[0m       tensor_conversion_registry\u001B[38;5;241m.\u001B[39mconvert(t)\n\u001B[0;32m     56\u001B[0m       \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(t, core_types\u001B[38;5;241m.\u001B[39mTensor)\n\u001B[0;32m     57\u001B[0m       \u001B[38;5;28;01melse\u001B[39;00m t\n\u001B[0;32m     58\u001B[0m       \u001B[38;5;28;01mfor\u001B[39;00m t \u001B[38;5;129;01min\u001B[39;00m inputs\n\u001B[0;32m     59\u001B[0m   ]\n\u001B[1;32m---> 60\u001B[0m   tensors \u001B[38;5;241m=\u001B[39m \u001B[43mpywrap_tfe\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mTFE_Py_Execute\u001B[49m\u001B[43m(\u001B[49m\u001B[43mctx\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_handle\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdevice_name\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mop_name\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     61\u001B[0m \u001B[43m                                      \u001B[49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mattrs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnum_outputs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     62\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m core\u001B[38;5;241m.\u001B[39m_NotOkStatusException \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m     63\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m name \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "#prend une séquence de notes, volume, durées\n",
    "pattern_note = input_note[-1]\n",
    "pattern_volume = input_volume[-1]\n",
    "pattern_duration = input_duration[-1]"
   ],
   "metadata": {
    "id": "S7L6Fyy1pFBa",
    "ExecuteTime": {
     "end_time": "2023-10-22T23:31:52.742303900Z",
     "start_time": "2023-10-22T23:31:52.737303500Z"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# prediction time\n",
    "prediction_output = []\n",
    "\n",
    "for i in tqdm(range(200)):\n",
    "\n",
    "    #on reshape les input à prédire\n",
    "    note_prediction_input = numpy.reshape(pattern_note, (1, len(pattern_note), -1))\n",
    "    volume_prediction_input = numpy.reshape(pattern_volume, (1, len(pattern_volume), -1))\n",
    "    duration_prediction_input = numpy.reshape(pattern_duration, (1, len(pattern_duration), -1))\n",
    "\n",
    "    #prédit ici\n",
    "    prediction = model.predict([note_prediction_input, volume_prediction_input, duration_prediction_input], verbose=0)\n",
    "\n",
    "    # prédis la note en récupérant l'index max du softmax et en faisant la transofr inverse\n",
    "    # à partir du one hot train sur les notes\n",
    "    notes_pred = np.zeros(len(pattern_note[0]))\n",
    "    notes_pred[np.argmax(prediction[0])] = 1\n",
    "    result_note = oh_notes.inverse_transform(notes_pred.reshape(1, -1))\n",
    "    pattern_note = numpy.concatenate([pattern_note, prediction[0]])\n",
    "    pattern_note = pattern_note[1:]\n",
    "\n",
    "    # la même avec le volume\n",
    "    volume_pred = np.zeros(len(pattern_volume[1]))\n",
    "    volume_pred[np.argmax(prediction[1])] = 1\n",
    "    result_volume = oh_volume.inverse_transform(volume_pred.reshape(1, -1))\n",
    "    pattern_volume = numpy.concatenate([pattern_volume, prediction[1]])\n",
    "    pattern_volume = pattern_volume[1:]\n",
    "\n",
    "    # la même avec la durée\n",
    "    duration_pred = np.zeros(len(pattern_duration[0]))\n",
    "    duration_pred[np.argmax(prediction[2])] = 1\n",
    "    result_duration = oh_duration.inverse_transform(duration_pred.reshape(1, -1))\n",
    "    pattern_duration = numpy.concatenate([pattern_duration, prediction[2]])\n",
    "    pattern_duration = pattern_duration[1:]\n",
    "\n",
    "    # comme on prédit un mot associé au volume, on associe au mot une valeur/intensité\n",
    "    #(manque des catégories)\n",
    "    volume_encoded = result_volume[0][0]\n",
    "    volume_decoded = 0\n",
    "    if volume_encoded == \"low\":\n",
    "      volume_decoded = 30\n",
    "    if volume_encoded == \"medium\":\n",
    "      volume_decoded = 60\n",
    "    if volume_encoded == \"high\":\n",
    "      volume_decoded = 90\n",
    "\n",
    "    # la même avec la durée\n",
    "    #(manque des catégories)\n",
    "    duration_encoded = result_duration[0][0]\n",
    "    duration_encoded = 0\n",
    "    if volume_encoded == \"short\":\n",
    "      duration_encoded = 0.25\n",
    "    if volume_encoded == \"medium\":\n",
    "      duration_encoded = 0.5\n",
    "    if volume_encoded == \"high\":\n",
    "      duration_encoded = 0.75\n",
    "\n",
    "    #on ajoute la note, le volyme et la durée\n",
    "    prediction_output.append([result_note[0][0], volume_decoded, duration_encoded])\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1C2Vt-MH0nm_",
    "outputId": "28359c66-670b-4c53-baa0-30fa3c0fd67f",
    "ExecuteTime": {
     "end_time": "2023-10-22T23:31:52.842303800Z",
     "start_time": "2023-10-22T23:31:52.751303300Z"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "from music21.duration import Duration\n"
   ],
   "metadata": {
    "id": "91w43lwl5urg",
    "ExecuteTime": {
     "start_time": "2023-10-22T23:31:52.752303700Z"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "offset = 0\n",
    "output_notes = []\n",
    "# on passes des prédicitons à un format écoutable à l'oreille\n",
    "\n",
    "# pour chaque note prédite\n",
    "for note_p in prediction_output:\n",
    "    pattern = note_p[0]\n",
    "    # si note = chord\n",
    "    if ('+' in pattern) or pattern.isdigit():\n",
    "        notes_in_chord = pattern.split('+')\n",
    "        notes = []\n",
    "        for current_note in notes_in_chord:\n",
    "            new_note = note.Note(int(current_note))\n",
    "            new_note.storedInstrument = instrument.Piano()\n",
    "            notes.append(new_note)\n",
    "        new_chord = chord.Chord(notes)\n",
    "        new_chord.offset = offset\n",
    "        # met le volume associé\n",
    "        new_chord.volume.velocity = note_p[1]\n",
    "        # met la durée associée\n",
    "        new_chord.duration = Duration(note_p[2])\n",
    "        output_notes.append(new_chord)\n",
    "    # si note est un rest\n",
    "    elif('REST'in pattern):\n",
    "      note_rest = note.Rest()\n",
    "      note_rest.offset = offset\n",
    "      # durée associée (pas de volume car silencieux)\n",
    "      note_rest.duration = Duration(note_p[2])\n",
    "      output_notes.append(note_rest)\n",
    "    else:\n",
    "        new_note = note.Note(pattern)\n",
    "        new_note.offset = offset\n",
    "        new_note.volume.velocity = note_p[1]\n",
    "        new_note.duration = Duration(note_p[2])\n",
    "        new_note.storedInstrument = instrument.Piano()\n",
    "        output_notes.append(new_note)\n",
    "\n",
    "    # increase offset each iteration so that notes do not stack\n",
    "    offset += 0.5"
   ],
   "metadata": {
    "id": "BxktumUV0H22",
    "ExecuteTime": {
     "start_time": "2023-10-22T23:31:52.824304300Z"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "#into midi\n",
    "midi_stream = stream.Stream(output_notes)\n",
    "midi_stream.write('midi', fp='test_outputminecraft.mid')"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "id": "I5W_QMyyn7BA",
    "outputId": "57dbdcf5-b78b-44f2-ffe6-66ef0745cd39",
    "ExecuteTime": {
     "start_time": "2023-10-22T23:31:52.825304Z"
    }
   },
   "execution_count": null,
   "outputs": []
  }
 ]
}
