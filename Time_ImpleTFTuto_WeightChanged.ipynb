{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "wLez1Slaaydy"
      },
      "outputs": [],
      "source": [
        "from music21 import converter, instrument, note, chord, stream\n",
        "import numpy\n",
        "from matplotlib import pyplot as plt\n",
        "import keras\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from keras import Sequential, Model\n",
        "from keras.layers import LSTM, Dropout, Dense, Activation, Input, concatenate\n",
        "import pandas as pd\n",
        "from tensorflow.keras.layers import Input, Dense, Dropout, BatchNormalization, Flatten\n",
        "import os\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import MultiHeadAttention, LayerNormalization, Embedding\n",
        "import tensorflow as tf\n",
        "from tqdm import tqdm\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip dataset.zip"
      ],
      "metadata": {
        "id": "jMOiwvUEduhe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_notes(midi):\n",
        "  notes = []\n",
        "\n",
        "  notes_from_midi = midi.flatten().notesAndRests\n",
        "  notes_sorted = sorted(notes_from_midi, key=lambda note: note.offset)\n",
        "\n",
        "  prev_start = notes_sorted[0].offset\n",
        "\n",
        "  for element in notes_sorted:\n",
        "    if isinstance(element , note.Note):\n",
        "      notes.append((float(element.offset), float(element.volume.velocity),float(element.seconds), str(element.pitch), float(element.offset-prev_start)))\n",
        "    elif isinstance(element, chord.Chord):\n",
        "      #notes.append((float(element.offset), float(element.volume.velocity), float(element.seconds), '+'.join(str(n) for n in element.normalOrder)))\n",
        "      for noteChord in element.pitches:\n",
        "        notes.append((float(element.offset),float(element.volume.velocity), float(element.seconds), str(noteChord), float(element.offset-prev_start)))\n",
        "\n",
        "    elif isinstance(element, note.Rest):\n",
        "        # Bizarre car main gauche et droite flatten (réunie)\n",
        "        # Voir autre implémentation\n",
        "        notes.append((float(element.offset), 0,float(element.seconds), \"REST\", float(element.offset-prev_start)))\n",
        "\n",
        "    prev_start = element.offset\n",
        "  return notes\n",
        "\n"
      ],
      "metadata": {
        "id": "ltEonII2gWg0"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_note, output_note = [], []\n",
        "input_offset, output_offset = [], []\n",
        "input_volume, output_volume = [], []\n",
        "input_duration, output_duration = [], []\n",
        "\n",
        "note_all_songs = []\n",
        "for folder in tqdm(os.walk(\"dataset\")):\n",
        "    if len(folder) != 3:\n",
        "      continue\n",
        "    else:\n",
        "      for file in folder[2]:\n",
        "        file_path = str(folder[0])+\"/\"+file\n",
        "\n",
        "        # convertit la piste midi\n",
        "        midi = converter.parse(file_path)\n",
        "\n",
        "        # récupère les notes, volume, dureées...\n",
        "        notes = get_notes(midi)\n",
        "\n",
        "        # ajoute à une liste globale\n",
        "        note_all_songs.append(notes)"
      ],
      "metadata": {
        "id": "nUvY0NWPd79V",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "52b7f766-772a-457f-e083-1e758a13104b"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "1it [00:02,  2.57s/it]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# fais un dataframe à partir de toutes les notes (sans distinctions)\n",
        "df = pd.DataFrame([], columns=['debut_note','volume','durée(s)', 'pitch/chord', 'offset'])\n",
        "df = df.reset_index(drop=True)\n",
        "for elem in note_all_songs:\n",
        "    df2 = pd.DataFrame(elem, columns=['debut_note','volume','durée(s)', 'pitch/chord', 'offset'])\n",
        "    df2 = df2.reset_index(drop=True)\n",
        "    df =pd.concat([df,df2])\n",
        "    df = df.reset_index(drop=True)"
      ],
      "metadata": {
        "id": "_bRdnkH6OdJA"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['nombre_de_notes_simultanees'] = 0\n",
        "\n",
        "# Triez le DataFrame par colonne 'offset'\n",
        "df = df.sort_values(by='debut_note')\n",
        "\n",
        "def compter_notes_simultanees(row):\n",
        "    return df[(df['debut_note'] <= row['debut_note']) & (df['debut_note'] + df['durée(s)'] >= row['debut_note'])].shape[0]\n",
        "\n",
        "# Appliquez la fonction compter_notes_simultanees à chaque ligne du DataFrame\n",
        "df['nombre_de_notes_simultanees'] = df.apply(compter_notes_simultanees, axis=1)\n"
      ],
      "metadata": {
        "id": "TUqnlzxUlFe3"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "id": "FsqRZiQCm3MV",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "outputId": "3908f74b-2576-4bc6-8e33-9fa79848a81e"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      debut_note  volume  durée(s) pitch/chord  offset\n",
              "0            0.0    56.0  0.416667          A2    0.00\n",
              "1            0.5    56.0  0.416667         C#3    0.50\n",
              "2            1.0    69.0  0.416667          A3    0.50\n",
              "3            1.5    73.0  0.416667          B3    0.50\n",
              "4            2.0    64.0  0.416667         C#4    0.50\n",
              "...          ...     ...       ...         ...     ...\n",
              "1753        86.0    74.0  3.200000          G1    0.25\n",
              "1754        86.0    74.0  3.200000          G3    0.25\n",
              "1755        86.0    74.0  3.200000          B3    0.25\n",
              "1756        86.0     0.0  3.200000        REST    0.00\n",
              "1757        86.0     0.0  3.200000        REST    0.00\n",
              "\n",
              "[1758 rows x 5 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-eb36629f-009a-4036-9323-36245ef9ce8e\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>debut_note</th>\n",
              "      <th>volume</th>\n",
              "      <th>durée(s)</th>\n",
              "      <th>pitch/chord</th>\n",
              "      <th>offset</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.0</td>\n",
              "      <td>56.0</td>\n",
              "      <td>0.416667</td>\n",
              "      <td>A2</td>\n",
              "      <td>0.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.5</td>\n",
              "      <td>56.0</td>\n",
              "      <td>0.416667</td>\n",
              "      <td>C#3</td>\n",
              "      <td>0.50</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1.0</td>\n",
              "      <td>69.0</td>\n",
              "      <td>0.416667</td>\n",
              "      <td>A3</td>\n",
              "      <td>0.50</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1.5</td>\n",
              "      <td>73.0</td>\n",
              "      <td>0.416667</td>\n",
              "      <td>B3</td>\n",
              "      <td>0.50</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2.0</td>\n",
              "      <td>64.0</td>\n",
              "      <td>0.416667</td>\n",
              "      <td>C#4</td>\n",
              "      <td>0.50</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1753</th>\n",
              "      <td>86.0</td>\n",
              "      <td>74.0</td>\n",
              "      <td>3.200000</td>\n",
              "      <td>G1</td>\n",
              "      <td>0.25</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1754</th>\n",
              "      <td>86.0</td>\n",
              "      <td>74.0</td>\n",
              "      <td>3.200000</td>\n",
              "      <td>G3</td>\n",
              "      <td>0.25</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1755</th>\n",
              "      <td>86.0</td>\n",
              "      <td>74.0</td>\n",
              "      <td>3.200000</td>\n",
              "      <td>B3</td>\n",
              "      <td>0.25</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1756</th>\n",
              "      <td>86.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.200000</td>\n",
              "      <td>REST</td>\n",
              "      <td>0.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1757</th>\n",
              "      <td>86.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.200000</td>\n",
              "      <td>REST</td>\n",
              "      <td>0.00</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1758 rows × 5 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-eb36629f-009a-4036-9323-36245ef9ce8e')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-eb36629f-009a-4036-9323-36245ef9ce8e button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-eb36629f-009a-4036-9323-36245ef9ce8e');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-5c1f0ec7-12d7-4e36-a785-498615042728\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-5c1f0ec7-12d7-4e36-a785-498615042728')\"\n",
              "            title=\"Suggest charts.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-5c1f0ec7-12d7-4e36-a785-498615042728 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#train les encoders pour les notes, volumes et durées en catégorielles (one hot)\n",
        "# sur intégralité des données (obligé)\n",
        "# Voir si on peut pas enregistré le transformateur\n",
        "oh_notes =  OneHotEncoder().fit(df[['pitch/chord']])\n",
        "\n",
        "\n",
        "# seuil/catégories modifiable\n",
        "dict_volume_class = {\n",
        "    \"very low\":10,\n",
        "    \"low\":30,\n",
        "    \"low medium\":50,\n",
        "    \"medium\":70,\n",
        "    \"high\": 90,\n",
        "    \"very high\":128\n",
        "}\n",
        "bins_volume = list(dict_volume_class.values())\n",
        "bins_volume.insert(0,-0.1)\n",
        "values_volume = list(dict_volume_class.keys())\n",
        "df[\"volume_class\"] = pd.cut(df[\"volume\"], bins=bins_volume, labels=values_volume)\n",
        "\"\"\"df[\"volume_class_interval\"] = pd.cut(df[\"volume\"], bins=20)\n",
        "intervals = df[\"volume_class_interval\"]\n",
        "median_values = [(interval.left + interval.right) / 2 for interval in intervals]\n",
        "df[\"volume_class\"] = median_values\"\"\"\n",
        "oh_volume =  OneHotEncoder().fit(df[['volume_class']])\n",
        "\n",
        "\n",
        "dict_duration_class = {\n",
        "\"very short\" : 0.1,\n",
        "\"short\" :0.25,\n",
        "\"medium\":0.5,\n",
        "\"medium-long\":0.75,\n",
        "\"long\":1.0,\n",
        "\"very long\": 1.5,\n",
        "\"kilometer long\":2.0,\n",
        "\"yearlight distance\":3.0,\n",
        "\"super mega long\":df['durée(s)'].max()\n",
        "}\n",
        "bins_duration = list(dict_duration_class.values())\n",
        "bins_duration.insert(0,-0.1)\n",
        "values_duration = list(dict_duration_class.keys())\n",
        "df[\"duration_class\"] = pd.cut(df[\"durée(s)\"], bins=bins_duration, labels=values_duration)\n",
        "\"\"\"df[\"duration_class_interval\"] = pd.cut(df[\"durée(s)\"], bins=20)\n",
        "intervals = df[\"duration_class_interval\"]\n",
        "median_values = [(interval.left + interval.right) / 2 for interval in intervals]\n",
        "df[\"duration_class\"] = median_values\"\"\"\n",
        "oh_duration =  OneHotEncoder().fit(df[['duration_class']])\n"
      ],
      "metadata": {
        "id": "sJ6s6EG-UTLz"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def prepare_sequence(data, sequence_length, network_input, network_output):\n",
        "  # create input sequences and the corresponding outputs\n",
        "  for i in range(0, len(data) - sequence_length, 1):\n",
        "      sequence_in = data[i:i + sequence_length]\n",
        "      sequence_out = data[i + sequence_length]\n",
        "      network_input.append(sequence_in)\n",
        "      network_output.append(sequence_out)\n",
        "  return (network_input, network_output)\n",
        "\n",
        "def reshape_array_input(array_tensor, sequence_length):\n",
        "  n_patterns = len(array_tensor)\n",
        "  array_reshaped = numpy.reshape(array_tensor, (n_patterns, sequence_length, -1))\n",
        "  return array_reshaped\n",
        "\n",
        "def reshape_array_output(array_tensor, sequence_length):\n",
        "  n_patterns = len(array_tensor)\n",
        "  array_reshaped = numpy.reshape(array_tensor, (len(array_tensor), -1))\n",
        "  return array_reshaped\n"
      ],
      "metadata": {
        "id": "2Z_CqsKBicHH"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sequence_length = 50"
      ],
      "metadata": {
        "id": "tqK33V-UjsOn"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_note, output_note = [], []\n",
        "input_offset, output_offset = [], []\n",
        "input_volume, output_volume = [], []\n",
        "input_duration, output_duration = [], []\n",
        "input_step, output_step = [], []\n",
        "input_simul, output_simult = [],[]\n",
        "\n",
        "# pour chaque music, on la transforme en dataframe, transforme les notes, durées et volumes\n",
        "for music in note_all_songs:\n",
        "  df_music = pd.DataFrame(music, columns=['debut_note','volume','durée(s)', 'pitch/chord', 'step'])\n",
        "\n",
        "  # encode le volume et la durée\n",
        "  df_music[\"volume_class\"] = pd.cut(df_music[\"volume\"], bins=bins_volume, labels=values_volume)\n",
        "  df_music[\"duration_class\"] = pd.cut(df_music[\"durée(s)\"], bins=bins_duration, labels=values_duration)\n",
        "  #df_music['nombre_de_notes_simultanees'] = df_music.apply(compter_notes_simultanees, axis=1)\n",
        "\n",
        "\n",
        "  # transform en one hot à partir des modèles entrainés\n",
        "  notes_encoded = oh_notes.transform(df_music[['pitch/chord']]).toarray()\n",
        "  volume_encoded = oh_volume.transform(df_music[['volume_class']]).toarray()\n",
        "  duration_encoded = oh_duration.transform(df_music[['duration_class']]).toarray()\n",
        "\n",
        "  # prépare les input (longeur = sequence_length) pour chaque morceau\n",
        "  # garde certaine cohérence au morceau même\n",
        "  input_offset, output_offset = prepare_sequence(df_music['debut_note'].values, sequence_length, input_offset, output_offset)\n",
        "  input_note, output_note = prepare_sequence(notes_encoded, sequence_length, input_note, output_note)\n",
        "  input_volume, output_volume = prepare_sequence(volume_encoded, sequence_length, input_volume, output_volume)\n",
        "  input_duration, output_duration = prepare_sequence(duration_encoded, sequence_length, input_duration, output_duration)\n",
        "  input_step, output_step = prepare_sequence(df_music['step'].values, sequence_length, input_step, output_step)\n",
        "  #input_simul, output_simult = prepare_sequence(df_music['nombre_de_notes_simultanees'].values, sequence_length, input_simul, output_simult)"
      ],
      "metadata": {
        "id": "1lpnB-spixTZ"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# on reshape tout\n",
        "input_note_reshaped= reshape_array_input(input_note, sequence_length)\n",
        "output_note_reshaped = reshape_array_output(output_note, sequence_length)\n",
        "\n",
        "input_offset_reshaped = reshape_array_input(input_offset, sequence_length)\n",
        "output_offset_reshaped = reshape_array_output(output_offset, sequence_length)\n",
        "\n",
        "input_offset_reshaped_d = input_offset_reshaped - 86\n",
        "output_offset_reshaped_d = output_offset_reshaped - 86\n",
        "\n",
        "input_volume_reshaped= reshape_array_input(input_volume, sequence_length)\n",
        "output_volume_reshaped = reshape_array_output(output_volume, sequence_length)\n",
        "\n",
        "input_duration_reshaped= reshape_array_input(input_duration, sequence_length)\n",
        "output_duration_reshaped = reshape_array_output(output_duration, sequence_length)\n",
        "\n",
        "\n",
        "input_step_reshaped= reshape_array_input(input_step, sequence_length)\n",
        "output_step_reshaped = reshape_array_output(output_step, sequence_length)\n",
        "\n",
        "\"\"\"input_simul = reshape_array_input(input_simul, sequence_length)\n",
        "output_simult = reshape_array_output(output_simult, sequence_length)\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "AzX_ofZZj1vY",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "02b83cc0-86b6-4c01-808f-33014a34372b"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'input_simul = reshape_array_input(input_simul, sequence_length)\\noutput_simult = reshape_array_output(output_simult, sequence_length)\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#création du modèle (à alléger si overfitting)\n",
        "inputNotes_layer = Input(shape=(input_note_reshaped.shape[1], input_note_reshaped.shape[2]))\n",
        "inputNotes = LSTM(\n",
        "        32,\n",
        "        input_shape=(input_note_reshaped.shape[1], input_note_reshaped.shape[2]),\n",
        "        dropout=0.25,\n",
        "        return_sequences=True\n",
        "    )(inputNotes_layer)\n",
        "\n",
        "inputVolume_layer = Input(shape=(input_volume_reshaped.shape[1], input_volume_reshaped.shape[2]))\n",
        "inputVolume = LSTM(\n",
        "        32,\n",
        "        input_shape=(input_volume_reshaped.shape[1], input_volume_reshaped.shape[2]),\n",
        "        dropout=0.25,\n",
        "        return_sequences=True\n",
        "    )(inputVolume_layer)\n",
        "\n",
        "inputDuration_layer = Input(shape=(input_duration_reshaped.shape[1], input_duration_reshaped.shape[2]))\n",
        "inputDuration = LSTM(\n",
        "        32,\n",
        "        input_shape=(input_duration_reshaped.shape[1], input_duration_reshaped.shape[2]),\n",
        "        dropout=0.25,\n",
        "        return_sequences=True\n",
        "    )(inputDuration_layer)\n",
        "\n",
        "\"\"\"inputOffset_layer = Input(shape=(input_offset_reshaped.shape[1], input_offset_reshaped.shape[2]))\n",
        "inputOffset = LSTM(\n",
        "        32,\n",
        "        input_shape=(input_offset_reshaped.shape[1], input_offset_reshaped.shape[2]),\n",
        "        return_sequences=True\n",
        "    )(inputOffset_layer)\"\"\"\n",
        "\n",
        "inputStep_layer = Input(shape=(input_step_reshaped.shape[1], input_step_reshaped.shape[2]))\n",
        "inputStep = LSTM(\n",
        "        32,\n",
        "        dropout=0.25,\n",
        "        input_shape=(input_step_reshaped.shape[1], input_step_reshaped.shape[2]),\n",
        "        return_sequences=True\n",
        "    )(inputStep_layer)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "inputs = concatenate([inputNotes, inputVolume, inputDuration, inputStep])\n",
        "x = LSTM(128, return_sequences=True, dropout=0.25)(inputs)\n",
        "x = LSTM(128, dropout=0.25)(inputs)\n",
        "x = Dense(128)(x)\n",
        "\n",
        "outputNotes = Dense(16)(x)\n",
        "outputNotes = Dropout(0.25)(outputNotes)\n",
        "outputNotes = Dense(output_note_reshaped.shape[1], activation='softmax', name=\"Note\")(outputNotes)\n",
        "\n",
        "outputVolume = Dense(16)(x)\n",
        "\"\"\"outputVolume = BatchNormalization()(outputVolume)\n",
        "outputVolume = Dropout(0.5)(outputVolume)\n",
        "outputVolume = Dense(16)(outputVolume)\"\"\"\n",
        "outputVolume = Dense(output_volume_reshaped.shape[1], activation='softmax', name=\"Volume\")(outputVolume)\n",
        "\n",
        "outputDuration = Dense(16)(x)\n",
        "outputDuration = Dense(64)(outputDuration)\n",
        "\n",
        "\"\"\"outputDuration = BatchNormalization()(outputDuration)\n",
        "outputDuration = Dropout(0.5)(outputDuration)\n",
        "outputDuration = Dense(16)(outputDuration)\"\"\"\n",
        "outputDuration = Dense(output_duration_reshaped.shape[1], activation='softmax', name=\"Duration\")(outputDuration)\n",
        "\n",
        "outputOffset =  Dense(16)(x)\n",
        "\"\"\"outputOffset = BatchNormalization()(outputOffset)\n",
        "outputOffset = Dropout(0.5)(outputOffset)\n",
        "outputOffset = Dense(16)(outputOffset)\"\"\"\n",
        "outputOffset = Dense(output_step_reshaped.shape[1], name=\"Offset\")(outputOffset)\n",
        "\n",
        "\n",
        "\n",
        "model = Model(inputs=[inputNotes_layer,inputStep_layer,  inputVolume_layer, inputDuration_layer], outputs=[outputNotes, outputOffset, outputVolume, outputDuration])\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=0.005)\n",
        "\n",
        "def mse_with_positive_pressure(y_true: tf.Tensor, y_pred: tf.Tensor):\n",
        "  mse = (y_true - y_pred) ** 2\n",
        "  positive_pressure = 10 * tf.maximum(-y_pred, 0.0)\n",
        "  return tf.reduce_mean(mse + positive_pressure)\n",
        "\n",
        "#Adam seems to be faster than RMSProp and learns better too\n",
        "model.compile(loss=[\"categorical_crossentropy\", mse_with_positive_pressure, \"categorical_crossentropy\", \"categorical_crossentropy\"], optimizer=optimizer, loss_weights=[0.8,1.0,0.05,0.5])"
      ],
      "metadata": {
        "id": "NyzHblQ7kfw0"
      },
      "execution_count": 99,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "id": "q_4pFN5EihPj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "cp_callback = keras.callbacks.ModelCheckpoint(\n",
        "    'model_weights_epoch.h5',  # Nom du fichier de sauvegarde avec un espace réservé pour le numéro de l'époque\n",
        "    save_best_only=True,  # Sauvegarder à chaque époque, pas seulement les meilleurs modèles\n",
        "    save_weights_only=True,  # Sauvegarder uniquement les poids, pas l'ensemble du modèle\n",
        "    verbose=1  # Afficher un message lors de la sauvegarde\n",
        "    )"
      ],
      "metadata": {
        "id": "YB2DV7zy3om5"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit([input_note_reshaped, input_step_reshaped,  input_volume_reshaped, input_duration_reshaped], [output_note_reshaped, output_step_reshaped, output_volume_reshaped, output_duration_reshaped], epochs=400, callbacks=[cp_callback], validation_split=0.1)"
      ],
      "metadata": {
        "id": "d7w5ODUnf8B8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "0c354030-1e89-4cea-a774-0c7d17fc975e"
      },
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/400\n",
            "42/44 [===========================>..] - ETA: 0s - loss: 5.0362 - Note_loss: 3.5295 - Offset_loss: 0.3876 - Volume_loss: 1.3863 - Duration_loss: 1.4180\n",
            "Epoch 1: val_loss did not improve from 2.97038\n",
            "44/44 [==============================] - 42s 649ms/step - loss: 5.0222 - Note_loss: 3.5283 - Offset_loss: 0.3865 - Volume_loss: 1.3800 - Duration_loss: 1.4055 - val_loss: 5.7692 - val_Note_loss: 3.5685 - val_Offset_loss: 0.4220 - val_Volume_loss: 1.2029 - val_Duration_loss: 2.1194\n",
            "Epoch 2/400\n",
            "44/44 [==============================] - ETA: 0s - loss: 4.6200 - Note_loss: 3.2676 - Offset_loss: 0.3140 - Volume_loss: 1.2178 - Duration_loss: 1.2758\n",
            "Epoch 2: val_loss did not improve from 2.97038\n",
            "44/44 [==============================] - 1s 31ms/step - loss: 4.6200 - Note_loss: 3.2676 - Offset_loss: 0.3140 - Volume_loss: 1.2178 - Duration_loss: 1.2758 - val_loss: 5.6887 - val_Note_loss: 3.5071 - val_Offset_loss: 0.4266 - val_Volume_loss: 1.1426 - val_Duration_loss: 2.1031\n",
            "Epoch 3/400\n",
            "43/44 [============================>.] - ETA: 0s - loss: 4.4596 - Note_loss: 3.1651 - Offset_loss: 0.3217 - Volume_loss: 1.1708 - Duration_loss: 1.2199\n",
            "Epoch 3: val_loss did not improve from 2.97038\n",
            "44/44 [==============================] - 1s 32ms/step - loss: 4.4651 - Note_loss: 3.1706 - Offset_loss: 0.3198 - Volume_loss: 1.1656 - Duration_loss: 1.2202 - val_loss: 5.7015 - val_Note_loss: 3.4706 - val_Offset_loss: 0.3527 - val_Volume_loss: 1.1069 - val_Duration_loss: 2.1579\n",
            "Epoch 4/400\n",
            "43/44 [============================>.] - ETA: 0s - loss: 4.3276 - Note_loss: 3.0871 - Offset_loss: 0.3233 - Volume_loss: 1.1445 - Duration_loss: 1.1671\n",
            "Epoch 4: val_loss did not improve from 2.97038\n",
            "44/44 [==============================] - 1s 21ms/step - loss: 4.3280 - Note_loss: 3.0865 - Offset_loss: 0.3212 - Volume_loss: 1.1421 - Duration_loss: 1.1683 - val_loss: 6.0342 - val_Note_loss: 3.4966 - val_Offset_loss: 0.3876 - val_Volume_loss: 1.1840 - val_Duration_loss: 2.4590\n",
            "Epoch 5/400\n",
            "43/44 [============================>.] - ETA: 0s - loss: 4.2761 - Note_loss: 3.0077 - Offset_loss: 0.2948 - Volume_loss: 1.1165 - Duration_loss: 1.1979\n",
            "Epoch 5: val_loss did not improve from 2.97038\n",
            "44/44 [==============================] - 1s 22ms/step - loss: 4.2716 - Note_loss: 3.0111 - Offset_loss: 0.3038 - Volume_loss: 1.1142 - Duration_loss: 1.1896 - val_loss: 5.6485 - val_Note_loss: 3.4023 - val_Offset_loss: 0.3403 - val_Volume_loss: 1.1545 - val_Duration_loss: 2.1715\n",
            "Epoch 6/400\n",
            "42/44 [===========================>..] - ETA: 0s - loss: 4.1030 - Note_loss: 2.9357 - Offset_loss: 0.3327 - Volume_loss: 1.0653 - Duration_loss: 1.0974\n",
            "Epoch 6: val_loss did not improve from 2.97038\n",
            "44/44 [==============================] - 1s 23ms/step - loss: 4.1063 - Note_loss: 2.9374 - Offset_loss: 0.3411 - Volume_loss: 1.0775 - Duration_loss: 1.0979 - val_loss: 5.4965 - val_Note_loss: 3.3283 - val_Offset_loss: 0.3696 - val_Volume_loss: 1.1506 - val_Duration_loss: 2.0922\n",
            "Epoch 7/400\n",
            "42/44 [===========================>..] - ETA: 0s - loss: 3.9536 - Note_loss: 2.8158 - Offset_loss: 0.2831 - Volume_loss: 1.0825 - Duration_loss: 1.0695\n",
            "Epoch 7: val_loss did not improve from 2.97038\n",
            "44/44 [==============================] - 1s 23ms/step - loss: 3.9713 - Note_loss: 2.8256 - Offset_loss: 0.2921 - Volume_loss: 1.0869 - Duration_loss: 1.0767 - val_loss: 5.1838 - val_Note_loss: 3.1784 - val_Offset_loss: 0.3080 - val_Volume_loss: 1.0849 - val_Duration_loss: 1.9357\n",
            "Epoch 8/400\n",
            "43/44 [============================>.] - ETA: 0s - loss: 3.8024 - Note_loss: 2.7279 - Offset_loss: 0.2827 - Volume_loss: 1.0750 - Duration_loss: 1.0066\n",
            "Epoch 8: val_loss did not improve from 2.97038\n",
            "44/44 [==============================] - 1s 21ms/step - loss: 3.8001 - Note_loss: 2.7202 - Offset_loss: 0.2854 - Volume_loss: 1.0727 - Duration_loss: 1.0120 - val_loss: 5.0658 - val_Note_loss: 3.0227 - val_Offset_loss: 0.2978 - val_Volume_loss: 1.0821 - val_Duration_loss: 1.9741\n",
            "Epoch 9/400\n",
            "43/44 [============================>.] - ETA: 0s - loss: 3.7268 - Note_loss: 2.6729 - Offset_loss: 0.2765 - Volume_loss: 1.0548 - Duration_loss: 0.9874\n",
            "Epoch 9: val_loss did not improve from 2.97038\n",
            "44/44 [==============================] - 1s 22ms/step - loss: 3.7295 - Note_loss: 2.6732 - Offset_loss: 0.2742 - Volume_loss: 1.0551 - Duration_loss: 0.9899 - val_loss: 5.1981 - val_Note_loss: 2.9298 - val_Offset_loss: 0.3057 - val_Volume_loss: 1.0216 - val_Duration_loss: 2.2019\n",
            "Epoch 10/400\n",
            "43/44 [============================>.] - ETA: 0s - loss: 3.5443 - Note_loss: 2.5271 - Offset_loss: 0.2863 - Volume_loss: 1.0277 - Duration_loss: 0.9515\n",
            "Epoch 10: val_loss did not improve from 2.97038\n",
            "44/44 [==============================] - 1s 21ms/step - loss: 3.5512 - Note_loss: 2.5341 - Offset_loss: 0.2865 - Volume_loss: 1.0244 - Duration_loss: 0.9516 - val_loss: 5.0487 - val_Note_loss: 2.9295 - val_Offset_loss: 0.3275 - val_Volume_loss: 0.9951 - val_Duration_loss: 2.0530\n",
            "Epoch 11/400\n",
            "43/44 [============================>.] - ETA: 0s - loss: 3.5123 - Note_loss: 2.5000 - Offset_loss: 0.2830 - Volume_loss: 1.0139 - Duration_loss: 0.9475\n",
            "Epoch 11: val_loss did not improve from 2.97038\n",
            "44/44 [==============================] - 1s 22ms/step - loss: 3.5167 - Note_loss: 2.5064 - Offset_loss: 0.2794 - Volume_loss: 1.0147 - Duration_loss: 0.9456 - val_loss: 4.7699 - val_Note_loss: 2.7799 - val_Offset_loss: 0.3373 - val_Volume_loss: 1.1008 - val_Duration_loss: 1.9182\n",
            "Epoch 12/400\n",
            "43/44 [============================>.] - ETA: 0s - loss: 3.3070 - Note_loss: 2.3457 - Offset_loss: 0.2619 - Volume_loss: 1.0177 - Duration_loss: 0.8972\n",
            "Epoch 12: val_loss did not improve from 2.97038\n",
            "44/44 [==============================] - 1s 21ms/step - loss: 3.3165 - Note_loss: 2.3491 - Offset_loss: 0.2606 - Volume_loss: 1.0146 - Duration_loss: 0.9036 - val_loss: 4.9806 - val_Note_loss: 2.6351 - val_Offset_loss: 0.3354 - val_Volume_loss: 1.1210 - val_Duration_loss: 2.2726\n",
            "Epoch 13/400\n",
            "43/44 [============================>.] - ETA: 0s - loss: 3.1560 - Note_loss: 2.2698 - Offset_loss: 0.2729 - Volume_loss: 0.9615 - Duration_loss: 0.8245\n",
            "Epoch 13: val_loss did not improve from 2.97038\n",
            "44/44 [==============================] - 1s 21ms/step - loss: 3.1622 - Note_loss: 2.2742 - Offset_loss: 0.2703 - Volume_loss: 0.9642 - Duration_loss: 0.8263 - val_loss: 4.8039 - val_Note_loss: 2.6691 - val_Offset_loss: 0.2835 - val_Volume_loss: 1.1460 - val_Duration_loss: 2.0634\n",
            "Epoch 14/400\n",
            "43/44 [============================>.] - ETA: 0s - loss: 3.1194 - Note_loss: 2.2760 - Offset_loss: 0.2660 - Volume_loss: 0.9607 - Duration_loss: 0.7822\n",
            "Epoch 14: val_loss did not improve from 2.97038\n",
            "44/44 [==============================] - 1s 32ms/step - loss: 3.1285 - Note_loss: 2.2813 - Offset_loss: 0.2647 - Volume_loss: 0.9639 - Duration_loss: 0.7858 - val_loss: 4.4575 - val_Note_loss: 2.7402 - val_Offset_loss: 0.3122 - val_Volume_loss: 1.0448 - val_Duration_loss: 1.6495\n",
            "Epoch 15/400\n",
            "42/44 [===========================>..] - ETA: 0s - loss: 3.0174 - Note_loss: 2.1848 - Offset_loss: 0.2529 - Volume_loss: 0.9437 - Duration_loss: 0.7727\n",
            "Epoch 15: val_loss did not improve from 2.97038\n",
            "44/44 [==============================] - 1s 33ms/step - loss: 3.0088 - Note_loss: 2.1794 - Offset_loss: 0.2483 - Volume_loss: 0.9449 - Duration_loss: 0.7698 - val_loss: 4.3701 - val_Note_loss: 2.5243 - val_Offset_loss: 0.3041 - val_Volume_loss: 1.0430 - val_Duration_loss: 1.7784\n",
            "Epoch 16/400\n",
            "42/44 [===========================>..] - ETA: 0s - loss: 2.8797 - Note_loss: 2.0894 - Offset_loss: 0.2518 - Volume_loss: 0.8970 - Duration_loss: 0.7329\n",
            "Epoch 16: val_loss did not improve from 2.97038\n",
            "44/44 [==============================] - 1s 21ms/step - loss: 2.8930 - Note_loss: 2.0899 - Offset_loss: 0.2591 - Volume_loss: 0.9026 - Duration_loss: 0.7450 - val_loss: 4.5369 - val_Note_loss: 2.4956 - val_Offset_loss: 0.2471 - val_Volume_loss: 1.1665 - val_Duration_loss: 1.9706\n",
            "Epoch 17/400\n",
            "42/44 [===========================>..] - ETA: 0s - loss: 2.7600 - Note_loss: 2.0367 - Offset_loss: 0.2662 - Volume_loss: 0.9049 - Duration_loss: 0.6648\n",
            "Epoch 17: val_loss did not improve from 2.97038\n",
            "44/44 [==============================] - 1s 23ms/step - loss: 2.7610 - Note_loss: 2.0291 - Offset_loss: 0.2616 - Volume_loss: 0.9023 - Duration_loss: 0.6737 - val_loss: 4.4931 - val_Note_loss: 2.4238 - val_Offset_loss: 0.2893 - val_Volume_loss: 1.0612 - val_Duration_loss: 2.0019\n",
            "Epoch 18/400\n",
            "43/44 [============================>.] - ETA: 0s - loss: 2.6973 - Note_loss: 1.9566 - Offset_loss: 0.2477 - Volume_loss: 0.9044 - Duration_loss: 0.6830\n",
            "Epoch 18: val_loss did not improve from 2.97038\n",
            "44/44 [==============================] - 1s 22ms/step - loss: 2.6880 - Note_loss: 1.9487 - Offset_loss: 0.2513 - Volume_loss: 0.9021 - Duration_loss: 0.6817 - val_loss: 4.9920 - val_Note_loss: 2.3472 - val_Offset_loss: 0.2794 - val_Volume_loss: 1.0114 - val_Duration_loss: 2.5803\n",
            "Epoch 19/400\n",
            "43/44 [============================>.] - ETA: 0s - loss: 2.5724 - Note_loss: 1.8796 - Offset_loss: 0.2446 - Volume_loss: 0.8792 - Duration_loss: 0.6366\n",
            "Epoch 19: val_loss did not improve from 2.97038\n",
            "44/44 [==============================] - 1s 21ms/step - loss: 2.5643 - Note_loss: 1.8743 - Offset_loss: 0.2482 - Volume_loss: 0.8794 - Duration_loss: 0.6336 - val_loss: 4.5732 - val_Note_loss: 2.3291 - val_Offset_loss: 0.2853 - val_Volume_loss: 1.0816 - val_Duration_loss: 2.1757\n",
            "Epoch 20/400\n",
            "42/44 [===========================>..] - ETA: 0s - loss: 2.4328 - Note_loss: 1.8114 - Offset_loss: 0.2597 - Volume_loss: 0.8673 - Duration_loss: 0.5650\n",
            "Epoch 20: val_loss did not improve from 2.97038\n",
            "44/44 [==============================] - 1s 22ms/step - loss: 2.4384 - Note_loss: 1.8131 - Offset_loss: 0.2594 - Volume_loss: 0.8608 - Duration_loss: 0.5693 - val_loss: 4.2667 - val_Note_loss: 2.1885 - val_Offset_loss: 0.2648 - val_Volume_loss: 1.0506 - val_Duration_loss: 2.0125\n",
            "Epoch 21/400\n",
            "43/44 [============================>.] - ETA: 0s - loss: 2.4153 - Note_loss: 1.7820 - Offset_loss: 0.2431 - Volume_loss: 0.8581 - Duration_loss: 0.5783\n",
            "Epoch 21: val_loss did not improve from 2.97038\n",
            "44/44 [==============================] - 1s 22ms/step - loss: 2.4162 - Note_loss: 1.7834 - Offset_loss: 0.2488 - Volume_loss: 0.8583 - Duration_loss: 0.5774 - val_loss: 4.8894 - val_Note_loss: 2.5416 - val_Offset_loss: 0.2926 - val_Volume_loss: 1.0278 - val_Duration_loss: 2.2817\n",
            "Epoch 22/400\n",
            "42/44 [===========================>..] - ETA: 0s - loss: 2.2984 - Note_loss: 1.7278 - Offset_loss: 0.2538 - Volume_loss: 0.8473 - Duration_loss: 0.5156\n",
            "Epoch 22: val_loss did not improve from 2.97038\n",
            "44/44 [==============================] - 1s 22ms/step - loss: 2.2918 - Note_loss: 1.7198 - Offset_loss: 0.2611 - Volume_loss: 0.8462 - Duration_loss: 0.5166 - val_loss: 4.3303 - val_Note_loss: 2.1061 - val_Offset_loss: 0.2954 - val_Volume_loss: 0.9638 - val_Duration_loss: 2.1612\n",
            "Epoch 23/400\n",
            "43/44 [============================>.] - ETA: 0s - loss: 2.2302 - Note_loss: 1.6472 - Offset_loss: 0.2516 - Volume_loss: 0.8469 - Duration_loss: 0.5280\n",
            "Epoch 23: val_loss did not improve from 2.97038\n",
            "44/44 [==============================] - 1s 27ms/step - loss: 2.2362 - Note_loss: 1.6495 - Offset_loss: 0.2485 - Volume_loss: 0.8456 - Duration_loss: 0.5319 - val_loss: 4.6877 - val_Note_loss: 2.4168 - val_Offset_loss: 0.2942 - val_Volume_loss: 1.0912 - val_Duration_loss: 2.2016\n",
            "Epoch 24/400\n",
            "43/44 [============================>.] - ETA: 0s - loss: 2.0785 - Note_loss: 1.5592 - Offset_loss: 0.2500 - Volume_loss: 0.8255 - Duration_loss: 0.4655\n",
            "Epoch 24: val_loss did not improve from 2.97038\n",
            "44/44 [==============================] - 1s 22ms/step - loss: 2.0681 - Note_loss: 1.5501 - Offset_loss: 0.2470 - Volume_loss: 0.8219 - Duration_loss: 0.4645 - val_loss: 4.1876 - val_Note_loss: 2.2259 - val_Offset_loss: 0.2425 - val_Volume_loss: 0.9720 - val_Duration_loss: 1.9010\n",
            "Epoch 25/400\n",
            "44/44 [==============================] - ETA: 0s - loss: 2.0502 - Note_loss: 1.5541 - Offset_loss: 0.2627 - Volume_loss: 0.8227 - Duration_loss: 0.4418\n",
            "Epoch 25: val_loss did not improve from 2.97038\n",
            "44/44 [==============================] - 1s 26ms/step - loss: 2.0502 - Note_loss: 1.5541 - Offset_loss: 0.2627 - Volume_loss: 0.8227 - Duration_loss: 0.4418 - val_loss: 4.4121 - val_Note_loss: 2.0981 - val_Offset_loss: 0.2903 - val_Volume_loss: 1.0271 - val_Duration_loss: 2.2481\n",
            "Epoch 26/400\n",
            "43/44 [============================>.] - ETA: 0s - loss: 1.8993 - Note_loss: 1.4435 - Offset_loss: 0.2626 - Volume_loss: 0.8021 - Duration_loss: 0.4026\n",
            "Epoch 26: val_loss did not improve from 2.97038\n",
            "44/44 [==============================] - 2s 35ms/step - loss: 1.8988 - Note_loss: 1.4433 - Offset_loss: 0.2587 - Volume_loss: 0.8036 - Duration_loss: 0.4023 - val_loss: 4.6563 - val_Note_loss: 2.2146 - val_Offset_loss: 0.2683 - val_Volume_loss: 1.0450 - val_Duration_loss: 2.3760\n",
            "Epoch 27/400\n",
            "42/44 [===========================>..] - ETA: 0s - loss: 1.8275 - Note_loss: 1.3963 - Offset_loss: 0.2531 - Volume_loss: 0.8034 - Duration_loss: 0.3783\n",
            "Epoch 27: val_loss did not improve from 2.97038\n",
            "44/44 [==============================] - 1s 26ms/step - loss: 1.8311 - Note_loss: 1.3997 - Offset_loss: 0.2581 - Volume_loss: 0.8016 - Duration_loss: 0.3784 - val_loss: 4.4877 - val_Note_loss: 2.1903 - val_Offset_loss: 0.2894 - val_Volume_loss: 0.9629 - val_Duration_loss: 2.2347\n",
            "Epoch 28/400\n",
            "43/44 [============================>.] - ETA: 0s - loss: 1.6820 - Note_loss: 1.2634 - Offset_loss: 0.2548 - Volume_loss: 0.7603 - Duration_loss: 0.3679\n",
            "Epoch 28: val_loss did not improve from 2.97038\n",
            "44/44 [==============================] - 1s 22ms/step - loss: 1.6955 - Note_loss: 1.2699 - Offset_loss: 0.2526 - Volume_loss: 0.7658 - Duration_loss: 0.3747 - val_loss: 5.3302 - val_Note_loss: 2.5668 - val_Offset_loss: 0.2823 - val_Volume_loss: 1.0035 - val_Duration_loss: 2.6991\n",
            "Epoch 29/400\n",
            "42/44 [===========================>..] - ETA: 0s - loss: 1.7164 - Note_loss: 1.3189 - Offset_loss: 0.2427 - Volume_loss: 0.7734 - Duration_loss: 0.3467\n",
            "Epoch 29: val_loss did not improve from 2.97038\n",
            "44/44 [==============================] - 1s 22ms/step - loss: 1.7098 - Note_loss: 1.3174 - Offset_loss: 0.2451 - Volume_loss: 0.7696 - Duration_loss: 0.3417 - val_loss: 4.7798 - val_Note_loss: 2.2832 - val_Offset_loss: 0.2790 - val_Volume_loss: 0.9005 - val_Duration_loss: 2.4376\n",
            "Epoch 30/400\n",
            "43/44 [============================>.] - ETA: 0s - loss: 1.6960 - Note_loss: 1.3052 - Offset_loss: 0.2406 - Volume_loss: 0.7731 - Duration_loss: 0.3402\n",
            "Epoch 30: val_loss did not improve from 2.97038\n",
            "44/44 [==============================] - 1s 22ms/step - loss: 1.6840 - Note_loss: 1.2965 - Offset_loss: 0.2403 - Volume_loss: 0.7728 - Duration_loss: 0.3368 - val_loss: 5.0729 - val_Note_loss: 2.4617 - val_Offset_loss: 0.2955 - val_Volume_loss: 1.0912 - val_Duration_loss: 2.5418\n",
            "Epoch 31/400\n",
            "43/44 [============================>.] - ETA: 0s - loss: 1.5172 - Note_loss: 1.1601 - Offset_loss: 0.2422 - Volume_loss: 0.7472 - Duration_loss: 0.3077\n",
            "Epoch 31: val_loss did not improve from 2.97038\n",
            "44/44 [==============================] - 1s 23ms/step - loss: 1.5138 - Note_loss: 1.1605 - Offset_loss: 0.2456 - Volume_loss: 0.7498 - Duration_loss: 0.3035 - val_loss: 5.3673 - val_Note_loss: 2.6361 - val_Offset_loss: 0.3139 - val_Volume_loss: 0.9863 - val_Duration_loss: 2.6662\n",
            "Epoch 32/400\n",
            "43/44 [============================>.] - ETA: 0s - loss: 1.4095 - Note_loss: 1.0614 - Offset_loss: 0.2518 - Volume_loss: 0.7267 - Duration_loss: 0.2992\n",
            "Epoch 32: val_loss did not improve from 2.97038\n",
            "44/44 [==============================] - 1s 22ms/step - loss: 1.4029 - Note_loss: 1.0576 - Offset_loss: 0.2489 - Volume_loss: 0.7252 - Duration_loss: 0.2966 - val_loss: 4.7400 - val_Note_loss: 2.3792 - val_Offset_loss: 0.2846 - val_Volume_loss: 0.9501 - val_Duration_loss: 2.2990\n",
            "Epoch 33/400\n",
            "43/44 [============================>.] - ETA: 0s - loss: 1.3814 - Note_loss: 1.0406 - Offset_loss: 0.2445 - Volume_loss: 0.7277 - Duration_loss: 0.2921\n",
            "Epoch 33: val_loss did not improve from 2.97038\n",
            "44/44 [==============================] - 1s 22ms/step - loss: 1.4020 - Note_loss: 1.0569 - Offset_loss: 0.2440 - Volume_loss: 0.7322 - Duration_loss: 0.2962 - val_loss: 4.9219 - val_Note_loss: 2.5728 - val_Offset_loss: 0.2841 - val_Volume_loss: 0.9527 - val_Duration_loss: 2.2872\n",
            "Epoch 34/400\n",
            "43/44 [============================>.] - ETA: 0s - loss: 1.3118 - Note_loss: 0.9860 - Offset_loss: 0.2531 - Volume_loss: 0.7250 - Duration_loss: 0.2770\n",
            "Epoch 34: val_loss did not improve from 2.97038\n",
            "44/44 [==============================] - 1s 22ms/step - loss: 1.3157 - Note_loss: 0.9883 - Offset_loss: 0.2524 - Volume_loss: 0.7341 - Duration_loss: 0.2781 - val_loss: 5.3304 - val_Note_loss: 2.6071 - val_Offset_loss: 0.3010 - val_Volume_loss: 0.8991 - val_Duration_loss: 2.6634\n",
            "Epoch 35/400\n",
            "43/44 [============================>.] - ETA: 0s - loss: 1.2803 - Note_loss: 0.9927 - Offset_loss: 0.2501 - Volume_loss: 0.6979 - Duration_loss: 0.2402\n",
            "Epoch 35: val_loss did not improve from 2.97038\n",
            "44/44 [==============================] - 1s 23ms/step - loss: 1.2752 - Note_loss: 0.9843 - Offset_loss: 0.2468 - Volume_loss: 0.6942 - Duration_loss: 0.2438 - val_loss: 5.2636 - val_Note_loss: 2.6354 - val_Offset_loss: 0.2845 - val_Volume_loss: 0.9848 - val_Duration_loss: 2.5648\n",
            "Epoch 36/400\n",
            "43/44 [============================>.] - ETA: 0s - loss: 1.2270 - Note_loss: 0.9128 - Offset_loss: 0.2502 - Volume_loss: 0.6940 - Duration_loss: 0.2670\n",
            "Epoch 36: val_loss did not improve from 2.97038\n",
            "44/44 [==============================] - 1s 22ms/step - loss: 1.2173 - Note_loss: 0.9060 - Offset_loss: 0.2523 - Volume_loss: 0.6933 - Duration_loss: 0.2640 - val_loss: 5.2461 - val_Note_loss: 2.7750 - val_Offset_loss: 0.2680 - val_Volume_loss: 0.9994 - val_Duration_loss: 2.4078\n",
            "Epoch 37/400\n",
            "43/44 [============================>.] - ETA: 0s - loss: 1.2556 - Note_loss: 0.9447 - Offset_loss: 0.2542 - Volume_loss: 0.7048 - Duration_loss: 0.2630\n",
            "Epoch 37: val_loss did not improve from 2.97038\n",
            "44/44 [==============================] - 1s 30ms/step - loss: 1.2540 - Note_loss: 0.9430 - Offset_loss: 0.2537 - Volume_loss: 0.7012 - Duration_loss: 0.2633 - val_loss: 5.2076 - val_Note_loss: 2.7012 - val_Offset_loss: 0.2618 - val_Volume_loss: 1.0474 - val_Duration_loss: 2.4409\n",
            "Epoch 38/400\n",
            "43/44 [============================>.] - ETA: 0s - loss: 1.1691 - Note_loss: 0.9028 - Offset_loss: 0.2490 - Volume_loss: 0.7025 - Duration_loss: 0.2188\n",
            "Epoch 38: val_loss did not improve from 2.97038\n",
            "44/44 [==============================] - 2s 35ms/step - loss: 1.1799 - Note_loss: 0.9104 - Offset_loss: 0.2588 - Volume_loss: 0.7094 - Duration_loss: 0.2211 - val_loss: 5.2448 - val_Note_loss: 2.9150 - val_Offset_loss: 0.2796 - val_Volume_loss: 1.1038 - val_Duration_loss: 2.2606\n",
            "Epoch 39/400\n",
            "44/44 [==============================] - ETA: 0s - loss: 1.0186 - Note_loss: 0.7584 - Offset_loss: 0.2443 - Volume_loss: 0.6544 - Duration_loss: 0.2153\n",
            "Epoch 39: val_loss did not improve from 2.97038\n",
            "44/44 [==============================] - 1s 23ms/step - loss: 1.0186 - Note_loss: 0.7584 - Offset_loss: 0.2443 - Volume_loss: 0.6544 - Duration_loss: 0.2153 - val_loss: 5.4613 - val_Note_loss: 3.0078 - val_Offset_loss: 0.2582 - val_Volume_loss: 1.1329 - val_Duration_loss: 2.3839\n",
            "Epoch 40/400\n",
            "42/44 [===========================>..] - ETA: 0s - loss: 1.0825 - Note_loss: 0.8225 - Offset_loss: 0.2400 - Volume_loss: 0.6709 - Duration_loss: 0.2144\n",
            "Epoch 40: val_loss did not improve from 2.97038\n",
            "44/44 [==============================] - 1s 21ms/step - loss: 1.0808 - Note_loss: 0.8234 - Offset_loss: 0.2394 - Volume_loss: 0.6751 - Duration_loss: 0.2117 - val_loss: 5.1723 - val_Note_loss: 2.8140 - val_Offset_loss: 0.2678 - val_Volume_loss: 1.0313 - val_Duration_loss: 2.2933\n",
            "Epoch 41/400\n",
            "43/44 [============================>.] - ETA: 0s - loss: 0.9595 - Note_loss: 0.7206 - Offset_loss: 0.2373 - Volume_loss: 0.6611 - Duration_loss: 0.1940\n",
            "Epoch 41: val_loss did not improve from 2.97038\n",
            "44/44 [==============================] - 1s 22ms/step - loss: 0.9639 - Note_loss: 0.7236 - Offset_loss: 0.2356 - Volume_loss: 0.6592 - Duration_loss: 0.1956 - val_loss: 5.3595 - val_Note_loss: 2.8817 - val_Offset_loss: 0.2629 - val_Volume_loss: 1.0620 - val_Duration_loss: 2.4115\n",
            "Epoch 42/400\n",
            "43/44 [============================>.] - ETA: 0s - loss: 0.8894 - Note_loss: 0.6767 - Offset_loss: 0.2574 - Volume_loss: 0.6523 - Duration_loss: 0.1673\n",
            "Epoch 42: val_loss did not improve from 2.97038\n",
            "44/44 [==============================] - 1s 23ms/step - loss: 0.8862 - Note_loss: 0.6717 - Offset_loss: 0.2597 - Volume_loss: 0.6541 - Duration_loss: 0.1688 - val_loss: 5.4480 - val_Note_loss: 3.0457 - val_Offset_loss: 0.2550 - val_Volume_loss: 1.1862 - val_Duration_loss: 2.3302\n",
            "Epoch 43/400\n",
            "43/44 [============================>.] - ETA: 0s - loss: 0.9131 - Note_loss: 0.6844 - Offset_loss: 0.2370 - Volume_loss: 0.6854 - Duration_loss: 0.1825\n",
            "Epoch 43: val_loss did not improve from 2.97038\n",
            "44/44 [==============================] - 1s 22ms/step - loss: 0.9046 - Note_loss: 0.6782 - Offset_loss: 0.2435 - Volume_loss: 0.6800 - Duration_loss: 0.1802 - val_loss: 5.6845 - val_Note_loss: 3.1168 - val_Offset_loss: 0.2800 - val_Volume_loss: 1.0589 - val_Duration_loss: 2.5007\n",
            "Epoch 44/400\n",
            "43/44 [============================>.] - ETA: 0s - loss: 0.8802 - Note_loss: 0.6627 - Offset_loss: 0.2471 - Volume_loss: 0.6645 - Duration_loss: 0.1719\n",
            "Epoch 44: val_loss did not improve from 2.97038\n",
            "44/44 [==============================] - 1s 23ms/step - loss: 0.8802 - Note_loss: 0.6657 - Offset_loss: 0.2449 - Volume_loss: 0.6598 - Duration_loss: 0.1693 - val_loss: 5.5920 - val_Note_loss: 3.0381 - val_Offset_loss: 0.2679 - val_Volume_loss: 1.1194 - val_Duration_loss: 2.4845\n",
            "Epoch 45/400\n",
            "42/44 [===========================>..] - ETA: 0s - loss: 0.8192 - Note_loss: 0.6291 - Offset_loss: 0.2465 - Volume_loss: 0.6555 - Duration_loss: 0.1449\n",
            "Epoch 45: val_loss did not improve from 2.97038\n",
            "44/44 [==============================] - 1s 23ms/step - loss: 0.8148 - Note_loss: 0.6287 - Offset_loss: 0.2444 - Volume_loss: 0.6533 - Duration_loss: 0.1412 - val_loss: 5.8711 - val_Note_loss: 3.0866 - val_Offset_loss: 0.3230 - val_Volume_loss: 1.0977 - val_Duration_loss: 2.7134\n",
            "Epoch 46/400\n",
            "42/44 [===========================>..] - ETA: 0s - loss: 0.8394 - Note_loss: 0.6502 - Offset_loss: 0.2535 - Volume_loss: 0.6369 - Duration_loss: 0.1447\n",
            "Epoch 46: val_loss did not improve from 2.97038\n",
            "44/44 [==============================] - 1s 23ms/step - loss: 0.8362 - Note_loss: 0.6466 - Offset_loss: 0.2481 - Volume_loss: 0.6348 - Duration_loss: 0.1455 - val_loss: 6.1762 - val_Note_loss: 3.3199 - val_Offset_loss: 0.2679 - val_Volume_loss: 1.1913 - val_Duration_loss: 2.7834\n",
            "Epoch 47/400\n",
            "43/44 [============================>.] - ETA: 0s - loss: 0.7746 - Note_loss: 0.5785 - Offset_loss: 0.2316 - Volume_loss: 0.6442 - Duration_loss: 0.1523\n",
            "Epoch 47: val_loss did not improve from 2.97038\n",
            "44/44 [==============================] - 1s 23ms/step - loss: 0.7728 - Note_loss: 0.5780 - Offset_loss: 0.2302 - Volume_loss: 0.6432 - Duration_loss: 0.1511 - val_loss: 6.2250 - val_Note_loss: 3.3554 - val_Offset_loss: 0.3009 - val_Volume_loss: 1.1825 - val_Duration_loss: 2.7955\n",
            "Epoch 48/400\n",
            "43/44 [============================>.] - ETA: 0s - loss: 0.8482 - Note_loss: 0.6405 - Offset_loss: 0.2334 - Volume_loss: 0.6413 - Duration_loss: 0.1640\n",
            "Epoch 48: val_loss did not improve from 2.97038\n",
            "44/44 [==============================] - 1s 23ms/step - loss: 0.8476 - Note_loss: 0.6423 - Offset_loss: 0.2372 - Volume_loss: 0.6415 - Duration_loss: 0.1614 - val_loss: 6.5358 - val_Note_loss: 3.3406 - val_Offset_loss: 0.3002 - val_Volume_loss: 1.1862 - val_Duration_loss: 3.1209\n",
            "Epoch 49/400\n",
            "44/44 [==============================] - ETA: 0s - loss: 0.7452 - Note_loss: 0.5813 - Offset_loss: 0.2340 - Volume_loss: 0.6444 - Duration_loss: 0.1200\n",
            "Epoch 49: val_loss did not improve from 2.97038\n",
            "44/44 [==============================] - 3s 59ms/step - loss: 0.7452 - Note_loss: 0.5813 - Offset_loss: 0.2340 - Volume_loss: 0.6444 - Duration_loss: 0.1200 - val_loss: 7.1986 - val_Note_loss: 3.7932 - val_Offset_loss: 0.2922 - val_Volume_loss: 1.2354 - val_Duration_loss: 3.3291\n",
            "Epoch 50/400\n",
            "43/44 [============================>.] - ETA: 0s - loss: 0.6680 - Note_loss: 0.5100 - Offset_loss: 0.2368 - Volume_loss: 0.6125 - Duration_loss: 0.1155\n",
            "Epoch 50: val_loss did not improve from 2.97038\n",
            "44/44 [==============================] - 2s 39ms/step - loss: 0.6687 - Note_loss: 0.5108 - Offset_loss: 0.2379 - Volume_loss: 0.6148 - Duration_loss: 0.1152 - val_loss: 7.5200 - val_Note_loss: 3.8636 - val_Offset_loss: 0.2671 - val_Volume_loss: 1.1388 - val_Duration_loss: 3.5862\n",
            "Epoch 51/400\n",
            "43/44 [============================>.] - ETA: 0s - loss: 0.6561 - Note_loss: 0.4730 - Offset_loss: 0.2299 - Volume_loss: 0.6263 - Duration_loss: 0.1402\n",
            "Epoch 51: val_loss did not improve from 2.97038\n",
            "44/44 [==============================] - 1s 34ms/step - loss: 0.6557 - Note_loss: 0.4749 - Offset_loss: 0.2291 - Volume_loss: 0.6254 - Duration_loss: 0.1381 - val_loss: 7.0990 - val_Note_loss: 3.7042 - val_Offset_loss: 0.2810 - val_Volume_loss: 1.1120 - val_Duration_loss: 3.3251\n",
            "Epoch 52/400\n",
            "42/44 [===========================>..] - ETA: 0s - loss: 0.5560 - Note_loss: 0.4176 - Offset_loss: 0.2345 - Volume_loss: 0.5879 - Duration_loss: 0.0973\n",
            "Epoch 52: val_loss did not improve from 2.97038\n",
            "44/44 [==============================] - 1s 22ms/step - loss: 0.5628 - Note_loss: 0.4234 - Offset_loss: 0.2336 - Volume_loss: 0.5882 - Duration_loss: 0.0983 - val_loss: 7.6813 - val_Note_loss: 3.8828 - val_Offset_loss: 0.2876 - val_Volume_loss: 1.0964 - val_Duration_loss: 3.7293\n",
            "Epoch 53/400\n",
            "42/44 [===========================>..] - ETA: 0s - loss: 0.6235 - Note_loss: 0.4523 - Offset_loss: 0.2211 - Volume_loss: 0.6302 - Duration_loss: 0.1286\n",
            "Epoch 53: val_loss did not improve from 2.97038\n",
            "44/44 [==============================] - 1s 23ms/step - loss: 0.6270 - Note_loss: 0.4541 - Offset_loss: 0.2287 - Volume_loss: 0.6221 - Duration_loss: 0.1304 - val_loss: 6.9492 - val_Note_loss: 3.7529 - val_Offset_loss: 0.2917 - val_Volume_loss: 1.1817 - val_Duration_loss: 3.1226\n",
            "Epoch 54/400\n",
            "43/44 [============================>.] - ETA: 0s - loss: 0.6804 - Note_loss: 0.4794 - Offset_loss: 0.2294 - Volume_loss: 0.6143 - Duration_loss: 0.1589\n",
            "Epoch 54: val_loss did not improve from 2.97038\n",
            "44/44 [==============================] - 1s 22ms/step - loss: 0.6924 - Note_loss: 0.4825 - Offset_loss: 0.2389 - Volume_loss: 0.6153 - Duration_loss: 0.1671 - val_loss: 7.1311 - val_Note_loss: 3.8417 - val_Offset_loss: 0.2915 - val_Volume_loss: 1.1202 - val_Duration_loss: 3.2189\n",
            "Epoch 55/400\n",
            "43/44 [============================>.] - ETA: 0s - loss: 0.5320 - Note_loss: 0.4038 - Offset_loss: 0.2279 - Volume_loss: 0.5976 - Duration_loss: 0.0869\n",
            "Epoch 55: val_loss did not improve from 2.97038\n",
            "44/44 [==============================] - 1s 22ms/step - loss: 0.5308 - Note_loss: 0.4031 - Offset_loss: 0.2332 - Volume_loss: 0.5994 - Duration_loss: 0.0861 - val_loss: 7.8187 - val_Note_loss: 4.2904 - val_Offset_loss: 0.2805 - val_Volume_loss: 1.1692 - val_Duration_loss: 3.4558\n",
            "Epoch 56/400\n",
            "42/44 [===========================>..] - ETA: 0s - loss: 0.5489 - Note_loss: 0.4096 - Offset_loss: 0.2351 - Volume_loss: 0.5850 - Duration_loss: 0.0983\n",
            "Epoch 56: val_loss did not improve from 2.97038\n",
            "44/44 [==============================] - 1s 23ms/step - loss: 0.5501 - Note_loss: 0.4094 - Offset_loss: 0.2341 - Volume_loss: 0.5882 - Duration_loss: 0.0996 - val_loss: 7.4541 - val_Note_loss: 3.9318 - val_Offset_loss: 0.2775 - val_Volume_loss: 1.1650 - val_Duration_loss: 3.4501\n",
            "Epoch 57/400\n",
            "42/44 [===========================>..] - ETA: 0s - loss: 0.5069 - Note_loss: 0.3725 - Offset_loss: 0.2321 - Volume_loss: 0.5802 - Duration_loss: 0.0937\n",
            "Epoch 57: val_loss did not improve from 2.97038\n",
            "44/44 [==============================] - 1s 22ms/step - loss: 0.5119 - Note_loss: 0.3793 - Offset_loss: 0.2364 - Volume_loss: 0.5792 - Duration_loss: 0.0919 - val_loss: 7.4600 - val_Note_loss: 4.0852 - val_Offset_loss: 0.3306 - val_Volume_loss: 1.1705 - val_Duration_loss: 3.2997\n",
            "Epoch 58/400\n",
            "43/44 [============================>.] - ETA: 0s - loss: 0.4648 - Note_loss: 0.3571 - Offset_loss: 0.2532 - Volume_loss: 0.5667 - Duration_loss: 0.0668\n",
            "Epoch 58: val_loss did not improve from 2.97038\n",
            "44/44 [==============================] - 1s 22ms/step - loss: 0.4712 - Note_loss: 0.3641 - Offset_loss: 0.2518 - Volume_loss: 0.5728 - Duration_loss: 0.0658 - val_loss: 8.2037 - val_Note_loss: 4.3532 - val_Offset_loss: 0.2835 - val_Volume_loss: 1.2433 - val_Duration_loss: 3.7741\n",
            "Epoch 59/400\n",
            "43/44 [============================>.] - ETA: 0s - loss: 0.4451 - Note_loss: 0.3360 - Offset_loss: 0.2314 - Volume_loss: 0.5757 - Duration_loss: 0.0688\n",
            "Epoch 59: val_loss did not improve from 2.97038\n",
            "44/44 [==============================] - 2s 36ms/step - loss: 0.4406 - Note_loss: 0.3327 - Offset_loss: 0.2343 - Volume_loss: 0.5743 - Duration_loss: 0.0675 - val_loss: 8.6331 - val_Note_loss: 4.4439 - val_Offset_loss: 0.3002 - val_Volume_loss: 1.3413 - val_Duration_loss: 4.1071\n",
            "Epoch 60/400\n",
            "42/44 [===========================>..] - ETA: 0s - loss: 0.5554 - Note_loss: 0.4000 - Offset_loss: 0.2470 - Volume_loss: 0.5781 - Duration_loss: 0.1142\n",
            "Epoch 60: val_loss did not improve from 2.97038\n",
            "44/44 [==============================] - 1s 30ms/step - loss: 0.5767 - Note_loss: 0.4139 - Offset_loss: 0.2425 - Volume_loss: 0.5890 - Duration_loss: 0.1212 - val_loss: 8.2107 - val_Note_loss: 4.2458 - val_Offset_loss: 0.2807 - val_Volume_loss: 1.2332 - val_Duration_loss: 3.8891\n",
            "Epoch 61/400\n",
            "42/44 [===========================>..] - ETA: 0s - loss: 0.5060 - Note_loss: 0.3477 - Offset_loss: 0.2420 - Volume_loss: 0.5907 - Duration_loss: 0.1167\n",
            "Epoch 61: val_loss did not improve from 2.97038\n",
            "44/44 [==============================] - 1s 23ms/step - loss: 0.5024 - Note_loss: 0.3478 - Offset_loss: 0.2400 - Volume_loss: 0.5937 - Duration_loss: 0.1129 - val_loss: 8.5232 - val_Note_loss: 4.4640 - val_Offset_loss: 0.3035 - val_Volume_loss: 1.2355 - val_Duration_loss: 3.9823\n",
            "Epoch 62/400\n",
            "42/44 [===========================>..] - ETA: 0s - loss: 0.5085 - Note_loss: 0.3787 - Offset_loss: 0.2379 - Volume_loss: 0.5604 - Duration_loss: 0.0899\n",
            "Epoch 62: val_loss did not improve from 2.97038\n",
            "44/44 [==============================] - 1s 23ms/step - loss: 0.5096 - Note_loss: 0.3793 - Offset_loss: 0.2345 - Volume_loss: 0.5659 - Duration_loss: 0.0903 - val_loss: 8.4311 - val_Note_loss: 4.6461 - val_Offset_loss: 0.2811 - val_Volume_loss: 1.1772 - val_Duration_loss: 3.7121\n",
            "Epoch 63/400\n",
            "42/44 [===========================>..] - ETA: 0s - loss: 0.4668 - Note_loss: 0.3478 - Offset_loss: 0.2425 - Volume_loss: 0.5473 - Duration_loss: 0.0795\n",
            "Epoch 63: val_loss did not improve from 2.97038\n",
            "44/44 [==============================] - 1s 23ms/step - loss: 0.4651 - Note_loss: 0.3489 - Offset_loss: 0.2390 - Volume_loss: 0.5549 - Duration_loss: 0.0764 - val_loss: 8.8627 - val_Note_loss: 4.8472 - val_Offset_loss: 0.2660 - val_Volume_loss: 1.2393 - val_Duration_loss: 3.9403\n",
            "Epoch 64/400\n",
            "42/44 [===========================>..] - ETA: 0s - loss: 0.4405 - Note_loss: 0.3305 - Offset_loss: 0.2323 - Volume_loss: 0.5818 - Duration_loss: 0.0693\n",
            "Epoch 64: val_loss did not improve from 2.97038\n",
            "44/44 [==============================] - 1s 22ms/step - loss: 0.4391 - Note_loss: 0.3286 - Offset_loss: 0.2379 - Volume_loss: 0.5786 - Duration_loss: 0.0697 - val_loss: 8.6600 - val_Note_loss: 4.7214 - val_Offset_loss: 0.2664 - val_Volume_loss: 1.1074 - val_Duration_loss: 3.8698\n",
            "Epoch 65/400\n",
            "44/44 [==============================] - ETA: 0s - loss: 0.4615 - Note_loss: 0.3213 - Offset_loss: 0.2345 - Volume_loss: 0.5607 - Duration_loss: 0.1004\n",
            "Epoch 65: val_loss did not improve from 2.97038\n",
            "44/44 [==============================] - 1s 23ms/step - loss: 0.4615 - Note_loss: 0.3213 - Offset_loss: 0.2345 - Volume_loss: 0.5607 - Duration_loss: 0.1004 - val_loss: 8.4083 - val_Note_loss: 4.6833 - val_Offset_loss: 0.2527 - val_Volume_loss: 1.1984 - val_Duration_loss: 3.6524\n",
            "Epoch 66/400\n",
            "43/44 [============================>.] - ETA: 0s - loss: 0.4649 - Note_loss: 0.3541 - Offset_loss: 0.2330 - Volume_loss: 0.5677 - Duration_loss: 0.0708\n",
            "Epoch 66: val_loss did not improve from 2.97038\n",
            "44/44 [==============================] - 1s 22ms/step - loss: 0.4675 - Note_loss: 0.3546 - Offset_loss: 0.2332 - Volume_loss: 0.5717 - Duration_loss: 0.0726 - val_loss: 9.2180 - val_Note_loss: 4.8236 - val_Offset_loss: 0.2883 - val_Volume_loss: 1.2551 - val_Duration_loss: 4.3172\n",
            "Epoch 67/400\n",
            "43/44 [============================>.] - ETA: 0s - loss: 0.4279 - Note_loss: 0.3198 - Offset_loss: 0.2410 - Volume_loss: 0.5856 - Duration_loss: 0.0668\n",
            "Epoch 67: val_loss did not improve from 2.97038\n",
            "44/44 [==============================] - 1s 23ms/step - loss: 0.4209 - Note_loss: 0.3140 - Offset_loss: 0.2392 - Volume_loss: 0.5843 - Duration_loss: 0.0657 - val_loss: 9.3158 - val_Note_loss: 4.8697 - val_Offset_loss: 0.2868 - val_Volume_loss: 1.3092 - val_Duration_loss: 4.3663\n",
            "Epoch 68/400\n",
            "43/44 [============================>.] - ETA: 0s - loss: 0.5208 - Note_loss: 0.3881 - Offset_loss: 0.2344 - Volume_loss: 0.5780 - Duration_loss: 0.0921\n",
            "Epoch 68: val_loss did not improve from 2.97038\n",
            "44/44 [==============================] - 1s 23ms/step - loss: 0.5198 - Note_loss: 0.3879 - Offset_loss: 0.2406 - Volume_loss: 0.5797 - Duration_loss: 0.0908 - val_loss: 8.3317 - val_Note_loss: 4.5075 - val_Offset_loss: 0.2846 - val_Volume_loss: 1.2192 - val_Duration_loss: 3.7490\n",
            "Epoch 69/400\n",
            "44/44 [==============================] - ETA: 0s - loss: 0.4579 - Note_loss: 0.3370 - Offset_loss: 0.2390 - Volume_loss: 0.5665 - Duration_loss: 0.0806\n",
            "Epoch 69: val_loss did not improve from 2.97038\n",
            "44/44 [==============================] - 1s 23ms/step - loss: 0.4579 - Note_loss: 0.3370 - Offset_loss: 0.2390 - Volume_loss: 0.5665 - Duration_loss: 0.0806 - val_loss: 7.6094 - val_Note_loss: 3.9552 - val_Offset_loss: 0.2801 - val_Volume_loss: 1.1976 - val_Duration_loss: 3.5803\n",
            "Epoch 70/400\n",
            "44/44 [==============================] - ETA: 0s - loss: 0.4530 - Note_loss: 0.3248 - Offset_loss: 0.2399 - Volume_loss: 0.5405 - Duration_loss: 0.0891\n",
            "Epoch 70: val_loss did not improve from 2.97038\n",
            "44/44 [==============================] - 1s 28ms/step - loss: 0.4530 - Note_loss: 0.3248 - Offset_loss: 0.2399 - Volume_loss: 0.5405 - Duration_loss: 0.0891 - val_loss: 8.9952 - val_Note_loss: 4.9281 - val_Offset_loss: 0.2860 - val_Volume_loss: 1.2785 - val_Duration_loss: 3.9889\n",
            "Epoch 71/400\n",
            "44/44 [==============================] - ETA: 0s - loss: 0.4096 - Note_loss: 0.2891 - Offset_loss: 0.2375 - Volume_loss: 0.5466 - Duration_loss: 0.0812\n",
            "Epoch 71: val_loss did not improve from 2.97038\n",
            "44/44 [==============================] - 2s 47ms/step - loss: 0.4096 - Note_loss: 0.2891 - Offset_loss: 0.2375 - Volume_loss: 0.5466 - Duration_loss: 0.0812 - val_loss: 9.0117 - val_Note_loss: 4.8782 - val_Offset_loss: 0.2782 - val_Volume_loss: 1.3142 - val_Duration_loss: 4.0539\n",
            "Epoch 72/400\n",
            "43/44 [============================>.] - ETA: 0s - loss: 0.3427 - Note_loss: 0.2477 - Offset_loss: 0.2325 - Volume_loss: 0.5539 - Duration_loss: 0.0557\n",
            "Epoch 72: val_loss did not improve from 2.97038\n",
            "44/44 [==============================] - 1s 28ms/step - loss: 0.3454 - Note_loss: 0.2502 - Offset_loss: 0.2315 - Volume_loss: 0.5579 - Duration_loss: 0.0558 - val_loss: 8.5935 - val_Note_loss: 4.5671 - val_Offset_loss: 0.2615 - val_Volume_loss: 1.3001 - val_Duration_loss: 3.9483\n",
            "Epoch 73/400\n",
            "43/44 [============================>.] - ETA: 0s - loss: 0.3602 - Note_loss: 0.2527 - Offset_loss: 0.2296 - Volume_loss: 0.5343 - Duration_loss: 0.0693\n",
            "Epoch 73: val_loss did not improve from 2.97038\n",
            "44/44 [==============================] - 1s 23ms/step - loss: 0.3600 - Note_loss: 0.2520 - Offset_loss: 0.2367 - Volume_loss: 0.5329 - Duration_loss: 0.0696 - val_loss: 8.7291 - val_Note_loss: 4.8156 - val_Offset_loss: 0.2884 - val_Volume_loss: 1.2802 - val_Duration_loss: 3.8351\n",
            "Epoch 74/400\n",
            "43/44 [============================>.] - ETA: 0s - loss: 0.3733 - Note_loss: 0.2624 - Offset_loss: 0.2414 - Volume_loss: 0.5661 - Duration_loss: 0.0706\n",
            "Epoch 74: val_loss did not improve from 2.97038\n",
            "44/44 [==============================] - 1s 23ms/step - loss: 0.3720 - Note_loss: 0.2620 - Offset_loss: 0.2384 - Volume_loss: 0.5633 - Duration_loss: 0.0699 - val_loss: 8.9287 - val_Note_loss: 4.9385 - val_Offset_loss: 0.2837 - val_Volume_loss: 1.2152 - val_Duration_loss: 3.9153\n",
            "Epoch 75/400\n",
            "42/44 [===========================>..] - ETA: 0s - loss: 0.3224 - Note_loss: 0.2320 - Offset_loss: 0.2187 - Volume_loss: 0.5172 - Duration_loss: 0.0536\n",
            "Epoch 75: val_loss did not improve from 2.97038\n",
            "44/44 [==============================] - 1s 24ms/step - loss: 0.3295 - Note_loss: 0.2315 - Offset_loss: 0.2244 - Volume_loss: 0.5222 - Duration_loss: 0.0606 - val_loss: 9.9753 - val_Note_loss: 5.7886 - val_Offset_loss: 0.3086 - val_Volume_loss: 1.3345 - val_Duration_loss: 4.1045\n",
            "Epoch 76/400\n",
            "42/44 [===========================>..] - ETA: 0s - loss: 0.4726 - Note_loss: 0.3377 - Offset_loss: 0.2345 - Volume_loss: 0.5596 - Duration_loss: 0.0952\n",
            "Epoch 76: val_loss did not improve from 2.97038\n",
            "44/44 [==============================] - 1s 23ms/step - loss: 0.4691 - Note_loss: 0.3372 - Offset_loss: 0.2341 - Volume_loss: 0.5518 - Duration_loss: 0.0926 - val_loss: 8.7224 - val_Note_loss: 4.9112 - val_Offset_loss: 0.2932 - val_Volume_loss: 1.3187 - val_Duration_loss: 3.7306\n",
            "Epoch 77/400\n",
            "42/44 [===========================>..] - ETA: 0s - loss: 0.4278 - Note_loss: 0.3130 - Offset_loss: 0.2171 - Volume_loss: 0.5502 - Duration_loss: 0.0764\n",
            "Epoch 77: val_loss did not improve from 2.97038\n",
            "44/44 [==============================] - 1s 23ms/step - loss: 0.4272 - Note_loss: 0.3128 - Offset_loss: 0.2209 - Volume_loss: 0.5503 - Duration_loss: 0.0758 - val_loss: 9.4009 - val_Note_loss: 5.2665 - val_Offset_loss: 0.2828 - val_Volume_loss: 1.2469 - val_Duration_loss: 4.0579\n",
            "Epoch 78/400\n",
            "43/44 [============================>.] - ETA: 0s - loss: 0.3540 - Note_loss: 0.2609 - Offset_loss: 0.2352 - Volume_loss: 0.5264 - Duration_loss: 0.0551\n",
            "Epoch 78: val_loss did not improve from 2.97038\n",
            "44/44 [==============================] - 1s 23ms/step - loss: 0.3591 - Note_loss: 0.2666 - Offset_loss: 0.2341 - Volume_loss: 0.5328 - Duration_loss: 0.0541 - val_loss: 9.1846 - val_Note_loss: 5.1264 - val_Offset_loss: 0.2728 - val_Volume_loss: 1.2094 - val_Duration_loss: 3.9840\n",
            "Epoch 79/400\n",
            "43/44 [============================>.] - ETA: 0s - loss: 0.3397 - Note_loss: 0.2394 - Offset_loss: 0.2235 - Volume_loss: 0.5112 - Duration_loss: 0.0636\n",
            "Epoch 79: val_loss did not improve from 2.97038\n",
            "44/44 [==============================] - 1s 24ms/step - loss: 0.3407 - Note_loss: 0.2412 - Offset_loss: 0.2245 - Volume_loss: 0.5084 - Duration_loss: 0.0628 - val_loss: 8.7659 - val_Note_loss: 4.9272 - val_Offset_loss: 0.2796 - val_Volume_loss: 1.3493 - val_Duration_loss: 3.7572\n",
            "Epoch 80/400\n",
            "43/44 [============================>.] - ETA: 0s - loss: 0.3452 - Note_loss: 0.2406 - Offset_loss: 0.2270 - Volume_loss: 0.5004 - Duration_loss: 0.0682\n",
            "Epoch 80: val_loss did not improve from 2.97038\n",
            "44/44 [==============================] - 1s 23ms/step - loss: 0.3452 - Note_loss: 0.2420 - Offset_loss: 0.2259 - Volume_loss: 0.4987 - Duration_loss: 0.0670 - val_loss: 8.6360 - val_Note_loss: 4.9071 - val_Offset_loss: 0.2844 - val_Volume_loss: 1.3721 - val_Duration_loss: 3.6461\n",
            "Epoch 81/400\n",
            "44/44 [==============================] - ETA: 0s - loss: 0.3226 - Note_loss: 0.2390 - Offset_loss: 0.2345 - Volume_loss: 0.5335 - Duration_loss: 0.0453\n",
            "Epoch 81: val_loss did not improve from 2.97038\n",
            "44/44 [==============================] - 1s 29ms/step - loss: 0.3226 - Note_loss: 0.2390 - Offset_loss: 0.2345 - Volume_loss: 0.5335 - Duration_loss: 0.0453 - val_loss: 8.7540 - val_Note_loss: 4.8557 - val_Offset_loss: 0.2732 - val_Volume_loss: 1.2805 - val_Duration_loss: 3.8206\n",
            "Epoch 82/400\n",
            "43/44 [============================>.] - ETA: 0s - loss: 0.3813 - Note_loss: 0.2865 - Offset_loss: 0.2185 - Volume_loss: 0.5314 - Duration_loss: 0.0573\n",
            "Epoch 82: val_loss did not improve from 2.97038\n",
            "44/44 [==============================] - 1s 33ms/step - loss: 0.3797 - Note_loss: 0.2858 - Offset_loss: 0.2182 - Volume_loss: 0.5279 - Duration_loss: 0.0566 - val_loss: 8.6838 - val_Note_loss: 4.6450 - val_Offset_loss: 0.3112 - val_Volume_loss: 1.2639 - val_Duration_loss: 3.9601\n",
            "Epoch 83/400\n",
            "44/44 [==============================] - ETA: 0s - loss: 0.3668 - Note_loss: 0.2705 - Offset_loss: 0.2262 - Volume_loss: 0.5227 - Duration_loss: 0.0588\n",
            "Epoch 83: val_loss did not improve from 2.97038\n",
            "44/44 [==============================] - 1s 28ms/step - loss: 0.3668 - Note_loss: 0.2705 - Offset_loss: 0.2262 - Volume_loss: 0.5227 - Duration_loss: 0.0588 - val_loss: 8.8709 - val_Note_loss: 4.8660 - val_Offset_loss: 0.2991 - val_Volume_loss: 1.2030 - val_Duration_loss: 3.9298\n",
            "Epoch 84/400\n",
            "42/44 [===========================>..] - ETA: 0s - loss: 0.2890 - Note_loss: 0.2045 - Offset_loss: 0.2226 - Volume_loss: 0.5051 - Duration_loss: 0.0481\n",
            "Epoch 84: val_loss did not improve from 2.97038\n",
            "44/44 [==============================] - 1s 24ms/step - loss: 0.2885 - Note_loss: 0.2049 - Offset_loss: 0.2232 - Volume_loss: 0.5119 - Duration_loss: 0.0469 - val_loss: 9.6051 - val_Note_loss: 5.2684 - val_Offset_loss: 0.2830 - val_Volume_loss: 1.3277 - val_Duration_loss: 4.2561\n",
            "Epoch 85/400\n",
            "43/44 [============================>.] - ETA: 0s - loss: 0.3247 - Note_loss: 0.2426 - Offset_loss: 0.2297 - Volume_loss: 0.5082 - Duration_loss: 0.0452\n",
            "Epoch 85: val_loss did not improve from 2.97038\n",
            "44/44 [==============================] - 1s 24ms/step - loss: 0.3266 - Note_loss: 0.2452 - Offset_loss: 0.2305 - Volume_loss: 0.5096 - Duration_loss: 0.0445 - val_loss: 9.4526 - val_Note_loss: 5.3392 - val_Offset_loss: 0.2861 - val_Volume_loss: 1.2996 - val_Duration_loss: 4.0342\n",
            "Epoch 86/400\n",
            "44/44 [==============================] - ETA: 0s - loss: 0.2785 - Note_loss: 0.2010 - Offset_loss: 0.2319 - Volume_loss: 0.5310 - Duration_loss: 0.0394\n",
            "Epoch 86: val_loss did not improve from 2.97038\n",
            "44/44 [==============================] - 1s 24ms/step - loss: 0.2785 - Note_loss: 0.2010 - Offset_loss: 0.2319 - Volume_loss: 0.5310 - Duration_loss: 0.0394 - val_loss: 9.1842 - val_Note_loss: 5.1905 - val_Offset_loss: 0.2849 - val_Volume_loss: 1.3566 - val_Duration_loss: 3.9116\n",
            "Epoch 87/400\n",
            "43/44 [============================>.] - ETA: 0s - loss: 0.3374 - Note_loss: 0.2262 - Offset_loss: 0.2326 - Volume_loss: 0.5142 - Duration_loss: 0.0738\n",
            "Epoch 87: val_loss did not improve from 2.97038\n",
            "44/44 [==============================] - 1s 25ms/step - loss: 0.3409 - Note_loss: 0.2265 - Offset_loss: 0.2305 - Volume_loss: 0.5131 - Duration_loss: 0.0772 - val_loss: 9.9258 - val_Note_loss: 5.3708 - val_Offset_loss: 0.2824 - val_Volume_loss: 1.4072 - val_Duration_loss: 4.4705\n",
            "Epoch 88/400\n",
            "44/44 [==============================] - ETA: 0s - loss: 0.3541 - Note_loss: 0.2709 - Offset_loss: 0.2335 - Volume_loss: 0.4919 - Duration_loss: 0.0470\n",
            "Epoch 88: val_loss did not improve from 2.97038\n",
            "44/44 [==============================] - 1s 25ms/step - loss: 0.3541 - Note_loss: 0.2709 - Offset_loss: 0.2335 - Volume_loss: 0.4919 - Duration_loss: 0.0470 - val_loss: 9.3473 - val_Note_loss: 5.3396 - val_Offset_loss: 0.2775 - val_Volume_loss: 1.3281 - val_Duration_loss: 3.9274\n",
            "Epoch 89/400\n",
            "42/44 [===========================>..] - ETA: 0s - loss: 0.2755 - Note_loss: 0.2030 - Offset_loss: 0.2333 - Volume_loss: 0.4967 - Duration_loss: 0.0360\n",
            "Epoch 89: val_loss did not improve from 2.97038\n",
            "44/44 [==============================] - 1s 24ms/step - loss: 0.2726 - Note_loss: 0.2016 - Offset_loss: 0.2303 - Volume_loss: 0.4989 - Duration_loss: 0.0346 - val_loss: 10.3367 - val_Note_loss: 5.4704 - val_Offset_loss: 0.2702 - val_Volume_loss: 1.3792 - val_Duration_loss: 4.7838\n",
            "Epoch 90/400\n",
            "44/44 [==============================] - ETA: 0s - loss: 0.5588 - Note_loss: 0.3700 - Offset_loss: 0.2253 - Volume_loss: 0.5745 - Duration_loss: 0.1488\n",
            "Epoch 90: val_loss did not improve from 2.97038\n",
            "44/44 [==============================] - 1s 25ms/step - loss: 0.5588 - Note_loss: 0.3700 - Offset_loss: 0.2253 - Volume_loss: 0.5745 - Duration_loss: 0.1488 - val_loss: 9.2769 - val_Note_loss: 5.4832 - val_Offset_loss: 0.2793 - val_Volume_loss: 1.2073 - val_Duration_loss: 3.7194\n",
            "Epoch 91/400\n",
            "43/44 [============================>.] - ETA: 0s - loss: 0.4526 - Note_loss: 0.3082 - Offset_loss: 0.2265 - Volume_loss: 0.5750 - Duration_loss: 0.1043\n",
            "Epoch 91: val_loss did not improve from 2.97038\n",
            "44/44 [==============================] - 1s 24ms/step - loss: 0.4551 - Note_loss: 0.3124 - Offset_loss: 0.2275 - Volume_loss: 0.5749 - Duration_loss: 0.1027 - val_loss: 9.2914 - val_Note_loss: 5.2568 - val_Offset_loss: 0.2816 - val_Volume_loss: 1.2094 - val_Duration_loss: 3.9601\n",
            "Epoch 92/400\n",
            "44/44 [==============================] - ETA: 0s - loss: 0.4092 - Note_loss: 0.2917 - Offset_loss: 0.2344 - Volume_loss: 0.5410 - Duration_loss: 0.0788\n",
            "Epoch 92: val_loss did not improve from 2.97038\n",
            "44/44 [==============================] - 1s 28ms/step - loss: 0.4092 - Note_loss: 0.2917 - Offset_loss: 0.2344 - Volume_loss: 0.5410 - Duration_loss: 0.0788 - val_loss: 9.7290 - val_Note_loss: 5.4868 - val_Offset_loss: 0.2553 - val_Volume_loss: 1.3183 - val_Duration_loss: 4.1635\n",
            "Epoch 93/400\n",
            "44/44 [==============================] - ETA: 0s - loss: 0.3682 - Note_loss: 0.2818 - Offset_loss: 0.2467 - Volume_loss: 0.5328 - Duration_loss: 0.0474\n",
            "Epoch 93: val_loss did not improve from 2.97038\n",
            "44/44 [==============================] - 2s 36ms/step - loss: 0.3682 - Note_loss: 0.2818 - Offset_loss: 0.2467 - Volume_loss: 0.5328 - Duration_loss: 0.0474 - val_loss: 9.6010 - val_Note_loss: 5.3297 - val_Offset_loss: 0.2774 - val_Volume_loss: 1.2767 - val_Duration_loss: 4.1936\n",
            "Epoch 94/400\n",
            "42/44 [===========================>..] - ETA: 0s - loss: 0.3204 - Note_loss: 0.2315 - Offset_loss: 0.2319 - Volume_loss: 0.5048 - Duration_loss: 0.0521\n",
            "Epoch 94: val_loss did not improve from 2.97038\n",
            "44/44 [==============================] - 1s 27ms/step - loss: 0.3209 - Note_loss: 0.2303 - Offset_loss: 0.2361 - Volume_loss: 0.5038 - Duration_loss: 0.0536 - val_loss: 9.5316 - val_Note_loss: 5.4069 - val_Offset_loss: 0.2862 - val_Volume_loss: 1.3776 - val_Duration_loss: 4.0415\n",
            "Epoch 95/400\n",
            "43/44 [============================>.] - ETA: 0s - loss: 0.3423 - Note_loss: 0.2421 - Offset_loss: 0.2375 - Volume_loss: 0.5046 - Duration_loss: 0.0630\n",
            "Epoch 95: val_loss did not improve from 2.97038\n",
            "44/44 [==============================] - 1s 24ms/step - loss: 0.3531 - Note_loss: 0.2483 - Offset_loss: 0.2363 - Volume_loss: 0.5060 - Duration_loss: 0.0676 - val_loss: 8.9888 - val_Note_loss: 5.1380 - val_Offset_loss: 0.2824 - val_Volume_loss: 1.3278 - val_Duration_loss: 3.7703\n",
            "Epoch 96/400\n",
            "44/44 [==============================] - ETA: 0s - loss: 0.2958 - Note_loss: 0.2013 - Offset_loss: 0.2408 - Volume_loss: 0.4913 - Duration_loss: 0.0579\n",
            "Epoch 96: val_loss did not improve from 2.97038\n",
            "44/44 [==============================] - 1s 24ms/step - loss: 0.2958 - Note_loss: 0.2013 - Offset_loss: 0.2408 - Volume_loss: 0.4913 - Duration_loss: 0.0579 - val_loss: 9.0711 - val_Note_loss: 5.1358 - val_Offset_loss: 0.2931 - val_Volume_loss: 1.3807 - val_Duration_loss: 3.8517\n",
            "Epoch 97/400\n",
            "42/44 [===========================>..] - ETA: 0s - loss: 0.2316 - Note_loss: 0.1666 - Offset_loss: 0.2500 - Volume_loss: 0.4795 - Duration_loss: 0.0286\n",
            "Epoch 97: val_loss did not improve from 2.97038\n",
            "44/44 [==============================] - 1s 24ms/step - loss: 0.2297 - Note_loss: 0.1617 - Offset_loss: 0.2445 - Volume_loss: 0.4860 - Duration_loss: 0.0314 - val_loss: 9.5206 - val_Note_loss: 5.5926 - val_Offset_loss: 0.2856 - val_Volume_loss: 1.3953 - val_Duration_loss: 3.8439\n",
            "Epoch 98/400\n",
            "44/44 [==============================] - ETA: 0s - loss: 0.2273 - Note_loss: 0.1575 - Offset_loss: 0.2276 - Volume_loss: 0.4771 - Duration_loss: 0.0346\n",
            "Epoch 98: val_loss did not improve from 2.97038\n",
            "44/44 [==============================] - 1s 23ms/step - loss: 0.2273 - Note_loss: 0.1575 - Offset_loss: 0.2276 - Volume_loss: 0.4771 - Duration_loss: 0.0346 - val_loss: 9.8724 - val_Note_loss: 5.4560 - val_Offset_loss: 0.2783 - val_Volume_loss: 1.3807 - val_Duration_loss: 4.3334\n",
            "Epoch 99/400\n",
            "43/44 [============================>.] - ETA: 0s - loss: 0.2435 - Note_loss: 0.1696 - Offset_loss: 0.2336 - Volume_loss: 0.4806 - Duration_loss: 0.0382\n",
            "Epoch 99: val_loss did not improve from 2.97038\n",
            "44/44 [==============================] - 1s 24ms/step - loss: 0.2419 - Note_loss: 0.1685 - Offset_loss: 0.2307 - Volume_loss: 0.4839 - Duration_loss: 0.0377 - val_loss: 10.1220 - val_Note_loss: 5.5025 - val_Offset_loss: 0.2945 - val_Volume_loss: 1.4173 - val_Duration_loss: 4.5339\n",
            "Epoch 100/400\n",
            "44/44 [==============================] - ETA: 0s - loss: 0.2293 - Note_loss: 0.1622 - Offset_loss: 0.2294 - Volume_loss: 0.4470 - Duration_loss: 0.0332\n",
            "Epoch 100: val_loss did not improve from 2.97038\n",
            "44/44 [==============================] - 1s 23ms/step - loss: 0.2293 - Note_loss: 0.1622 - Offset_loss: 0.2294 - Volume_loss: 0.4470 - Duration_loss: 0.0332 - val_loss: 10.0024 - val_Note_loss: 5.6600 - val_Offset_loss: 0.2825 - val_Volume_loss: 1.4859 - val_Duration_loss: 4.2539\n",
            "Epoch 101/400\n",
            "12/44 [=======>......................] - ETA: 0s - loss: 0.2024 - Note_loss: 0.1258 - Offset_loss: 0.2015 - Volume_loss: 0.4420 - Duration_loss: 0.0444"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-100-c91c3c338aa5>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0minput_note_reshaped\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_step_reshaped\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0minput_volume_reshaped\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_duration_reshaped\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0moutput_note_reshaped\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_step_reshaped\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_volume_reshaped\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_duration_reshaped\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m400\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcp_callback\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1781\u001b[0m                         ):\n\u001b[1;32m   1782\u001b[0m                             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1783\u001b[0;31m                             \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1784\u001b[0m                             \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1785\u001b[0m                                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    829\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 831\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    832\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    833\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    865\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    866\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 867\u001b[0;31m       return tracing_compilation.call_function(\n\u001b[0m\u001b[1;32m    868\u001b[0m           \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_no_variable_creation_config\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    869\u001b[0m       )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m   \u001b[0mbound_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m   \u001b[0mflat_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munpack_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbound_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m   return function._call_flat(  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m    140\u001b[0m       \u001b[0mflat_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m   )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1262\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1263\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1264\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inference_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflat_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1265\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1266\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36mflat_call\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    215\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mflat_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mSequence\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m     \u001b[0;34m\"\"\"Calls with tensor inputs and returns the structured output.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m     \u001b[0mflat_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    218\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpack_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflat_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    250\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mrecord\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_recording\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    251\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_bound_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 252\u001b[0;31m             outputs = self._bound_context.call_function(\n\u001b[0m\u001b[1;32m    253\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m                 \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/context.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1477\u001b[0m     \u001b[0mcancellation_context\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcancellation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1478\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcancellation_context\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1479\u001b[0;31m       outputs = execute.execute(\n\u001b[0m\u001b[1;32m   1480\u001b[0m           \u001b[0mname\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1481\u001b[0m           \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     ]\n\u001b[0;32m---> 60\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     61\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     62\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#prend une séquence de notes, volume, durées\n",
        "pattern_note = input_note[-1]\n",
        "pattern_offset = input_offset[-1]\n",
        "pattern_volume = input_volume[-1]\n",
        "pattern_duration = input_duration[-1]\n",
        "pattern_step = input_step[-1]\n"
      ],
      "metadata": {
        "id": "S7L6Fyy1pFBa"
      },
      "execution_count": 101,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "eGzZVJsX2-0J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prediction time\n",
        "prediction_output = []\n",
        "\n",
        "\n",
        "prev_start = pattern_offset[-1]\n",
        "for i in tqdm(range(200)):\n",
        "\n",
        "    #on reshape les input à prédire\n",
        "    note_prediction_input = numpy.reshape(pattern_note, (1, len(pattern_note), -1))\n",
        "    volume_prediction_input = numpy.reshape(pattern_volume, (1, len(pattern_volume), -1))\n",
        "    duration_prediction_input = numpy.reshape(pattern_duration, (1, len(pattern_duration), -1))\n",
        "    offset_prediction_input = numpy.reshape(pattern_offset, (1, len(pattern_offset), 1))\n",
        "    step_prediction_input = numpy.reshape(pattern_step, (1, len(pattern_step), 1))\n",
        "\n",
        "    #prédit ici\n",
        "    prediction = model.predict([note_prediction_input, step_prediction_input, volume_prediction_input, duration_prediction_input], verbose=0)\n",
        "\n",
        "    # prédis la note en récupérant l'index max du softmax et en faisant la transofr inverse\n",
        "    # à partir du one hot train sur les notes\n",
        "\n",
        "    temperature = 1.0\n",
        "\n",
        "    note_softmax = prediction[0]\n",
        "\n",
        "    notes_pred = np.zeros(len(pattern_note[0]))\n",
        "    notes_pred[np.argmax(prediction[0])] = 1\n",
        "    #notes_pred[note_soft] = 1\n",
        "    result_note = oh_notes.inverse_transform(notes_pred.reshape(1, -1))\n",
        "    pattern_note = numpy.concatenate([pattern_note, [notes_pred]])\n",
        "    pattern_note = pattern_note[1:]\n",
        "\n",
        "\n",
        "    \"\"\"offset_predict = prediction[1][0][0]\n",
        "    pattern_offset = numpy.concatenate([pattern_offset, prediction[1][0]])\n",
        "    pattern_offset = pattern_offset[1:]\n",
        "    print(pattern_offset)\"\"\"\n",
        "\n",
        "\n",
        "\n",
        "    step_predict = prediction[1][0][0]\n",
        "    pattern_step = numpy.concatenate([pattern_step, prediction[1][0]])\n",
        "    prev_start += step_predict\n",
        "    pattern_offset = numpy.concatenate([pattern_offset, [prev_start]])\n",
        "\n",
        "    pattern_step = pattern_step[1:]\n",
        "    pattern_offset = pattern_offset[1:]\n",
        "\n",
        "    # la même avec le volume\n",
        "    volume_pred = np.zeros(len(pattern_volume[1]))\n",
        "    volume_pred[np.argmax(prediction[2])] = 1\n",
        "    result_volume = oh_volume.inverse_transform(volume_pred.reshape(1, -1))\n",
        "    pattern_volume = numpy.concatenate([pattern_volume, [volume_pred]])\n",
        "    pattern_volume = pattern_volume[1:]\n",
        "\n",
        "    # la même avec la durée\n",
        "    duration_pred = np.zeros(len(pattern_duration[0]))\n",
        "    duration_pred[np.argmax(prediction[3])] = 1\n",
        "    result_duration = oh_duration.inverse_transform(duration_pred.reshape(1, -1))\n",
        "    pattern_duration = numpy.concatenate([pattern_duration, [duration_pred]])\n",
        "    pattern_duration = pattern_duration[1:]\n",
        "\n",
        "    # comme on prédit un mot associé au volume, on associe au mot une valeur/intensité\n",
        "    #(manque des catégories)\n",
        "    volume_encoded = result_volume[0][0]\n",
        "    volume_decoded = dict_volume_class[volume_encoded]\n",
        "\n",
        "    # la même avec la durée\n",
        "    #(manque des catégories)\n",
        "    duration_encoded = result_duration[0][0]\n",
        "    duration_decoded = dict_duration_class[duration_encoded]\n",
        "\n",
        "\n",
        "    #on ajoute la note, le volyme et la durée\n",
        "    prediction_output.append([result_note[0][0], step_predict, volume_decoded, duration_decoded])\n"
      ],
      "metadata": {
        "id": "1C2Vt-MH0nm_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2a8c3ccd-5727-4378-acc3-c01c0398e839"
      },
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 200/200 [00:24<00:00,  8.10it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prediction_output"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PD7StEvwxzXl",
        "outputId": "044c7d67-bc13-46a6-df0a-09b8ee2fc527"
      },
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['B4', 0.5877142, 90, 1.0],\n",
              " ['G3', 0.29085854, 90, 1.0],\n",
              " ['E4', 0.5680388, 90, 0.25],\n",
              " ['E3', 0.57176536, 90, 1.5],\n",
              " ['A2', 0.30471832, 90, 0.5],\n",
              " ['E2', 0.32547572, 90, 0.25],\n",
              " ['A3', 0.29331362, 90, 0.25],\n",
              " ['E2', 0.36164188, 90, 0.25],\n",
              " ['A3', 0.38604856, 90, 0.5],\n",
              " ['E4', 0.35914338, 90, 0.25],\n",
              " ['B3', 0.26899433, 90, 0.25],\n",
              " ['E2', 0.46559447, 128, 0.25],\n",
              " ['A4', 0.53436035, 90, 0.25],\n",
              " ['E2', 0.31768352, 90, 0.25],\n",
              " ['B4', 0.45146835, 90, 0.25],\n",
              " ['E2', 0.20210662, 90, 1.0],\n",
              " ['E5', 0.33120456, 90, 0.25],\n",
              " ['E4', 0.26528198, 128, 0.25],\n",
              " ['E2', 0.35143653, 90, 0.25],\n",
              " ['B4', 0.24777183, 90, 0.25],\n",
              " ['E2', 0.29492876, 90, 0.25],\n",
              " ['E4', 0.45040038, 90, 0.25],\n",
              " ['E2', 0.33737454, 90, 0.25],\n",
              " ['D6', 0.49515092, 90, 0.25],\n",
              " ['E2', 0.2549308, 90, 0.25],\n",
              " ['E4', 0.4025818, 90, 0.25],\n",
              " ['E2', 0.28233266, 90, 0.25],\n",
              " ['E4', 0.49652076, 90, 0.25],\n",
              " ['E2', 0.38140708, 90, 0.25],\n",
              " ['A4', 0.5485728, 90, 0.25],\n",
              " ['E2', 0.46502945, 90, 0.25],\n",
              " ['B4', 0.44562197, 90, 0.25],\n",
              " ['E2', 0.30672303, 90, 0.25],\n",
              " ['E5', 0.49399891, 90, 0.25],\n",
              " ['E2', 0.4868386, 90, 0.25],\n",
              " ['G5', 0.46800947, 90, 0.25],\n",
              " ['E2', 0.54911315, 90, 0.25],\n",
              " ['B5', 0.45352817, 90, 0.25],\n",
              " ['E2', 0.6667403, 90, 0.25],\n",
              " ['D6', 0.47861356, 90, 0.25],\n",
              " ['E2', 0.44862425, 90, 0.25],\n",
              " ['G6', 0.56764805, 90, 0.25],\n",
              " ['E2', 0.26116925, 90, 0.25],\n",
              " ['E4', 0.41370875, 70, 0.25],\n",
              " ['E2', 0.36114672, 70, 0.25],\n",
              " ['A4', 0.53864694, 70, 0.25],\n",
              " ['E2', 0.5214356, 70, 0.25],\n",
              " ['B4', 0.2971692, 90, 0.25],\n",
              " ['E2', 0.27379107, 90, 0.25],\n",
              " ['E5', 0.46069103, 90, 0.25],\n",
              " ['E2', 0.3677832, 90, 0.25],\n",
              " ['G5', 0.4218629, 90, 0.25],\n",
              " ['E2', 0.44044828, 90, 0.25],\n",
              " ['B5', 0.451429, 90, 0.25],\n",
              " ['E2', 0.6904901, 90, 0.25],\n",
              " ['D6', 0.500473, 90, 0.25],\n",
              " ['E2', 0.5422045, 90, 0.25],\n",
              " ['G6', 0.64639604, 90, 0.25],\n",
              " ['E2', 0.3213856, 90, 0.25],\n",
              " ['E4', 0.4115998, 70, 0.25],\n",
              " ['E2', 0.37046668, 70, 0.25],\n",
              " ['A4', 0.5304079, 70, 0.25],\n",
              " ['E2', 0.5199399, 70, 0.25],\n",
              " ['B4', 0.2897493, 90, 0.25],\n",
              " ['E2', 0.27040976, 90, 0.25],\n",
              " ['E5', 0.44726223, 90, 0.25],\n",
              " ['E2', 0.35558257, 90, 0.25],\n",
              " ['G5', 0.41030893, 90, 0.25],\n",
              " ['E2', 0.42102516, 90, 0.25],\n",
              " ['B5', 0.45460942, 90, 0.25],\n",
              " ['E2', 0.6991396, 90, 0.25],\n",
              " ['D6', 0.5121332, 90, 0.25],\n",
              " ['E2', 0.54936826, 90, 0.25],\n",
              " ['G6', 0.64541286, 90, 0.25],\n",
              " ['E2', 0.32539934, 90, 0.25],\n",
              " ['E4', 0.4062902, 70, 0.25],\n",
              " ['E2', 0.37133464, 70, 0.25],\n",
              " ['A4', 0.5300906, 70, 0.25],\n",
              " ['E2', 0.520244, 70, 0.25],\n",
              " ['B4', 0.28889406, 90, 0.25],\n",
              " ['E2', 0.2679475, 90, 0.25],\n",
              " ['E5', 0.4442111, 90, 0.25],\n",
              " ['E2', 0.35350326, 90, 0.25],\n",
              " ['G5', 0.4086914, 90, 0.25],\n",
              " ['E2', 0.4174103, 90, 0.25],\n",
              " ['B5', 0.45529664, 90, 0.25],\n",
              " ['E2', 0.70030725, 90, 0.25],\n",
              " ['D6', 0.5137841, 90, 0.25],\n",
              " ['E2', 0.5521623, 90, 0.25],\n",
              " ['G6', 0.64495206, 90, 0.25],\n",
              " ['E2', 0.32151717, 90, 0.25],\n",
              " ['E4', 0.40360615, 70, 0.25],\n",
              " ['E2', 0.3718767, 70, 0.25],\n",
              " ['A4', 0.5297401, 70, 0.25],\n",
              " ['E2', 0.5201671, 70, 0.25],\n",
              " ['B4', 0.28964058, 90, 0.25],\n",
              " ['E2', 0.26755583, 90, 0.25],\n",
              " ['E5', 0.44421685, 90, 0.25],\n",
              " ['E2', 0.3535159, 90, 0.25],\n",
              " ['G5', 0.40872404, 90, 0.25],\n",
              " ['E2', 0.41741, 90, 0.25],\n",
              " ['B5', 0.4553002, 90, 0.25],\n",
              " ['E2', 0.7002779, 90, 0.25],\n",
              " ['D6', 0.51379114, 90, 0.25],\n",
              " ['E2', 0.552188, 90, 0.25],\n",
              " ['G6', 0.64500743, 90, 0.25],\n",
              " ['E2', 0.32160044, 90, 0.25],\n",
              " ['E4', 0.40362224, 70, 0.25],\n",
              " ['E2', 0.37187538, 70, 0.25],\n",
              " ['A4', 0.52973413, 70, 0.25],\n",
              " ['E2', 0.52016103, 70, 0.25],\n",
              " ['B4', 0.28963453, 90, 0.25],\n",
              " ['E2', 0.26756003, 90, 0.25],\n",
              " ['E5', 0.44421732, 90, 0.25],\n",
              " ['E2', 0.35351545, 90, 0.25],\n",
              " ['G5', 0.4087235, 90, 0.25],\n",
              " ['E2', 0.4174098, 90, 0.25],\n",
              " ['B5', 0.45530093, 90, 0.25],\n",
              " ['E2', 0.70027876, 90, 0.25],\n",
              " ['D6', 0.5137925, 90, 0.25],\n",
              " ['E2', 0.5521843, 90, 0.25],\n",
              " ['G6', 0.64500624, 90, 0.25],\n",
              " ['E2', 0.3216026, 90, 0.25],\n",
              " ['E4', 0.4036233, 70, 0.25],\n",
              " ['E2', 0.37187517, 70, 0.25],\n",
              " ['A4', 0.52973443, 70, 0.25],\n",
              " ['E2', 0.5201613, 70, 0.25],\n",
              " ['B4', 0.289634, 90, 0.25],\n",
              " ['E2', 0.26755995, 90, 0.25],\n",
              " ['E5', 0.44421744, 90, 0.25],\n",
              " ['E2', 0.35351542, 90, 0.25],\n",
              " ['G5', 0.40872374, 90, 0.25],\n",
              " ['E2', 0.41740972, 90, 0.25],\n",
              " ['B5', 0.455301, 90, 0.25],\n",
              " ['E2', 0.70027876, 90, 0.25],\n",
              " ['D6', 0.51379263, 90, 0.25],\n",
              " ['E2', 0.55218446, 90, 0.25],\n",
              " ['G6', 0.64500624, 90, 0.25],\n",
              " ['E2', 0.3216014, 90, 0.25],\n",
              " ['E4', 0.40362313, 70, 0.25],\n",
              " ['E2', 0.37187514, 70, 0.25],\n",
              " ['A4', 0.5297345, 70, 0.25],\n",
              " ['E2', 0.5201614, 70, 0.25],\n",
              " ['B4', 0.28963405, 90, 0.25],\n",
              " ['E2', 0.26756012, 90, 0.25],\n",
              " ['E5', 0.44421747, 90, 0.25],\n",
              " ['E2', 0.35351545, 90, 0.25],\n",
              " ['G5', 0.40872374, 90, 0.25],\n",
              " ['E2', 0.41740978, 90, 0.25],\n",
              " ['B5', 0.45530108, 90, 0.25],\n",
              " ['E2', 0.7002789, 90, 0.25],\n",
              " ['D6', 0.51379263, 90, 0.25],\n",
              " ['E2', 0.55218446, 90, 0.25],\n",
              " ['G6', 0.6450062, 90, 0.25],\n",
              " ['E2', 0.32160148, 90, 0.25],\n",
              " ['E4', 0.40362307, 70, 0.25],\n",
              " ['E2', 0.37187514, 70, 0.25],\n",
              " ['A4', 0.5297344, 70, 0.25],\n",
              " ['E2', 0.5201613, 70, 0.25],\n",
              " ['B4', 0.28963414, 90, 0.25],\n",
              " ['E2', 0.26756012, 90, 0.25],\n",
              " ['E5', 0.44421738, 90, 0.25],\n",
              " ['E2', 0.35351533, 90, 0.25],\n",
              " ['G5', 0.40872365, 90, 0.25],\n",
              " ['E2', 0.4174097, 90, 0.25],\n",
              " ['B5', 0.45530108, 90, 0.25],\n",
              " ['E2', 0.70027876, 90, 0.25],\n",
              " ['D6', 0.5137927, 90, 0.25],\n",
              " ['E2', 0.5521846, 90, 0.25],\n",
              " ['G6', 0.6450062, 90, 0.25],\n",
              " ['E2', 0.32160148, 90, 0.25],\n",
              " ['E4', 0.4036231, 70, 0.25],\n",
              " ['E2', 0.3718752, 70, 0.25],\n",
              " ['A4', 0.5297344, 70, 0.25],\n",
              " ['E2', 0.5201613, 70, 0.25],\n",
              " ['B4', 0.28963417, 90, 0.25],\n",
              " ['E2', 0.26756, 90, 0.25],\n",
              " ['E5', 0.4442175, 90, 0.25],\n",
              " ['E2', 0.3535154, 90, 0.25],\n",
              " ['G5', 0.40872365, 90, 0.25],\n",
              " ['E2', 0.41740984, 90, 0.25],\n",
              " ['B5', 0.45530105, 90, 0.25],\n",
              " ['E2', 0.7002788, 90, 0.25],\n",
              " ['D6', 0.51379275, 90, 0.25],\n",
              " ['E2', 0.5521846, 90, 0.25],\n",
              " ['G6', 0.64500624, 90, 0.25],\n",
              " ['E2', 0.3216015, 90, 0.25],\n",
              " ['E4', 0.40362307, 70, 0.25],\n",
              " ['E2', 0.37187517, 70, 0.25],\n",
              " ['A4', 0.52973443, 70, 0.25],\n",
              " ['E2', 0.5201613, 70, 0.25],\n",
              " ['B4', 0.2896341, 90, 0.25],\n",
              " ['E2', 0.26756, 90, 0.25],\n",
              " ['E5', 0.44421738, 90, 0.25],\n",
              " ['E2', 0.35351542, 90, 0.25],\n",
              " ['G5', 0.40872365, 90, 0.25],\n",
              " ['E2', 0.41740975, 90, 0.25],\n",
              " ['B5', 0.4553011, 90, 0.25],\n",
              " ['E2', 0.7002788, 90, 0.25],\n",
              " ['D6', 0.5137927, 90, 0.25]]"
            ]
          },
          "metadata": {},
          "execution_count": 103
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from music21.duration import Duration\n"
      ],
      "metadata": {
        "id": "91w43lwl5urg"
      },
      "execution_count": 104,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "offset = 0\n",
        "output_notes = []\n",
        "# on passes des prédicitons à un format écoutable à l'oreille\n",
        "\n",
        "prev_start = 0\n",
        "# pour chaque note prédite\n",
        "for note_p in prediction_output:\n",
        "    pattern = note_p[0]\n",
        "    # si note = chord\n",
        "    if ('+' in pattern) or pattern.isdigit():\n",
        "        notes_in_chord = pattern.split('+')\n",
        "        notes = []\n",
        "        for current_note in notes_in_chord:\n",
        "            new_note = note.Note(int(current_note))\n",
        "            new_note.storedInstrument = instrument.Piano()\n",
        "            notes.append(new_note)\n",
        "        new_chord = chord.Chord(notes)\n",
        "        new_chord.offset = prev_start + note_p[1]\n",
        "        #new_chord.offset = note_p[1]\n",
        "        # met le volume associé\n",
        "        new_chord.volume.velocity = note_p[2]\n",
        "        # met la durée associée\n",
        "        new_chord.duration = Duration(note_p[3])\n",
        "        output_notes.append(new_chord)\n",
        "    # si note est un rest\n",
        "    elif('REST'in pattern):\n",
        "      note_rest = note.Rest()\n",
        "      note_rest.offset = prev_start + note_p[1]\n",
        "      #note_rest.offset = note_p[1]\n",
        "      # durée associée (pas de volume car silencieux)\n",
        "      note_rest.duration = Duration(note_p[3])\n",
        "      output_notes.append(note_rest)\n",
        "    else:\n",
        "        new_note = note.Note(pattern)\n",
        "        new_note.offset = prev_start + note_p[1]\n",
        "        #new_note.offset = note_p[1]\n",
        "        new_note.volume.velocity = note_p[2]\n",
        "        new_note.duration = Duration(note_p[3])\n",
        "        new_note.storedInstrument = instrument.Piano()\n",
        "        output_notes.append(new_note)\n",
        "    prev_start = prev_start + note_p[1]\n",
        "    # increase offset each iteration so that notes do not stack\n",
        "    #offset += 0.5"
      ],
      "metadata": {
        "id": "BxktumUV0H22"
      },
      "execution_count": 105,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#into midi\n",
        "midi_stream = stream.Stream(output_notes)\n",
        "midi_stream.write('midi', fp='test_outputminecraft25.mid')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "I5W_QMyyn7BA",
        "outputId": "e65b35cb-77dd-4b83-86f2-81c32f9abddb"
      },
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'test_outputminecraft25.mid'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 106
        }
      ]
    }
  ]
}