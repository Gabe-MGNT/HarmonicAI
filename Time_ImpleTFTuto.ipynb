{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "wLez1Slaaydy"
      },
      "outputs": [],
      "source": [
        "from music21 import converter, instrument, note, chord, stream\n",
        "import numpy\n",
        "from matplotlib import pyplot as plt\n",
        "import keras\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from keras import Sequential, Model\n",
        "from keras.layers import LSTM, Dropout, Dense, Activation, Input, concatenate\n",
        "import pandas as pd\n",
        "from tensorflow.keras.layers import Input, Dense, Dropout\n",
        "import os\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import MultiHeadAttention, LayerNormalization, Embedding\n",
        "import tensorflow as tf\n",
        "from tqdm import tqdm\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip dataset.zip"
      ],
      "metadata": {
        "id": "jMOiwvUEduhe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5b60bf94-0ba1-419b-a696-485e952d9e20"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "unzip:  cannot find or open dataset.zip, dataset.zip.zip or dataset.zip.ZIP.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_notes(midi):\n",
        "  notes = []\n",
        "\n",
        "  notes_from_midi = midi.flatten().notesAndRests\n",
        "  notes_sorted = sorted(notes_from_midi, key=lambda note: note.offset)\n",
        "\n",
        "  prev_start = notes_sorted[0].offset\n",
        "\n",
        "  for element in notes_sorted:\n",
        "    if isinstance(element , note.Note):\n",
        "      notes.append((float(element.offset), float(element.volume.velocity),float(element.seconds), str(element.pitch), float(element.offset-prev_start)))\n",
        "    elif isinstance(element, chord.Chord):\n",
        "      #notes.append((float(element.offset), float(element.volume.velocity), float(element.seconds), '+'.join(str(n) for n in element.normalOrder)))\n",
        "      for noteChord in element.pitches:\n",
        "        notes.append((float(element.offset),float(element.volume.velocity), float(element.seconds), str(noteChord), float(element.offset-prev_start)))\n",
        "\n",
        "    elif isinstance(element, note.Rest):\n",
        "        # Bizarre car main gauche et droite flatten (réunie)\n",
        "        # Voir autre implémentation\n",
        "        notes.append((float(element.offset), 0,float(element.seconds), \"REST\", float(element.offset-prev_start)))\n",
        "\n",
        "    prev_start = element.offset\n",
        "  return notes\n",
        "\n"
      ],
      "metadata": {
        "id": "ltEonII2gWg0"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_note, output_note = [], []\n",
        "input_offset, output_offset = [], []\n",
        "input_volume, output_volume = [], []\n",
        "input_duration, output_duration = [], []\n",
        "\n",
        "note_all_songs = []\n",
        "for folder in tqdm(os.walk(\"dataset\")):\n",
        "    if len(folder) != 3:\n",
        "      continue\n",
        "    else:\n",
        "      for file in folder[2][:5]:\n",
        "        file_path = str(folder[0])+\"/\"+file\n",
        "\n",
        "        # convertit la piste midi\n",
        "        midi = converter.parse(file_path)\n",
        "\n",
        "        # récupère les notes, volume, dureées...\n",
        "        notes = get_notes(midi)\n",
        "\n",
        "        # ajoute à une liste globale\n",
        "        note_all_songs.append(notes)"
      ],
      "metadata": {
        "id": "nUvY0NWPd79V",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d27b52f2-f30a-4674-9799-a58eb461d710"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "1it [00:00, 22.48it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# fais un dataframe à partir de toutes les notes (sans distinctions)\n",
        "df = pd.DataFrame([], columns=['debut_note','volume','durée(s)', 'pitch/chord', 'offset'])\n",
        "df = df.reset_index(drop=True)\n",
        "for elem in note_all_songs:\n",
        "    df2 = pd.DataFrame(elem, columns=['debut_note','volume','durée(s)', 'pitch/chord', 'offset'])\n",
        "    df2 = df2.reset_index(drop=True)\n",
        "    df =pd.concat([df,df2])\n",
        "    df = df.reset_index(drop=True)"
      ],
      "metadata": {
        "id": "_bRdnkH6OdJA"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "FsqRZiQCm3MV",
        "outputId": "5b5aa054-60cb-40a0-bfea-5dff35410050"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     debut_note  volume  durée(s) pitch/chord  offset\n",
              "0           0.0    55.0      2.50          E3    0.00\n",
              "1           0.0    55.0      2.50          G3    0.00\n",
              "2           0.0    55.0      1.25          E2    0.00\n",
              "3           1.0    69.0      1.25         F#2    1.00\n",
              "4           2.0    68.0      2.50          A3    1.00\n",
              "..          ...     ...       ...         ...     ...\n",
              "298        86.0    74.0      3.20          G1    0.25\n",
              "299        86.0    74.0      3.20          G3    0.25\n",
              "300        86.0    74.0      3.20          B3    0.25\n",
              "301        86.0     0.0      3.20        REST    0.00\n",
              "302        86.0     0.0      3.20        REST    0.00\n",
              "\n",
              "[303 rows x 5 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-b65a8a16-0556-452f-9cac-3fb5f0cb3d88\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>debut_note</th>\n",
              "      <th>volume</th>\n",
              "      <th>durée(s)</th>\n",
              "      <th>pitch/chord</th>\n",
              "      <th>offset</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.0</td>\n",
              "      <td>55.0</td>\n",
              "      <td>2.50</td>\n",
              "      <td>E3</td>\n",
              "      <td>0.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.0</td>\n",
              "      <td>55.0</td>\n",
              "      <td>2.50</td>\n",
              "      <td>G3</td>\n",
              "      <td>0.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.0</td>\n",
              "      <td>55.0</td>\n",
              "      <td>1.25</td>\n",
              "      <td>E2</td>\n",
              "      <td>0.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1.0</td>\n",
              "      <td>69.0</td>\n",
              "      <td>1.25</td>\n",
              "      <td>F#2</td>\n",
              "      <td>1.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2.0</td>\n",
              "      <td>68.0</td>\n",
              "      <td>2.50</td>\n",
              "      <td>A3</td>\n",
              "      <td>1.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>298</th>\n",
              "      <td>86.0</td>\n",
              "      <td>74.0</td>\n",
              "      <td>3.20</td>\n",
              "      <td>G1</td>\n",
              "      <td>0.25</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>299</th>\n",
              "      <td>86.0</td>\n",
              "      <td>74.0</td>\n",
              "      <td>3.20</td>\n",
              "      <td>G3</td>\n",
              "      <td>0.25</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>300</th>\n",
              "      <td>86.0</td>\n",
              "      <td>74.0</td>\n",
              "      <td>3.20</td>\n",
              "      <td>B3</td>\n",
              "      <td>0.25</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>301</th>\n",
              "      <td>86.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.20</td>\n",
              "      <td>REST</td>\n",
              "      <td>0.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>302</th>\n",
              "      <td>86.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.20</td>\n",
              "      <td>REST</td>\n",
              "      <td>0.00</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>303 rows × 5 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b65a8a16-0556-452f-9cac-3fb5f0cb3d88')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-b65a8a16-0556-452f-9cac-3fb5f0cb3d88 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-b65a8a16-0556-452f-9cac-3fb5f0cb3d88');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-8b9c94ef-55af-42d1-b2ae-3503848c1853\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-8b9c94ef-55af-42d1-b2ae-3503848c1853')\"\n",
              "            title=\"Suggest charts.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-8b9c94ef-55af-42d1-b2ae-3503848c1853 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#train les encoders pour les notes, volumes et durées en catégorielles (one hot)\n",
        "# sur intégralité des données (obligé)\n",
        "# Voir si on peut pas enregistré le transformateur\n",
        "oh_notes =  OneHotEncoder().fit(df[['pitch/chord']])\n",
        "\n",
        "\n",
        "# seuil/catégories modifiable\n",
        "dict_volume_class = {\n",
        "    \"very low\":10,\n",
        "    \"low\":30,\n",
        "    \"low medium\":50,\n",
        "    \"medium\":70,\n",
        "    \"high\": 90,\n",
        "    \"very high\":128\n",
        "}\n",
        "bins_volume = list(dict_volume_class.values())\n",
        "bins_volume.insert(0,-0.1)\n",
        "values_volume = list(dict_volume_class.keys())\n",
        "df[\"volume_class\"] = pd.cut(df[\"volume\"], bins=bins_volume, labels=values_volume)\n",
        "\"\"\"df[\"volume_class_interval\"] = pd.cut(df[\"volume\"], bins=20)\n",
        "intervals = df[\"volume_class_interval\"]\n",
        "median_values = [(interval.left + interval.right) / 2 for interval in intervals]\n",
        "df[\"volume_class\"] = median_values\"\"\"\n",
        "oh_volume =  OneHotEncoder().fit(df[['volume_class']])\n",
        "\n",
        "\n",
        "dict_duration_class = {\n",
        "\"very short\" : 0.1,\n",
        "\"short\" :0.25,\n",
        "\"medium\":0.5,\n",
        "\"medium-long\":0.75,\n",
        "\"long\":1.0,\n",
        "\"very long\": 1.5,\n",
        "\"super mega long\":df['durée(s)'].max()\n",
        "}\n",
        "bins_duration = list(dict_duration_class.values())\n",
        "bins_duration.insert(0,-0.1)\n",
        "values_duration = list(dict_duration_class.keys())\n",
        "df[\"duration_class\"] = pd.cut(df[\"durée(s)\"], bins=bins_duration, labels=values_duration)\n",
        "\"\"\"df[\"duration_class_interval\"] = pd.cut(df[\"durée(s)\"], bins=20)\n",
        "intervals = df[\"duration_class_interval\"]\n",
        "median_values = [(interval.left + interval.right) / 2 for interval in intervals]\n",
        "df[\"duration_class\"] = median_values\"\"\"\n",
        "oh_duration =  OneHotEncoder().fit(df[['duration_class']])\n"
      ],
      "metadata": {
        "id": "sJ6s6EG-UTLz"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def prepare_sequence(data, sequence_length, network_input, network_output):\n",
        "  # create input sequences and the corresponding outputs\n",
        "  for i in range(0, len(data) - sequence_length, 1):\n",
        "      sequence_in = data[i:i + sequence_length]\n",
        "      sequence_out = data[i + sequence_length]\n",
        "      network_input.append(sequence_in)\n",
        "      network_output.append(sequence_out)\n",
        "  return (network_input, network_output)\n",
        "\n",
        "def reshape_array_input(array_tensor, sequence_length):\n",
        "  n_patterns = len(array_tensor)\n",
        "  array_reshaped = numpy.reshape(array_tensor, (n_patterns, sequence_length, -1))\n",
        "  return array_reshaped\n",
        "\n",
        "def reshape_array_output(array_tensor, sequence_length):\n",
        "  n_patterns = len(array_tensor)\n",
        "  array_reshaped = numpy.reshape(array_tensor, (len(array_tensor), -1))\n",
        "  return array_reshaped\n"
      ],
      "metadata": {
        "id": "2Z_CqsKBicHH"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sequence_length = 50"
      ],
      "metadata": {
        "id": "tqK33V-UjsOn"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_note, output_note = [], []\n",
        "input_offset, output_offset = [], []\n",
        "input_volume, output_volume = [], []\n",
        "input_duration, output_duration = [], []\n",
        "input_step, output_step = [], []\n",
        "\n",
        "# pour chaque music, on la transforme en dataframe, transforme les notes, durées et volumes\n",
        "for music in note_all_songs:\n",
        "  df_music = pd.DataFrame(music, columns=['debut_note','volume','durée(s)', 'pitch/chord', 'step'])\n",
        "\n",
        "  # encode le volume et la durée\n",
        "  df_music[\"volume_class\"] = pd.cut(df_music[\"volume\"], bins=bins_volume, labels=values_volume)\n",
        "  df_music[\"duration_class\"] = pd.cut(df_music[\"durée(s)\"], bins=bins_duration, labels=values_duration)\n",
        "\n",
        "\n",
        "  # transform en one hot à partir des modèles entrainés\n",
        "  notes_encoded = oh_notes.transform(df_music[['pitch/chord']]).toarray()\n",
        "  volume_encoded = oh_volume.transform(df_music[['volume_class']]).toarray()\n",
        "  duration_encoded = oh_duration.transform(df_music[['duration_class']]).toarray()\n",
        "\n",
        "  # prépare les input (longeur = sequence_length) pour chaque morceau\n",
        "  # garde certaine cohérence au morceau même\n",
        "  input_offset, output_offset = prepare_sequence(df_music['debut_note'].values, sequence_length, input_offset, output_offset)\n",
        "  input_note, output_note = prepare_sequence(notes_encoded, sequence_length, input_note, output_note)\n",
        "  input_volume, output_volume = prepare_sequence(volume_encoded, sequence_length, input_volume, output_volume)\n",
        "  input_duration, output_duration = prepare_sequence(duration_encoded, sequence_length, input_duration, output_duration)\n",
        "  input_step, output_step = prepare_sequence(df_music['step'].values, sequence_length, input_step, output_step)"
      ],
      "metadata": {
        "id": "1lpnB-spixTZ"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# on reshape tout\n",
        "input_note_reshaped= reshape_array_input(input_note, sequence_length)\n",
        "output_note_reshaped = reshape_array_output(output_note, sequence_length)\n",
        "\n",
        "input_offset_reshaped = reshape_array_input(input_offset, sequence_length)\n",
        "output_offset_reshaped = reshape_array_output(output_offset, sequence_length)\n",
        "\n",
        "input_volume_reshaped= reshape_array_input(input_volume, sequence_length)\n",
        "output_volume_reshaped = reshape_array_output(output_volume, sequence_length)\n",
        "\n",
        "input_duration_reshaped= reshape_array_input(input_duration, sequence_length)\n",
        "output_duration_reshaped = reshape_array_output(output_duration, sequence_length)\n",
        "\n",
        "\n",
        "input_step_reshaped= reshape_array_input(input_step, sequence_length)\n",
        "output_step_reshaped = reshape_array_output(output_step, sequence_length)\n"
      ],
      "metadata": {
        "id": "AzX_ofZZj1vY"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#création du modèle (à alléger si overfitting)\n",
        "inputNotes_layer = Input(shape=(input_note_reshaped.shape[1], input_note_reshaped.shape[2]))\n",
        "inputNotes = LSTM(\n",
        "        8,\n",
        "        input_shape=(input_note_reshaped.shape[1], input_note_reshaped.shape[2]),\n",
        "        return_sequences=True\n",
        "    )(inputNotes_layer)\n",
        "\n",
        "inputVolume_layer = Input(shape=(input_volume_reshaped.shape[1], input_volume_reshaped.shape[2]))\n",
        "inputVolume = LSTM(\n",
        "        8,\n",
        "        input_shape=(input_volume_reshaped.shape[1], input_volume_reshaped.shape[2]),\n",
        "        return_sequences=True\n",
        "    )(inputVolume_layer)\n",
        "\n",
        "inputDuration_layer = Input(shape=(input_duration_reshaped.shape[1], input_duration_reshaped.shape[2]))\n",
        "inputDuration = LSTM(\n",
        "        8,\n",
        "        input_shape=(input_duration_reshaped.shape[1], input_duration_reshaped.shape[2]),\n",
        "        return_sequences=True\n",
        "    )(inputDuration_layer)\n",
        "\n",
        "inputOffset_layer = Input(shape=(input_offset_reshaped.shape[1], input_offset_reshaped.shape[2]))\n",
        "inputOffset = LSTM(\n",
        "        8,\n",
        "        input_shape=(input_offset_reshaped.shape[1], input_offset_reshaped.shape[2]),\n",
        "        return_sequences=True\n",
        "    )(inputOffset_layer)\n",
        "\n",
        "inputs = concatenate([inputNotes, inputVolume, inputDuration, inputOffset])\n",
        "x = LSTM(64, return_sequences=True)(inputs)\n",
        "x = Dropout(0.3)(x)\n",
        "x = LSTM(64)(inputs)\n",
        "x = Dropout(0.3)(x)\n",
        "x = Dense(64, activation='relu')(x)\n",
        "\n",
        "outputNotes = Dense(8, activation='relu')(x)\n",
        "outputNotes = Dense(output_note_reshaped.shape[1], activation='softmax', name=\"Note\")(outputNotes)\n",
        "\n",
        "outputVolume = Dense(8, activation='relu')(x)\n",
        "outputVolume = Dense(output_volume_reshaped.shape[1], activation='softmax', name=\"Volume\")(outputVolume)\n",
        "\n",
        "outputDuration = Dense(8, activation='relu')(x)\n",
        "outputDuration = Dense(output_duration_reshaped.shape[1], activation='softmax', name=\"Duration\")(outputDuration)\n",
        "\n",
        "outputOffset =  Dense(8, activation='relu')(x)\n",
        "outputOffset = Dense(output_offset_reshaped.shape[1], activation='linear', name=\"Offset\")(outputOffset)\n",
        "\n",
        "\n",
        "\n",
        "model = Model(inputs=[inputNotes_layer,inputOffset_layer,  inputVolume_layer, inputDuration_layer], outputs=[outputNotes, outputOffset, outputVolume, outputDuration])\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=0.005)\n",
        "#Adam seems to be faster than RMSProp and learns better too\n",
        "model.compile(loss=[\"categorical_crossentropy\", \"mean_squared_error\", \"categorical_crossentropy\", \"categorical_crossentropy\"], optimizer=optimizer)"
      ],
      "metadata": {
        "id": "NyzHblQ7kfw0"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "id": "q_4pFN5EihPj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "584f8e3d-3ab0-428d-b0ae-134b6fcad96a"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)        [(None, 50, 27)]             0         []                            \n",
            "                                                                                                  \n",
            " input_2 (InputLayer)        [(None, 50, 4)]              0         []                            \n",
            "                                                                                                  \n",
            " input_3 (InputLayer)        [(None, 50, 6)]              0         []                            \n",
            "                                                                                                  \n",
            " input_4 (InputLayer)        [(None, 50, 1)]              0         []                            \n",
            "                                                                                                  \n",
            " lstm (LSTM)                 (None, 50, 8)                1152      ['input_1[0][0]']             \n",
            "                                                                                                  \n",
            " lstm_1 (LSTM)               (None, 50, 8)                416       ['input_2[0][0]']             \n",
            "                                                                                                  \n",
            " lstm_2 (LSTM)               (None, 50, 8)                480       ['input_3[0][0]']             \n",
            "                                                                                                  \n",
            " lstm_3 (LSTM)               (None, 50, 8)                320       ['input_4[0][0]']             \n",
            "                                                                                                  \n",
            " concatenate (Concatenate)   (None, 50, 32)               0         ['lstm[0][0]',                \n",
            "                                                                     'lstm_1[0][0]',              \n",
            "                                                                     'lstm_2[0][0]',              \n",
            "                                                                     'lstm_3[0][0]']              \n",
            "                                                                                                  \n",
            " lstm_5 (LSTM)               (None, 16)                   3136      ['concatenate[0][0]']         \n",
            "                                                                                                  \n",
            " dropout_1 (Dropout)         (None, 16)                   0         ['lstm_5[0][0]']              \n",
            "                                                                                                  \n",
            " dense (Dense)               (None, 16)                   272       ['dropout_1[0][0]']           \n",
            "                                                                                                  \n",
            " dense_1 (Dense)             (None, 8)                    136       ['dense[0][0]']               \n",
            "                                                                                                  \n",
            " dense_4 (Dense)             (None, 8)                    136       ['dense[0][0]']               \n",
            "                                                                                                  \n",
            " dense_2 (Dense)             (None, 8)                    136       ['dense[0][0]']               \n",
            "                                                                                                  \n",
            " dense_3 (Dense)             (None, 8)                    136       ['dense[0][0]']               \n",
            "                                                                                                  \n",
            " Note (Dense)                (None, 27)                   243       ['dense_1[0][0]']             \n",
            "                                                                                                  \n",
            " Offset (Dense)              (None, 1)                    9         ['dense_4[0][0]']             \n",
            "                                                                                                  \n",
            " Volume (Dense)              (None, 4)                    36        ['dense_2[0][0]']             \n",
            "                                                                                                  \n",
            " Duration (Dense)            (None, 6)                    54        ['dense_3[0][0]']             \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 6662 (26.02 KB)\n",
            "Trainable params: 6662 (26.02 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "cp_callback = keras.callbacks.ModelCheckpoint(\n",
        "    'model_weights_epoch.h5',  # Nom du fichier de sauvegarde avec un espace réservé pour le numéro de l'époque\n",
        "    save_best_only=True,  # Sauvegarder à chaque époque, pas seulement les meilleurs modèles\n",
        "    save_weights_only=True,  # Sauvegarder uniquement les poids, pas l'ensemble du modèle\n",
        "    verbose=1  # Afficher un message lors de la sauvegarde\n",
        "    )"
      ],
      "metadata": {
        "id": "YB2DV7zy3om5"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit([input_note_reshaped, input_step_reshaped, input_volume_reshaped, input_duration_reshaped], [output_note_reshaped, output_step_reshaped, output_volume_reshaped, output_duration_reshaped], epochs=400, callbacks=[cp_callback], validation_split=0.2)"
      ],
      "metadata": {
        "id": "d7w5ODUnf8B8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "b804231d-c1a9-457a-8385-97a435f43854"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/400\n",
            "7/7 [==============================] - ETA: 0s - loss: 6.6436 - Note_loss: 3.2838 - Offset_loss: 0.4232 - Volume_loss: 1.3316 - Duration_loss: 1.6049\n",
            "Epoch 1: val_loss did not improve from 5.95548\n",
            "7/7 [==============================] - 12s 323ms/step - loss: 6.6436 - Note_loss: 3.2838 - Offset_loss: 0.4232 - Volume_loss: 1.3316 - Duration_loss: 1.6049 - val_loss: 6.4899 - val_Note_loss: 3.3488 - val_Offset_loss: 0.3487 - val_Volume_loss: 1.2068 - val_Duration_loss: 1.5856\n",
            "Epoch 2/400\n",
            "7/7 [==============================] - ETA: 0s - loss: 6.0394 - Note_loss: 3.2064 - Offset_loss: 0.3737 - Volume_loss: 1.1534 - Duration_loss: 1.3058\n",
            "Epoch 2: val_loss did not improve from 5.95548\n",
            "7/7 [==============================] - 0s 38ms/step - loss: 6.0394 - Note_loss: 3.2064 - Offset_loss: 0.3737 - Volume_loss: 1.1534 - Duration_loss: 1.3058 - val_loss: 6.2342 - val_Note_loss: 3.3323 - val_Offset_loss: 0.3968 - val_Volume_loss: 1.1779 - val_Duration_loss: 1.3273\n",
            "Epoch 3/400\n",
            "7/7 [==============================] - ETA: 0s - loss: 5.9702 - Note_loss: 3.1538 - Offset_loss: 0.3846 - Volume_loss: 1.1409 - Duration_loss: 1.2909\n",
            "Epoch 3: val_loss did not improve from 5.95548\n",
            "7/7 [==============================] - 0s 30ms/step - loss: 5.9702 - Note_loss: 3.1538 - Offset_loss: 0.3846 - Volume_loss: 1.1409 - Duration_loss: 1.2909 - val_loss: 6.2880 - val_Note_loss: 3.4099 - val_Offset_loss: 0.3997 - val_Volume_loss: 1.1595 - val_Duration_loss: 1.3188\n",
            "Epoch 4/400\n",
            "7/7 [==============================] - ETA: 0s - loss: 5.8384 - Note_loss: 3.0889 - Offset_loss: 0.4111 - Volume_loss: 1.0987 - Duration_loss: 1.2397\n",
            "Epoch 4: val_loss did not improve from 5.95548\n",
            "7/7 [==============================] - 0s 31ms/step - loss: 5.8384 - Note_loss: 3.0889 - Offset_loss: 0.4111 - Volume_loss: 1.0987 - Duration_loss: 1.2397 - val_loss: 6.4804 - val_Note_loss: 3.5076 - val_Offset_loss: 0.3789 - val_Volume_loss: 1.1396 - val_Duration_loss: 1.4544\n",
            "Epoch 5/400\n",
            "7/7 [==============================] - ETA: 0s - loss: 5.7641 - Note_loss: 3.0316 - Offset_loss: 0.3681 - Volume_loss: 1.1065 - Duration_loss: 1.2579\n",
            "Epoch 5: val_loss did not improve from 5.95548\n",
            "7/7 [==============================] - 0s 29ms/step - loss: 5.7641 - Note_loss: 3.0316 - Offset_loss: 0.3681 - Volume_loss: 1.1065 - Duration_loss: 1.2579 - val_loss: 6.3892 - val_Note_loss: 3.4426 - val_Offset_loss: 0.3289 - val_Volume_loss: 1.1356 - val_Duration_loss: 1.4821\n",
            "Epoch 6/400\n",
            "7/7 [==============================] - ETA: 0s - loss: 5.6877 - Note_loss: 2.9943 - Offset_loss: 0.3731 - Volume_loss: 1.0874 - Duration_loss: 1.2328\n",
            "Epoch 6: val_loss did not improve from 5.95548\n",
            "7/7 [==============================] - 0s 28ms/step - loss: 5.6877 - Note_loss: 2.9943 - Offset_loss: 0.3731 - Volume_loss: 1.0874 - Duration_loss: 1.2328 - val_loss: 6.3810 - val_Note_loss: 3.4428 - val_Offset_loss: 0.3211 - val_Volume_loss: 1.1423 - val_Duration_loss: 1.4747\n",
            "Epoch 7/400\n",
            "7/7 [==============================] - ETA: 0s - loss: 5.6366 - Note_loss: 2.9666 - Offset_loss: 0.3782 - Volume_loss: 1.0964 - Duration_loss: 1.1954\n",
            "Epoch 7: val_loss did not improve from 5.95548\n",
            "7/7 [==============================] - 0s 30ms/step - loss: 5.6366 - Note_loss: 2.9666 - Offset_loss: 0.3782 - Volume_loss: 1.0964 - Duration_loss: 1.1954 - val_loss: 6.4856 - val_Note_loss: 3.5103 - val_Offset_loss: 0.3180 - val_Volume_loss: 1.1232 - val_Duration_loss: 1.5340\n",
            "Epoch 8/400\n",
            "7/7 [==============================] - ETA: 0s - loss: 5.4921 - Note_loss: 2.9244 - Offset_loss: 0.3198 - Volume_loss: 1.0892 - Duration_loss: 1.1587\n",
            "Epoch 8: val_loss did not improve from 5.95548\n",
            "7/7 [==============================] - 0s 30ms/step - loss: 5.4921 - Note_loss: 2.9244 - Offset_loss: 0.3198 - Volume_loss: 1.0892 - Duration_loss: 1.1587 - val_loss: 6.5121 - val_Note_loss: 3.4560 - val_Offset_loss: 0.3086 - val_Volume_loss: 1.1199 - val_Duration_loss: 1.6276\n",
            "Epoch 9/400\n",
            "7/7 [==============================] - ETA: 0s - loss: 5.3457 - Note_loss: 2.8851 - Offset_loss: 0.2851 - Volume_loss: 1.0637 - Duration_loss: 1.1118\n",
            "Epoch 9: val_loss did not improve from 5.95548\n",
            "7/7 [==============================] - 0s 30ms/step - loss: 5.3457 - Note_loss: 2.8851 - Offset_loss: 0.2851 - Volume_loss: 1.0637 - Duration_loss: 1.1118 - val_loss: 6.6412 - val_Note_loss: 3.4872 - val_Offset_loss: 0.3039 - val_Volume_loss: 1.1217 - val_Duration_loss: 1.7283\n",
            "Epoch 10/400\n",
            "7/7 [==============================] - ETA: 0s - loss: 5.2172 - Note_loss: 2.8494 - Offset_loss: 0.2772 - Volume_loss: 1.0374 - Duration_loss: 1.0532\n",
            "Epoch 10: val_loss did not improve from 5.95548\n",
            "7/7 [==============================] - 0s 29ms/step - loss: 5.2172 - Note_loss: 2.8494 - Offset_loss: 0.2772 - Volume_loss: 1.0374 - Duration_loss: 1.0532 - val_loss: 6.6027 - val_Note_loss: 3.4512 - val_Offset_loss: 0.3547 - val_Volume_loss: 1.1098 - val_Duration_loss: 1.6870\n",
            "Epoch 11/400\n",
            "7/7 [==============================] - ETA: 0s - loss: 5.1204 - Note_loss: 2.8192 - Offset_loss: 0.2649 - Volume_loss: 1.0446 - Duration_loss: 0.9917\n",
            "Epoch 11: val_loss did not improve from 5.95548\n",
            "7/7 [==============================] - 0s 29ms/step - loss: 5.1204 - Note_loss: 2.8192 - Offset_loss: 0.2649 - Volume_loss: 1.0446 - Duration_loss: 0.9917 - val_loss: 6.6172 - val_Note_loss: 3.4705 - val_Offset_loss: 0.3296 - val_Volume_loss: 1.1442 - val_Duration_loss: 1.6729\n",
            "Epoch 12/400\n",
            "7/7 [==============================] - ETA: 0s - loss: 5.0080 - Note_loss: 2.7709 - Offset_loss: 0.2655 - Volume_loss: 1.0258 - Duration_loss: 0.9458\n",
            "Epoch 12: val_loss did not improve from 5.95548\n",
            "7/7 [==============================] - 0s 29ms/step - loss: 5.0080 - Note_loss: 2.7709 - Offset_loss: 0.2655 - Volume_loss: 1.0258 - Duration_loss: 0.9458 - val_loss: 6.7366 - val_Note_loss: 3.5179 - val_Offset_loss: 0.3498 - val_Volume_loss: 1.1406 - val_Duration_loss: 1.7282\n",
            "Epoch 13/400\n",
            "7/7 [==============================] - ETA: 0s - loss: 4.8234 - Note_loss: 2.7064 - Offset_loss: 0.2174 - Volume_loss: 1.0255 - Duration_loss: 0.8741\n",
            "Epoch 13: val_loss did not improve from 5.95548\n",
            "7/7 [==============================] - 0s 30ms/step - loss: 4.8234 - Note_loss: 2.7064 - Offset_loss: 0.2174 - Volume_loss: 1.0255 - Duration_loss: 0.8741 - val_loss: 6.8643 - val_Note_loss: 3.5738 - val_Offset_loss: 0.3391 - val_Volume_loss: 1.1572 - val_Duration_loss: 1.7942\n",
            "Epoch 14/400\n",
            "7/7 [==============================] - ETA: 0s - loss: 4.6935 - Note_loss: 2.6414 - Offset_loss: 0.2170 - Volume_loss: 1.0087 - Duration_loss: 0.8263\n",
            "Epoch 14: val_loss did not improve from 5.95548\n",
            "7/7 [==============================] - 0s 29ms/step - loss: 4.6935 - Note_loss: 2.6414 - Offset_loss: 0.2170 - Volume_loss: 1.0087 - Duration_loss: 0.8263 - val_loss: 6.8280 - val_Note_loss: 3.5233 - val_Offset_loss: 0.3592 - val_Volume_loss: 1.1337 - val_Duration_loss: 1.8118\n",
            "Epoch 15/400\n",
            "7/7 [==============================] - ETA: 0s - loss: 4.6419 - Note_loss: 2.6020 - Offset_loss: 0.2513 - Volume_loss: 0.9898 - Duration_loss: 0.7988\n",
            "Epoch 15: val_loss did not improve from 5.95548\n",
            "7/7 [==============================] - 0s 29ms/step - loss: 4.6419 - Note_loss: 2.6020 - Offset_loss: 0.2513 - Volume_loss: 0.9898 - Duration_loss: 0.7988 - val_loss: 7.0764 - val_Note_loss: 3.6657 - val_Offset_loss: 0.3591 - val_Volume_loss: 1.1296 - val_Duration_loss: 1.9220\n",
            "Epoch 16/400\n",
            "7/7 [==============================] - ETA: 0s - loss: 4.6112 - Note_loss: 2.5464 - Offset_loss: 0.3019 - Volume_loss: 0.9943 - Duration_loss: 0.7687\n",
            "Epoch 16: val_loss did not improve from 5.95548\n",
            "7/7 [==============================] - 0s 29ms/step - loss: 4.6112 - Note_loss: 2.5464 - Offset_loss: 0.3019 - Volume_loss: 0.9943 - Duration_loss: 0.7687 - val_loss: 7.2415 - val_Note_loss: 3.6805 - val_Offset_loss: 0.3613 - val_Volume_loss: 1.1533 - val_Duration_loss: 2.0464\n",
            "Epoch 17/400\n",
            "7/7 [==============================] - ETA: 0s - loss: 4.3499 - Note_loss: 2.4740 - Offset_loss: 0.1947 - Volume_loss: 0.9783 - Duration_loss: 0.7029\n",
            "Epoch 17: val_loss did not improve from 5.95548\n",
            "7/7 [==============================] - 0s 29ms/step - loss: 4.3499 - Note_loss: 2.4740 - Offset_loss: 0.1947 - Volume_loss: 0.9783 - Duration_loss: 0.7029 - val_loss: 7.0580 - val_Note_loss: 3.6519 - val_Offset_loss: 0.3424 - val_Volume_loss: 1.1306 - val_Duration_loss: 1.9331\n",
            "Epoch 18/400\n",
            "7/7 [==============================] - ETA: 0s - loss: 4.1065 - Note_loss: 2.3160 - Offset_loss: 0.1882 - Volume_loss: 0.9458 - Duration_loss: 0.6565\n",
            "Epoch 18: val_loss did not improve from 5.95548\n",
            "7/7 [==============================] - 0s 28ms/step - loss: 4.1065 - Note_loss: 2.3160 - Offset_loss: 0.1882 - Volume_loss: 0.9458 - Duration_loss: 0.6565 - val_loss: 7.9044 - val_Note_loss: 3.9736 - val_Offset_loss: 0.3599 - val_Volume_loss: 1.1323 - val_Duration_loss: 2.4387\n",
            "Epoch 19/400\n",
            "7/7 [==============================] - ETA: 0s - loss: 3.8458 - Note_loss: 2.2220 - Offset_loss: 0.1276 - Volume_loss: 0.9297 - Duration_loss: 0.5665\n",
            "Epoch 19: val_loss did not improve from 5.95548\n",
            "7/7 [==============================] - 0s 28ms/step - loss: 3.8458 - Note_loss: 2.2220 - Offset_loss: 0.1276 - Volume_loss: 0.9297 - Duration_loss: 0.5665 - val_loss: 8.7166 - val_Note_loss: 4.2289 - val_Offset_loss: 0.3287 - val_Volume_loss: 1.1549 - val_Duration_loss: 3.0041\n",
            "Epoch 20/400\n",
            "7/7 [==============================] - ETA: 0s - loss: 3.6691 - Note_loss: 2.1245 - Offset_loss: 0.1362 - Volume_loss: 0.9174 - Duration_loss: 0.4910\n",
            "Epoch 20: val_loss did not improve from 5.95548\n",
            "7/7 [==============================] - 0s 27ms/step - loss: 3.6691 - Note_loss: 2.1245 - Offset_loss: 0.1362 - Volume_loss: 0.9174 - Duration_loss: 0.4910 - val_loss: 9.3827 - val_Note_loss: 4.5081 - val_Offset_loss: 0.3541 - val_Volume_loss: 1.1617 - val_Duration_loss: 3.3588\n",
            "Epoch 21/400\n",
            "7/7 [==============================] - ETA: 0s - loss: 3.5061 - Note_loss: 2.0223 - Offset_loss: 0.1348 - Volume_loss: 0.8833 - Duration_loss: 0.4656\n",
            "Epoch 21: val_loss did not improve from 5.95548\n",
            "7/7 [==============================] - 0s 28ms/step - loss: 3.5061 - Note_loss: 2.0223 - Offset_loss: 0.1348 - Volume_loss: 0.8833 - Duration_loss: 0.4656 - val_loss: 9.4820 - val_Note_loss: 4.7044 - val_Offset_loss: 0.3133 - val_Volume_loss: 1.1855 - val_Duration_loss: 3.2788\n",
            "Epoch 22/400\n",
            "7/7 [==============================] - ETA: 0s - loss: 3.3163 - Note_loss: 1.8797 - Offset_loss: 0.1438 - Volume_loss: 0.8674 - Duration_loss: 0.4253\n",
            "Epoch 22: val_loss did not improve from 5.95548\n",
            "7/7 [==============================] - 0s 29ms/step - loss: 3.3163 - Note_loss: 1.8797 - Offset_loss: 0.1438 - Volume_loss: 0.8674 - Duration_loss: 0.4253 - val_loss: 9.9822 - val_Note_loss: 4.8267 - val_Offset_loss: 0.3344 - val_Volume_loss: 1.1745 - val_Duration_loss: 3.6466\n",
            "Epoch 23/400\n",
            "7/7 [==============================] - ETA: 0s - loss: 3.2880 - Note_loss: 1.8071 - Offset_loss: 0.1299 - Volume_loss: 0.8768 - Duration_loss: 0.4743\n",
            "Epoch 23: val_loss did not improve from 5.95548\n",
            "7/7 [==============================] - 0s 29ms/step - loss: 3.2880 - Note_loss: 1.8071 - Offset_loss: 0.1299 - Volume_loss: 0.8768 - Duration_loss: 0.4743 - val_loss: 10.1386 - val_Note_loss: 4.9892 - val_Offset_loss: 0.3131 - val_Volume_loss: 1.1835 - val_Duration_loss: 3.6527\n",
            "Epoch 24/400\n",
            "7/7 [==============================] - ETA: 0s - loss: 3.1313 - Note_loss: 1.7630 - Offset_loss: 0.1250 - Volume_loss: 0.8575 - Duration_loss: 0.3858\n",
            "Epoch 24: val_loss did not improve from 5.95548\n",
            "7/7 [==============================] - 0s 28ms/step - loss: 3.1313 - Note_loss: 1.7630 - Offset_loss: 0.1250 - Volume_loss: 0.8575 - Duration_loss: 0.3858 - val_loss: 10.2448 - val_Note_loss: 5.0845 - val_Offset_loss: 0.3071 - val_Volume_loss: 1.1482 - val_Duration_loss: 3.7050\n",
            "Epoch 25/400\n",
            "7/7 [==============================] - ETA: 0s - loss: 2.8586 - Note_loss: 1.5980 - Offset_loss: 0.0975 - Volume_loss: 0.8084 - Duration_loss: 0.3546\n",
            "Epoch 25: val_loss did not improve from 5.95548\n",
            "7/7 [==============================] - 0s 29ms/step - loss: 2.8586 - Note_loss: 1.5980 - Offset_loss: 0.0975 - Volume_loss: 0.8084 - Duration_loss: 0.3546 - val_loss: 10.4809 - val_Note_loss: 5.2642 - val_Offset_loss: 0.3110 - val_Volume_loss: 1.1438 - val_Duration_loss: 3.7619\n",
            "Epoch 26/400\n",
            "7/7 [==============================] - ETA: 0s - loss: 2.7972 - Note_loss: 1.5368 - Offset_loss: 0.1064 - Volume_loss: 0.8032 - Duration_loss: 0.3508\n",
            "Epoch 26: val_loss did not improve from 5.95548\n",
            "7/7 [==============================] - 0s 29ms/step - loss: 2.7972 - Note_loss: 1.5368 - Offset_loss: 0.1064 - Volume_loss: 0.8032 - Duration_loss: 0.3508 - val_loss: 10.6298 - val_Note_loss: 5.3663 - val_Offset_loss: 0.3020 - val_Volume_loss: 1.0757 - val_Duration_loss: 3.8859\n",
            "Epoch 27/400\n",
            "7/7 [==============================] - ETA: 0s - loss: 2.6818 - Note_loss: 1.4169 - Offset_loss: 0.1223 - Volume_loss: 0.7818 - Duration_loss: 0.3609\n",
            "Epoch 27: val_loss did not improve from 5.95548\n",
            "7/7 [==============================] - 0s 48ms/step - loss: 2.6818 - Note_loss: 1.4169 - Offset_loss: 0.1223 - Volume_loss: 0.7818 - Duration_loss: 0.3609 - val_loss: 11.7409 - val_Note_loss: 6.2011 - val_Offset_loss: 0.3135 - val_Volume_loss: 1.1154 - val_Duration_loss: 4.1108\n",
            "Epoch 28/400\n",
            "7/7 [==============================] - ETA: 0s - loss: 2.6984 - Note_loss: 1.4012 - Offset_loss: 0.1152 - Volume_loss: 0.7839 - Duration_loss: 0.3981\n",
            "Epoch 28: val_loss did not improve from 5.95548\n",
            "7/7 [==============================] - 0s 45ms/step - loss: 2.6984 - Note_loss: 1.4012 - Offset_loss: 0.1152 - Volume_loss: 0.7839 - Duration_loss: 0.3981 - val_loss: 11.3640 - val_Note_loss: 6.0309 - val_Offset_loss: 0.3012 - val_Volume_loss: 1.0951 - val_Duration_loss: 3.9368\n",
            "Epoch 29/400\n",
            "7/7 [==============================] - ETA: 0s - loss: 2.5684 - Note_loss: 1.3634 - Offset_loss: 0.1171 - Volume_loss: 0.7508 - Duration_loss: 0.3370\n",
            "Epoch 29: val_loss did not improve from 5.95548\n",
            "7/7 [==============================] - 0s 44ms/step - loss: 2.5684 - Note_loss: 1.3634 - Offset_loss: 0.1171 - Volume_loss: 0.7508 - Duration_loss: 0.3370 - val_loss: 11.8536 - val_Note_loss: 6.2374 - val_Offset_loss: 0.3212 - val_Volume_loss: 1.0951 - val_Duration_loss: 4.1998\n",
            "Epoch 30/400\n",
            "7/7 [==============================] - ETA: 0s - loss: 2.5004 - Note_loss: 1.2754 - Offset_loss: 0.1402 - Volume_loss: 0.7645 - Duration_loss: 0.3202\n",
            "Epoch 30: val_loss did not improve from 5.95548\n",
            "7/7 [==============================] - 0s 46ms/step - loss: 2.5004 - Note_loss: 1.2754 - Offset_loss: 0.1402 - Volume_loss: 0.7645 - Duration_loss: 0.3202 - val_loss: 10.9873 - val_Note_loss: 5.8333 - val_Offset_loss: 0.2977 - val_Volume_loss: 1.0946 - val_Duration_loss: 3.7617\n",
            "Epoch 31/400\n",
            "7/7 [==============================] - ETA: 0s - loss: 2.5488 - Note_loss: 1.2931 - Offset_loss: 0.1822 - Volume_loss: 0.7742 - Duration_loss: 0.2993\n",
            "Epoch 31: val_loss did not improve from 5.95548\n",
            "7/7 [==============================] - 0s 45ms/step - loss: 2.5488 - Note_loss: 1.2931 - Offset_loss: 0.1822 - Volume_loss: 0.7742 - Duration_loss: 0.2993 - val_loss: 11.3696 - val_Note_loss: 6.0841 - val_Offset_loss: 0.3012 - val_Volume_loss: 1.0542 - val_Duration_loss: 3.9301\n",
            "Epoch 32/400\n",
            "7/7 [==============================] - ETA: 0s - loss: 2.3921 - Note_loss: 1.2498 - Offset_loss: 0.1214 - Volume_loss: 0.7504 - Duration_loss: 0.2705\n",
            "Epoch 32: val_loss did not improve from 5.95548\n",
            "7/7 [==============================] - 0s 47ms/step - loss: 2.3921 - Note_loss: 1.2498 - Offset_loss: 0.1214 - Volume_loss: 0.7504 - Duration_loss: 0.2705 - val_loss: 11.6756 - val_Note_loss: 6.2870 - val_Offset_loss: 0.3003 - val_Volume_loss: 1.0474 - val_Duration_loss: 4.0409\n",
            "Epoch 33/400\n",
            "7/7 [==============================] - ETA: 0s - loss: 2.3801 - Note_loss: 1.2116 - Offset_loss: 0.1536 - Volume_loss: 0.7253 - Duration_loss: 0.2895\n",
            "Epoch 33: val_loss did not improve from 5.95548\n",
            "7/7 [==============================] - 0s 46ms/step - loss: 2.3801 - Note_loss: 1.2116 - Offset_loss: 0.1536 - Volume_loss: 0.7253 - Duration_loss: 0.2895 - val_loss: 11.4584 - val_Note_loss: 6.1845 - val_Offset_loss: 0.3424 - val_Volume_loss: 1.0177 - val_Duration_loss: 3.9138\n",
            "Epoch 34/400\n",
            "7/7 [==============================] - ETA: 0s - loss: 2.3300 - Note_loss: 1.1457 - Offset_loss: 0.1605 - Volume_loss: 0.6969 - Duration_loss: 0.3269\n",
            "Epoch 34: val_loss did not improve from 5.95548\n",
            "7/7 [==============================] - 0s 44ms/step - loss: 2.3300 - Note_loss: 1.1457 - Offset_loss: 0.1605 - Volume_loss: 0.6969 - Duration_loss: 0.3269 - val_loss: 12.9608 - val_Note_loss: 7.1942 - val_Offset_loss: 0.3187 - val_Volume_loss: 1.1948 - val_Duration_loss: 4.2531\n",
            "Epoch 35/400\n",
            "7/7 [==============================] - ETA: 0s - loss: 2.2244 - Note_loss: 1.1584 - Offset_loss: 0.1129 - Volume_loss: 0.6839 - Duration_loss: 0.2691\n",
            "Epoch 35: val_loss did not improve from 5.95548\n",
            "7/7 [==============================] - 0s 29ms/step - loss: 2.2244 - Note_loss: 1.1584 - Offset_loss: 0.1129 - Volume_loss: 0.6839 - Duration_loss: 0.2691 - val_loss: 11.7922 - val_Note_loss: 6.3128 - val_Offset_loss: 0.3277 - val_Volume_loss: 1.0954 - val_Duration_loss: 4.0564\n",
            "Epoch 36/400\n",
            "7/7 [==============================] - ETA: 0s - loss: 2.1069 - Note_loss: 1.0738 - Offset_loss: 0.0972 - Volume_loss: 0.6934 - Duration_loss: 0.2424\n",
            "Epoch 36: val_loss did not improve from 5.95548\n",
            "7/7 [==============================] - 0s 29ms/step - loss: 2.1069 - Note_loss: 1.0738 - Offset_loss: 0.0972 - Volume_loss: 0.6934 - Duration_loss: 0.2424 - val_loss: 12.3387 - val_Note_loss: 6.5937 - val_Offset_loss: 0.3356 - val_Volume_loss: 1.1135 - val_Duration_loss: 4.2960\n",
            "Epoch 37/400\n",
            "7/7 [==============================] - ETA: 0s - loss: 2.0420 - Note_loss: 0.9893 - Offset_loss: 0.0868 - Volume_loss: 0.7124 - Duration_loss: 0.2536\n",
            "Epoch 37: val_loss did not improve from 5.95548\n",
            "7/7 [==============================] - 0s 30ms/step - loss: 2.0420 - Note_loss: 0.9893 - Offset_loss: 0.0868 - Volume_loss: 0.7124 - Duration_loss: 0.2536 - val_loss: 12.6154 - val_Note_loss: 6.9135 - val_Offset_loss: 0.3386 - val_Volume_loss: 1.0399 - val_Duration_loss: 4.3233\n",
            "Epoch 38/400\n",
            "7/7 [==============================] - ETA: 0s - loss: 1.9402 - Note_loss: 1.0182 - Offset_loss: 0.0867 - Volume_loss: 0.6037 - Duration_loss: 0.2317\n",
            "Epoch 38: val_loss did not improve from 5.95548\n",
            "7/7 [==============================] - 0s 29ms/step - loss: 1.9402 - Note_loss: 1.0182 - Offset_loss: 0.0867 - Volume_loss: 0.6037 - Duration_loss: 0.2317 - val_loss: 13.3868 - val_Note_loss: 7.2662 - val_Offset_loss: 0.3317 - val_Volume_loss: 1.0719 - val_Duration_loss: 4.7171\n",
            "Epoch 39/400\n",
            "7/7 [==============================] - ETA: 0s - loss: 2.0224 - Note_loss: 0.9980 - Offset_loss: 0.1076 - Volume_loss: 0.6582 - Duration_loss: 0.2586\n",
            "Epoch 39: val_loss did not improve from 5.95548\n",
            "7/7 [==============================] - 0s 28ms/step - loss: 2.0224 - Note_loss: 0.9980 - Offset_loss: 0.1076 - Volume_loss: 0.6582 - Duration_loss: 0.2586 - val_loss: 14.0483 - val_Note_loss: 7.8308 - val_Offset_loss: 0.3350 - val_Volume_loss: 1.1139 - val_Duration_loss: 4.7685\n",
            "Epoch 40/400\n",
            "7/7 [==============================] - ETA: 0s - loss: 2.0748 - Note_loss: 1.0654 - Offset_loss: 0.1105 - Volume_loss: 0.6610 - Duration_loss: 0.2380\n",
            "Epoch 40: val_loss did not improve from 5.95548\n",
            "7/7 [==============================] - 0s 29ms/step - loss: 2.0748 - Note_loss: 1.0654 - Offset_loss: 0.1105 - Volume_loss: 0.6610 - Duration_loss: 0.2380 - val_loss: 13.8468 - val_Note_loss: 7.6802 - val_Offset_loss: 0.3277 - val_Volume_loss: 1.1340 - val_Duration_loss: 4.7050\n",
            "Epoch 41/400\n",
            "7/7 [==============================] - ETA: 0s - loss: 1.8936 - Note_loss: 0.9045 - Offset_loss: 0.1051 - Volume_loss: 0.6299 - Duration_loss: 0.2541\n",
            "Epoch 41: val_loss did not improve from 5.95548\n",
            "7/7 [==============================] - 0s 28ms/step - loss: 1.8936 - Note_loss: 0.9045 - Offset_loss: 0.1051 - Volume_loss: 0.6299 - Duration_loss: 0.2541 - val_loss: 14.5814 - val_Note_loss: 8.1242 - val_Offset_loss: 0.3494 - val_Volume_loss: 1.0568 - val_Duration_loss: 5.0510\n",
            "Epoch 42/400\n",
            "7/7 [==============================] - ETA: 0s - loss: 1.8316 - Note_loss: 0.8895 - Offset_loss: 0.0915 - Volume_loss: 0.6159 - Duration_loss: 0.2346\n",
            "Epoch 42: val_loss did not improve from 5.95548\n",
            "7/7 [==============================] - 0s 29ms/step - loss: 1.8316 - Note_loss: 0.8895 - Offset_loss: 0.0915 - Volume_loss: 0.6159 - Duration_loss: 0.2346 - val_loss: 14.8053 - val_Note_loss: 8.4733 - val_Offset_loss: 0.3263 - val_Volume_loss: 1.1717 - val_Duration_loss: 4.8341\n",
            "Epoch 43/400\n",
            "7/7 [==============================] - ETA: 0s - loss: 1.8338 - Note_loss: 0.8956 - Offset_loss: 0.0908 - Volume_loss: 0.6333 - Duration_loss: 0.2141\n",
            "Epoch 43: val_loss did not improve from 5.95548\n",
            "7/7 [==============================] - 0s 29ms/step - loss: 1.8338 - Note_loss: 0.8956 - Offset_loss: 0.0908 - Volume_loss: 0.6333 - Duration_loss: 0.2141 - val_loss: 15.1687 - val_Note_loss: 8.5336 - val_Offset_loss: 0.3234 - val_Volume_loss: 1.1681 - val_Duration_loss: 5.1436\n",
            "Epoch 44/400\n",
            "7/7 [==============================] - ETA: 0s - loss: 1.7290 - Note_loss: 0.8392 - Offset_loss: 0.0760 - Volume_loss: 0.6177 - Duration_loss: 0.1961\n",
            "Epoch 44: val_loss did not improve from 5.95548\n",
            "7/7 [==============================] - 0s 38ms/step - loss: 1.7290 - Note_loss: 0.8392 - Offset_loss: 0.0760 - Volume_loss: 0.6177 - Duration_loss: 0.1961 - val_loss: 15.4930 - val_Note_loss: 8.5706 - val_Offset_loss: 0.3593 - val_Volume_loss: 1.2002 - val_Duration_loss: 5.3629\n",
            "Epoch 45/400\n",
            "7/7 [==============================] - ETA: 0s - loss: 1.6821 - Note_loss: 0.7968 - Offset_loss: 0.0736 - Volume_loss: 0.6091 - Duration_loss: 0.2026\n",
            "Epoch 45: val_loss did not improve from 5.95548\n",
            "7/7 [==============================] - 0s 28ms/step - loss: 1.6821 - Note_loss: 0.7968 - Offset_loss: 0.0736 - Volume_loss: 0.6091 - Duration_loss: 0.2026 - val_loss: 16.0719 - val_Note_loss: 9.2135 - val_Offset_loss: 0.3295 - val_Volume_loss: 1.2578 - val_Duration_loss: 5.2712\n",
            "Epoch 46/400\n",
            "7/7 [==============================] - ETA: 0s - loss: 1.6293 - Note_loss: 0.7956 - Offset_loss: 0.0748 - Volume_loss: 0.5859 - Duration_loss: 0.1730\n",
            "Epoch 46: val_loss did not improve from 5.95548\n",
            "7/7 [==============================] - 0s 30ms/step - loss: 1.6293 - Note_loss: 0.7956 - Offset_loss: 0.0748 - Volume_loss: 0.5859 - Duration_loss: 0.1730 - val_loss: 15.4087 - val_Note_loss: 8.8666 - val_Offset_loss: 0.3417 - val_Volume_loss: 1.0852 - val_Duration_loss: 5.1152\n",
            "Epoch 47/400\n",
            "7/7 [==============================] - ETA: 0s - loss: 1.6583 - Note_loss: 0.7938 - Offset_loss: 0.0642 - Volume_loss: 0.5890 - Duration_loss: 0.2113\n",
            "Epoch 47: val_loss did not improve from 5.95548\n",
            "7/7 [==============================] - 0s 27ms/step - loss: 1.6583 - Note_loss: 0.7938 - Offset_loss: 0.0642 - Volume_loss: 0.5890 - Duration_loss: 0.2113 - val_loss: 15.8224 - val_Note_loss: 8.9820 - val_Offset_loss: 0.3256 - val_Volume_loss: 1.0527 - val_Duration_loss: 5.4621\n",
            "Epoch 48/400\n",
            "7/7 [==============================] - ETA: 0s - loss: 1.5504 - Note_loss: 0.7225 - Offset_loss: 0.0676 - Volume_loss: 0.5982 - Duration_loss: 0.1622\n",
            "Epoch 48: val_loss did not improve from 5.95548\n",
            "7/7 [==============================] - 0s 27ms/step - loss: 1.5504 - Note_loss: 0.7225 - Offset_loss: 0.0676 - Volume_loss: 0.5982 - Duration_loss: 0.1622 - val_loss: 16.4019 - val_Note_loss: 9.1792 - val_Offset_loss: 0.3211 - val_Volume_loss: 1.1402 - val_Duration_loss: 5.7614\n",
            "Epoch 49/400\n",
            "7/7 [==============================] - ETA: 0s - loss: 1.6236 - Note_loss: 0.7692 - Offset_loss: 0.0529 - Volume_loss: 0.6008 - Duration_loss: 0.2008\n",
            "Epoch 49: val_loss did not improve from 5.95548\n",
            "7/7 [==============================] - 0s 32ms/step - loss: 1.6236 - Note_loss: 0.7692 - Offset_loss: 0.0529 - Volume_loss: 0.6008 - Duration_loss: 0.2008 - val_loss: 16.9914 - val_Note_loss: 9.6580 - val_Offset_loss: 0.3439 - val_Volume_loss: 1.1515 - val_Duration_loss: 5.8381\n",
            "Epoch 50/400\n",
            "7/7 [==============================] - ETA: 0s - loss: 1.5054 - Note_loss: 0.7606 - Offset_loss: 0.0633 - Volume_loss: 0.5191 - Duration_loss: 0.1625\n",
            "Epoch 50: val_loss did not improve from 5.95548\n",
            "7/7 [==============================] - 0s 36ms/step - loss: 1.5054 - Note_loss: 0.7606 - Offset_loss: 0.0633 - Volume_loss: 0.5191 - Duration_loss: 0.1625 - val_loss: 16.6226 - val_Note_loss: 9.4449 - val_Offset_loss: 0.3496 - val_Volume_loss: 1.1165 - val_Duration_loss: 5.7117\n",
            "Epoch 51/400\n",
            "7/7 [==============================] - ETA: 0s - loss: 1.4336 - Note_loss: 0.6925 - Offset_loss: 0.0814 - Volume_loss: 0.5014 - Duration_loss: 0.1582\n",
            "Epoch 51: val_loss did not improve from 5.95548\n",
            "7/7 [==============================] - 0s 29ms/step - loss: 1.4336 - Note_loss: 0.6925 - Offset_loss: 0.0814 - Volume_loss: 0.5014 - Duration_loss: 0.1582 - val_loss: 17.2118 - val_Note_loss: 9.7185 - val_Offset_loss: 0.3322 - val_Volume_loss: 1.2052 - val_Duration_loss: 5.9559\n",
            "Epoch 52/400\n",
            "7/7 [==============================] - ETA: 0s - loss: 1.4550 - Note_loss: 0.7179 - Offset_loss: 0.0622 - Volume_loss: 0.5130 - Duration_loss: 0.1619\n",
            "Epoch 52: val_loss did not improve from 5.95548\n",
            "7/7 [==============================] - 0s 29ms/step - loss: 1.4550 - Note_loss: 0.7179 - Offset_loss: 0.0622 - Volume_loss: 0.5130 - Duration_loss: 0.1619 - val_loss: 17.9135 - val_Note_loss: 10.0677 - val_Offset_loss: 0.3432 - val_Volume_loss: 1.1960 - val_Duration_loss: 6.3066\n",
            "Epoch 53/400\n",
            "7/7 [==============================] - ETA: 0s - loss: 1.4052 - Note_loss: 0.6700 - Offset_loss: 0.0593 - Volume_loss: 0.5344 - Duration_loss: 0.1414\n",
            "Epoch 53: val_loss did not improve from 5.95548\n",
            "7/7 [==============================] - 0s 30ms/step - loss: 1.4052 - Note_loss: 0.6700 - Offset_loss: 0.0593 - Volume_loss: 0.5344 - Duration_loss: 0.1414 - val_loss: 18.5917 - val_Note_loss: 10.8730 - val_Offset_loss: 0.3128 - val_Volume_loss: 1.1613 - val_Duration_loss: 6.2445\n",
            "Epoch 54/400\n",
            "7/7 [==============================] - ETA: 0s - loss: 1.3285 - Note_loss: 0.6097 - Offset_loss: 0.0482 - Volume_loss: 0.5101 - Duration_loss: 0.1604\n",
            "Epoch 54: val_loss did not improve from 5.95548\n",
            "7/7 [==============================] - 0s 30ms/step - loss: 1.3285 - Note_loss: 0.6097 - Offset_loss: 0.0482 - Volume_loss: 0.5101 - Duration_loss: 0.1604 - val_loss: 17.7082 - val_Note_loss: 10.4977 - val_Offset_loss: 0.3125 - val_Volume_loss: 1.1684 - val_Duration_loss: 5.7296\n",
            "Epoch 55/400\n",
            "7/7 [==============================] - ETA: 0s - loss: 1.3032 - Note_loss: 0.6094 - Offset_loss: 0.0599 - Volume_loss: 0.4823 - Duration_loss: 0.1516\n",
            "Epoch 55: val_loss did not improve from 5.95548\n",
            "7/7 [==============================] - 0s 28ms/step - loss: 1.3032 - Note_loss: 0.6094 - Offset_loss: 0.0599 - Volume_loss: 0.4823 - Duration_loss: 0.1516 - val_loss: 17.6710 - val_Note_loss: 10.3019 - val_Offset_loss: 0.3255 - val_Volume_loss: 1.2229 - val_Duration_loss: 5.8207\n",
            "Epoch 56/400\n",
            "7/7 [==============================] - ETA: 0s - loss: 1.3102 - Note_loss: 0.5908 - Offset_loss: 0.0719 - Volume_loss: 0.4969 - Duration_loss: 0.1505\n",
            "Epoch 56: val_loss did not improve from 5.95548\n",
            "7/7 [==============================] - 0s 28ms/step - loss: 1.3102 - Note_loss: 0.5908 - Offset_loss: 0.0719 - Volume_loss: 0.4969 - Duration_loss: 0.1505 - val_loss: 17.7608 - val_Note_loss: 10.4083 - val_Offset_loss: 0.3234 - val_Volume_loss: 1.2111 - val_Duration_loss: 5.8181\n",
            "Epoch 57/400\n",
            "7/7 [==============================] - ETA: 0s - loss: 1.3093 - Note_loss: 0.5819 - Offset_loss: 0.0508 - Volume_loss: 0.5298 - Duration_loss: 0.1468\n",
            "Epoch 57: val_loss did not improve from 5.95548\n",
            "7/7 [==============================] - 0s 29ms/step - loss: 1.3093 - Note_loss: 0.5819 - Offset_loss: 0.0508 - Volume_loss: 0.5298 - Duration_loss: 0.1468 - val_loss: 18.2881 - val_Note_loss: 10.8980 - val_Offset_loss: 0.3041 - val_Volume_loss: 1.1743 - val_Duration_loss: 5.9117\n",
            "Epoch 58/400\n",
            "7/7 [==============================] - ETA: 0s - loss: 1.2611 - Note_loss: 0.5957 - Offset_loss: 0.0560 - Volume_loss: 0.4777 - Duration_loss: 0.1317\n",
            "Epoch 58: val_loss did not improve from 5.95548\n",
            "7/7 [==============================] - 0s 33ms/step - loss: 1.2611 - Note_loss: 0.5957 - Offset_loss: 0.0560 - Volume_loss: 0.4777 - Duration_loss: 0.1317 - val_loss: 19.1678 - val_Note_loss: 11.6686 - val_Offset_loss: 0.3214 - val_Volume_loss: 1.0972 - val_Duration_loss: 6.0805\n",
            "Epoch 59/400\n",
            "7/7 [==============================] - ETA: 0s - loss: 1.1745 - Note_loss: 0.5742 - Offset_loss: 0.0541 - Volume_loss: 0.4071 - Duration_loss: 0.1391\n",
            "Epoch 59: val_loss did not improve from 5.95548\n",
            "7/7 [==============================] - 0s 31ms/step - loss: 1.1745 - Note_loss: 0.5742 - Offset_loss: 0.0541 - Volume_loss: 0.4071 - Duration_loss: 0.1391 - val_loss: 18.5453 - val_Note_loss: 11.1226 - val_Offset_loss: 0.3137 - val_Volume_loss: 1.1961 - val_Duration_loss: 5.9129\n",
            "Epoch 60/400\n",
            "7/7 [==============================] - ETA: 0s - loss: 1.2995 - Note_loss: 0.6404 - Offset_loss: 0.0545 - Volume_loss: 0.4609 - Duration_loss: 0.1437\n",
            "Epoch 60: val_loss did not improve from 5.95548\n",
            "7/7 [==============================] - 0s 29ms/step - loss: 1.2995 - Note_loss: 0.6404 - Offset_loss: 0.0545 - Volume_loss: 0.4609 - Duration_loss: 0.1437 - val_loss: 19.9885 - val_Note_loss: 12.3654 - val_Offset_loss: 0.3017 - val_Volume_loss: 1.2064 - val_Duration_loss: 6.1150\n",
            "Epoch 61/400\n",
            "7/7 [==============================] - ETA: 0s - loss: 1.3337 - Note_loss: 0.5869 - Offset_loss: 0.0687 - Volume_loss: 0.4484 - Duration_loss: 0.2297\n",
            "Epoch 61: val_loss did not improve from 5.95548\n",
            "7/7 [==============================] - 0s 30ms/step - loss: 1.3337 - Note_loss: 0.5869 - Offset_loss: 0.0687 - Volume_loss: 0.4484 - Duration_loss: 0.2297 - val_loss: 19.4132 - val_Note_loss: 11.7365 - val_Offset_loss: 0.3079 - val_Volume_loss: 1.2571 - val_Duration_loss: 6.1116\n",
            "Epoch 62/400\n",
            "7/7 [==============================] - ETA: 0s - loss: 1.3298 - Note_loss: 0.5807 - Offset_loss: 0.0610 - Volume_loss: 0.4423 - Duration_loss: 0.2458\n",
            "Epoch 62: val_loss did not improve from 5.95548\n",
            "7/7 [==============================] - 0s 37ms/step - loss: 1.3298 - Note_loss: 0.5807 - Offset_loss: 0.0610 - Volume_loss: 0.4423 - Duration_loss: 0.2458 - val_loss: 18.2070 - val_Note_loss: 11.0329 - val_Offset_loss: 0.3031 - val_Volume_loss: 1.2199 - val_Duration_loss: 5.6510\n",
            "Epoch 63/400\n",
            "7/7 [==============================] - ETA: 0s - loss: 1.2209 - Note_loss: 0.5958 - Offset_loss: 0.0592 - Volume_loss: 0.4209 - Duration_loss: 0.1449\n",
            "Epoch 63: val_loss did not improve from 5.95548\n",
            "7/7 [==============================] - 0s 36ms/step - loss: 1.2209 - Note_loss: 0.5958 - Offset_loss: 0.0592 - Volume_loss: 0.4209 - Duration_loss: 0.1449 - val_loss: 18.1976 - val_Note_loss: 11.3744 - val_Offset_loss: 0.3028 - val_Volume_loss: 1.0807 - val_Duration_loss: 5.4396\n",
            "Epoch 64/400\n",
            "7/7 [==============================] - ETA: 0s - loss: 1.3116 - Note_loss: 0.6885 - Offset_loss: 0.0609 - Volume_loss: 0.4117 - Duration_loss: 0.1505\n",
            "Epoch 64: val_loss did not improve from 5.95548\n",
            "7/7 [==============================] - 0s 30ms/step - loss: 1.3116 - Note_loss: 0.6885 - Offset_loss: 0.0609 - Volume_loss: 0.4117 - Duration_loss: 0.1505 - val_loss: 18.8169 - val_Note_loss: 11.3969 - val_Offset_loss: 0.3142 - val_Volume_loss: 1.1169 - val_Duration_loss: 5.9889\n",
            "Epoch 65/400\n",
            "7/7 [==============================] - ETA: 0s - loss: 1.2472 - Note_loss: 0.5951 - Offset_loss: 0.0677 - Volume_loss: 0.4348 - Duration_loss: 0.1497\n",
            "Epoch 65: val_loss did not improve from 5.95548\n",
            "7/7 [==============================] - 0s 29ms/step - loss: 1.2472 - Note_loss: 0.5951 - Offset_loss: 0.0677 - Volume_loss: 0.4348 - Duration_loss: 0.1497 - val_loss: 18.6118 - val_Note_loss: 11.0396 - val_Offset_loss: 0.2993 - val_Volume_loss: 1.1659 - val_Duration_loss: 6.1071\n",
            "Epoch 66/400\n",
            "7/7 [==============================] - ETA: 0s - loss: 1.2187 - Note_loss: 0.5677 - Offset_loss: 0.0672 - Volume_loss: 0.4582 - Duration_loss: 0.1256\n",
            "Epoch 66: val_loss did not improve from 5.95548\n",
            "7/7 [==============================] - 0s 31ms/step - loss: 1.2187 - Note_loss: 0.5677 - Offset_loss: 0.0672 - Volume_loss: 0.4582 - Duration_loss: 0.1256 - val_loss: 19.7277 - val_Note_loss: 12.3409 - val_Offset_loss: 0.2965 - val_Volume_loss: 1.1254 - val_Duration_loss: 5.9649\n",
            "Epoch 67/400\n",
            "7/7 [==============================] - ETA: 0s - loss: 1.2084 - Note_loss: 0.5588 - Offset_loss: 0.0863 - Volume_loss: 0.4326 - Duration_loss: 0.1307\n",
            "Epoch 67: val_loss did not improve from 5.95548\n",
            "7/7 [==============================] - 0s 30ms/step - loss: 1.2084 - Note_loss: 0.5588 - Offset_loss: 0.0863 - Volume_loss: 0.4326 - Duration_loss: 0.1307 - val_loss: 19.9304 - val_Note_loss: 12.5980 - val_Offset_loss: 0.2897 - val_Volume_loss: 1.1497 - val_Duration_loss: 5.8931\n",
            "Epoch 68/400\n",
            "6/7 [========================>.....] - ETA: 0s - loss: 1.1154 - Note_loss: 0.5681 - Offset_loss: 0.0545 - Volume_loss: 0.3626 - Duration_loss: 0.1303\n",
            "Epoch 68: val_loss did not improve from 5.95548\n",
            "7/7 [==============================] - 0s 33ms/step - loss: 1.1042 - Note_loss: 0.5593 - Offset_loss: 0.0555 - Volume_loss: 0.3607 - Duration_loss: 0.1287 - val_loss: 21.2911 - val_Note_loss: 13.7174 - val_Offset_loss: 0.3078 - val_Volume_loss: 1.1701 - val_Duration_loss: 6.0958\n",
            "Epoch 69/400\n",
            "7/7 [==============================] - ETA: 0s - loss: 1.1101 - Note_loss: 0.4988 - Offset_loss: 0.0578 - Volume_loss: 0.4017 - Duration_loss: 0.1517\n",
            "Epoch 69: val_loss did not improve from 5.95548\n",
            "7/7 [==============================] - 0s 30ms/step - loss: 1.1101 - Note_loss: 0.4988 - Offset_loss: 0.0578 - Volume_loss: 0.4017 - Duration_loss: 0.1517 - val_loss: 21.6272 - val_Note_loss: 13.9670 - val_Offset_loss: 0.3138 - val_Volume_loss: 1.1365 - val_Duration_loss: 6.2100\n",
            "Epoch 70/400\n",
            "7/7 [==============================] - ETA: 0s - loss: 1.0180 - Note_loss: 0.4772 - Offset_loss: 0.0565 - Volume_loss: 0.4044 - Duration_loss: 0.0800\n",
            "Epoch 70: val_loss did not improve from 5.95548\n",
            "7/7 [==============================] - 0s 31ms/step - loss: 1.0180 - Note_loss: 0.4772 - Offset_loss: 0.0565 - Volume_loss: 0.4044 - Duration_loss: 0.0800 - val_loss: 20.8466 - val_Note_loss: 13.4881 - val_Offset_loss: 0.3097 - val_Volume_loss: 1.2109 - val_Duration_loss: 5.8379\n",
            "Epoch 71/400\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.9356 - Note_loss: 0.4191 - Offset_loss: 0.0538 - Volume_loss: 0.3507 - Duration_loss: 0.1121\n",
            "Epoch 71: val_loss did not improve from 5.95548\n",
            "7/7 [==============================] - 0s 30ms/step - loss: 0.9356 - Note_loss: 0.4191 - Offset_loss: 0.0538 - Volume_loss: 0.3507 - Duration_loss: 0.1121 - val_loss: 20.4174 - val_Note_loss: 13.1810 - val_Offset_loss: 0.3012 - val_Volume_loss: 1.2839 - val_Duration_loss: 5.6513\n",
            "Epoch 72/400\n",
            "7/7 [==============================] - ETA: 0s - loss: 1.0465 - Note_loss: 0.4928 - Offset_loss: 0.0551 - Volume_loss: 0.3801 - Duration_loss: 0.1185\n",
            "Epoch 72: val_loss did not improve from 5.95548\n",
            "7/7 [==============================] - 0s 37ms/step - loss: 1.0465 - Note_loss: 0.4928 - Offset_loss: 0.0551 - Volume_loss: 0.3801 - Duration_loss: 0.1185 - val_loss: 21.7384 - val_Note_loss: 13.8521 - val_Offset_loss: 0.3025 - val_Volume_loss: 1.2116 - val_Duration_loss: 6.3721\n",
            "Epoch 73/400\n",
            "6/7 [========================>.....] - ETA: 0s - loss: 0.9982 - Note_loss: 0.4591 - Offset_loss: 0.0503 - Volume_loss: 0.3781 - Duration_loss: 0.1107\n",
            "Epoch 73: val_loss did not improve from 5.95548\n",
            "7/7 [==============================] - 0s 31ms/step - loss: 0.9927 - Note_loss: 0.4575 - Offset_loss: 0.0484 - Volume_loss: 0.3798 - Duration_loss: 0.1070 - val_loss: 22.9164 - val_Note_loss: 14.5405 - val_Offset_loss: 0.3005 - val_Volume_loss: 1.2944 - val_Duration_loss: 6.7810\n",
            "Epoch 74/400\n",
            "7/7 [==============================] - ETA: 0s - loss: 1.0018 - Note_loss: 0.4276 - Offset_loss: 0.0428 - Volume_loss: 0.3959 - Duration_loss: 0.1355\n",
            "Epoch 74: val_loss did not improve from 5.95548\n",
            "7/7 [==============================] - 0s 30ms/step - loss: 1.0018 - Note_loss: 0.4276 - Offset_loss: 0.0428 - Volume_loss: 0.3959 - Duration_loss: 0.1355 - val_loss: 22.8976 - val_Note_loss: 14.7639 - val_Offset_loss: 0.3053 - val_Volume_loss: 1.4221 - val_Duration_loss: 6.4063\n",
            "Epoch 75/400\n",
            "7/7 [==============================] - ETA: 0s - loss: 1.0388 - Note_loss: 0.4827 - Offset_loss: 0.0441 - Volume_loss: 0.3994 - Duration_loss: 0.1126\n",
            "Epoch 75: val_loss did not improve from 5.95548\n",
            "7/7 [==============================] - 0s 30ms/step - loss: 1.0388 - Note_loss: 0.4827 - Offset_loss: 0.0441 - Volume_loss: 0.3994 - Duration_loss: 0.1126 - val_loss: 21.4458 - val_Note_loss: 13.7852 - val_Offset_loss: 0.3364 - val_Volume_loss: 1.3643 - val_Duration_loss: 5.9599\n",
            "Epoch 76/400\n",
            "7/7 [==============================] - ETA: 0s - loss: 1.0443 - Note_loss: 0.4405 - Offset_loss: 0.0599 - Volume_loss: 0.4293 - Duration_loss: 0.1145\n",
            "Epoch 76: val_loss did not improve from 5.95548\n",
            "7/7 [==============================] - 0s 26ms/step - loss: 1.0443 - Note_loss: 0.4405 - Offset_loss: 0.0599 - Volume_loss: 0.4293 - Duration_loss: 0.1145 - val_loss: 21.4121 - val_Note_loss: 13.6128 - val_Offset_loss: 0.3315 - val_Volume_loss: 1.4911 - val_Duration_loss: 5.9766\n",
            "Epoch 77/400\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.9783 - Note_loss: 0.4470 - Offset_loss: 0.0505 - Volume_loss: 0.3672 - Duration_loss: 0.1136\n",
            "Epoch 77: val_loss did not improve from 5.95548\n",
            "7/7 [==============================] - 0s 36ms/step - loss: 0.9783 - Note_loss: 0.4470 - Offset_loss: 0.0505 - Volume_loss: 0.3672 - Duration_loss: 0.1136 - val_loss: 23.3974 - val_Note_loss: 14.5021 - val_Offset_loss: 0.2997 - val_Volume_loss: 1.5122 - val_Duration_loss: 7.0834\n",
            "Epoch 78/400\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.9412 - Note_loss: 0.4116 - Offset_loss: 0.0534 - Volume_loss: 0.3615 - Duration_loss: 0.1148\n",
            "Epoch 78: val_loss did not improve from 5.95548\n",
            "7/7 [==============================] - 0s 29ms/step - loss: 0.9412 - Note_loss: 0.4116 - Offset_loss: 0.0534 - Volume_loss: 0.3615 - Duration_loss: 0.1148 - val_loss: 24.1265 - val_Note_loss: 15.2264 - val_Offset_loss: 0.3057 - val_Volume_loss: 1.3620 - val_Duration_loss: 7.2323\n",
            "Epoch 79/400\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.9427 - Note_loss: 0.4336 - Offset_loss: 0.0446 - Volume_loss: 0.3234 - Duration_loss: 0.1410\n",
            "Epoch 79: val_loss did not improve from 5.95548\n",
            "7/7 [==============================] - 0s 29ms/step - loss: 0.9427 - Note_loss: 0.4336 - Offset_loss: 0.0446 - Volume_loss: 0.3234 - Duration_loss: 0.1410 - val_loss: 23.3566 - val_Note_loss: 14.8476 - val_Offset_loss: 0.3085 - val_Volume_loss: 1.5914 - val_Duration_loss: 6.6091\n",
            "Epoch 80/400\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.8891 - Note_loss: 0.4090 - Offset_loss: 0.0410 - Volume_loss: 0.3365 - Duration_loss: 0.1025\n",
            "Epoch 80: val_loss did not improve from 5.95548\n",
            "7/7 [==============================] - 0s 29ms/step - loss: 0.8891 - Note_loss: 0.4090 - Offset_loss: 0.0410 - Volume_loss: 0.3365 - Duration_loss: 0.1025 - val_loss: 23.3483 - val_Note_loss: 14.8421 - val_Offset_loss: 0.3055 - val_Volume_loss: 1.7149 - val_Duration_loss: 6.4858\n",
            "Epoch 81/400\n",
            "6/7 [========================>.....] - ETA: 0s - loss: 0.8491 - Note_loss: 0.3919 - Offset_loss: 0.0369 - Volume_loss: 0.3195 - Duration_loss: 0.1009\n",
            "Epoch 81: val_loss did not improve from 5.95548\n",
            "7/7 [==============================] - 0s 41ms/step - loss: 0.8340 - Note_loss: 0.3827 - Offset_loss: 0.0364 - Volume_loss: 0.3185 - Duration_loss: 0.0964 - val_loss: 24.0065 - val_Note_loss: 14.9300 - val_Offset_loss: 0.3012 - val_Volume_loss: 1.6717 - val_Duration_loss: 7.1035\n",
            "Epoch 82/400\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.7954 - Note_loss: 0.3768 - Offset_loss: 0.0290 - Volume_loss: 0.3037 - Duration_loss: 0.0859\n",
            "Epoch 82: val_loss did not improve from 5.95548\n",
            "7/7 [==============================] - 0s 46ms/step - loss: 0.7954 - Note_loss: 0.3768 - Offset_loss: 0.0290 - Volume_loss: 0.3037 - Duration_loss: 0.0859 - val_loss: 24.5883 - val_Note_loss: 15.1328 - val_Offset_loss: 0.3332 - val_Volume_loss: 1.6579 - val_Duration_loss: 7.4645\n",
            "Epoch 83/400\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.7552 - Note_loss: 0.3480 - Offset_loss: 0.0466 - Volume_loss: 0.2778 - Duration_loss: 0.0828\n",
            "Epoch 83: val_loss did not improve from 5.95548\n",
            "7/7 [==============================] - 0s 47ms/step - loss: 0.7552 - Note_loss: 0.3480 - Offset_loss: 0.0466 - Volume_loss: 0.2778 - Duration_loss: 0.0828 - val_loss: 25.5699 - val_Note_loss: 15.7290 - val_Offset_loss: 0.3452 - val_Volume_loss: 1.8338 - val_Duration_loss: 7.6619\n",
            "Epoch 84/400\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.8926 - Note_loss: 0.4490 - Offset_loss: 0.0459 - Volume_loss: 0.2838 - Duration_loss: 0.1138\n",
            "Epoch 84: val_loss did not improve from 5.95548\n",
            "7/7 [==============================] - 0s 40ms/step - loss: 0.8926 - Note_loss: 0.4490 - Offset_loss: 0.0459 - Volume_loss: 0.2838 - Duration_loss: 0.1138 - val_loss: 25.2455 - val_Note_loss: 15.3333 - val_Offset_loss: 0.3324 - val_Volume_loss: 1.8055 - val_Duration_loss: 7.7742\n",
            "Epoch 85/400\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.8995 - Note_loss: 0.4205 - Offset_loss: 0.0387 - Volume_loss: 0.3135 - Duration_loss: 0.1268\n",
            "Epoch 85: val_loss did not improve from 5.95548\n",
            "7/7 [==============================] - 0s 52ms/step - loss: 0.8995 - Note_loss: 0.4205 - Offset_loss: 0.0387 - Volume_loss: 0.3135 - Duration_loss: 0.1268 - val_loss: 24.5561 - val_Note_loss: 15.4860 - val_Offset_loss: 0.3565 - val_Volume_loss: 1.9449 - val_Duration_loss: 6.7688\n",
            "Epoch 86/400\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.8232 - Note_loss: 0.3819 - Offset_loss: 0.0480 - Volume_loss: 0.2894 - Duration_loss: 0.1040\n",
            "Epoch 86: val_loss did not improve from 5.95548\n",
            "7/7 [==============================] - 0s 42ms/step - loss: 0.8232 - Note_loss: 0.3819 - Offset_loss: 0.0480 - Volume_loss: 0.2894 - Duration_loss: 0.1040 - val_loss: 27.7615 - val_Note_loss: 17.6816 - val_Offset_loss: 0.3347 - val_Volume_loss: 1.5275 - val_Duration_loss: 8.2178\n",
            "Epoch 87/400\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.8702 - Note_loss: 0.3998 - Offset_loss: 0.0536 - Volume_loss: 0.2901 - Duration_loss: 0.1267\n",
            "Epoch 87: val_loss did not improve from 5.95548\n",
            "7/7 [==============================] - 0s 46ms/step - loss: 0.8702 - Note_loss: 0.3998 - Offset_loss: 0.0536 - Volume_loss: 0.2901 - Duration_loss: 0.1267 - val_loss: 26.4623 - val_Note_loss: 16.9049 - val_Offset_loss: 0.3472 - val_Volume_loss: 1.5293 - val_Duration_loss: 7.6809\n",
            "Epoch 88/400\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.9748 - Note_loss: 0.4598 - Offset_loss: 0.0560 - Volume_loss: 0.3515 - Duration_loss: 0.1075\n",
            "Epoch 88: val_loss did not improve from 5.95548\n",
            "7/7 [==============================] - 0s 42ms/step - loss: 0.9748 - Note_loss: 0.4598 - Offset_loss: 0.0560 - Volume_loss: 0.3515 - Duration_loss: 0.1075 - val_loss: 24.2492 - val_Note_loss: 15.5523 - val_Offset_loss: 0.3587 - val_Volume_loss: 1.5152 - val_Duration_loss: 6.8230\n",
            "Epoch 89/400\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.7462 - Note_loss: 0.3368 - Offset_loss: 0.0423 - Volume_loss: 0.2704 - Duration_loss: 0.0967\n",
            "Epoch 89: val_loss did not improve from 5.95548\n",
            "7/7 [==============================] - 0s 48ms/step - loss: 0.7462 - Note_loss: 0.3368 - Offset_loss: 0.0423 - Volume_loss: 0.2704 - Duration_loss: 0.0967 - val_loss: 26.4221 - val_Note_loss: 16.9167 - val_Offset_loss: 0.3126 - val_Volume_loss: 1.4870 - val_Duration_loss: 7.7058\n",
            "Epoch 90/400\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.8837 - Note_loss: 0.4457 - Offset_loss: 0.0483 - Volume_loss: 0.2877 - Duration_loss: 0.1020\n",
            "Epoch 90: val_loss did not improve from 5.95548\n",
            "7/7 [==============================] - 0s 31ms/step - loss: 0.8837 - Note_loss: 0.4457 - Offset_loss: 0.0483 - Volume_loss: 0.2877 - Duration_loss: 0.1020 - val_loss: 25.5328 - val_Note_loss: 16.5618 - val_Offset_loss: 0.3387 - val_Volume_loss: 1.7139 - val_Duration_loss: 6.9185\n",
            "Epoch 91/400\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.7764 - Note_loss: 0.3596 - Offset_loss: 0.0550 - Volume_loss: 0.2656 - Duration_loss: 0.0962\n",
            "Epoch 91: val_loss did not improve from 5.95548\n",
            "7/7 [==============================] - 0s 29ms/step - loss: 0.7764 - Note_loss: 0.3596 - Offset_loss: 0.0550 - Volume_loss: 0.2656 - Duration_loss: 0.0962 - val_loss: 24.5293 - val_Note_loss: 15.8401 - val_Offset_loss: 0.3309 - val_Volume_loss: 1.8107 - val_Duration_loss: 6.5477\n",
            "Epoch 92/400\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.7312 - Note_loss: 0.3323 - Offset_loss: 0.0479 - Volume_loss: 0.2747 - Duration_loss: 0.0763\n",
            "Epoch 92: val_loss did not improve from 5.95548\n",
            "7/7 [==============================] - 0s 30ms/step - loss: 0.7312 - Note_loss: 0.3323 - Offset_loss: 0.0479 - Volume_loss: 0.2747 - Duration_loss: 0.0763 - val_loss: 24.8858 - val_Note_loss: 15.9081 - val_Offset_loss: 0.3309 - val_Volume_loss: 1.7627 - val_Duration_loss: 6.8841\n",
            "Epoch 93/400\n",
            "6/7 [========================>.....] - ETA: 0s - loss: 0.7684 - Note_loss: 0.3335 - Offset_loss: 0.0462 - Volume_loss: 0.2540 - Duration_loss: 0.1346\n",
            "Epoch 93: val_loss did not improve from 5.95548\n",
            "7/7 [==============================] - 0s 32ms/step - loss: 0.7792 - Note_loss: 0.3363 - Offset_loss: 0.0458 - Volume_loss: 0.2539 - Duration_loss: 0.1432 - val_loss: 25.1096 - val_Note_loss: 15.7495 - val_Offset_loss: 0.3673 - val_Volume_loss: 1.9002 - val_Duration_loss: 7.0926\n",
            "Epoch 94/400\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.6703 - Note_loss: 0.3165 - Offset_loss: 0.0346 - Volume_loss: 0.2214 - Duration_loss: 0.0978\n",
            "Epoch 94: val_loss did not improve from 5.95548\n",
            "7/7 [==============================] - 0s 30ms/step - loss: 0.6703 - Note_loss: 0.3165 - Offset_loss: 0.0346 - Volume_loss: 0.2214 - Duration_loss: 0.0978 - val_loss: 23.8355 - val_Note_loss: 14.8294 - val_Offset_loss: 0.3320 - val_Volume_loss: 1.9564 - val_Duration_loss: 6.7177\n",
            "Epoch 95/400\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.8013 - Note_loss: 0.3779 - Offset_loss: 0.0436 - Volume_loss: 0.2497 - Duration_loss: 0.1301\n",
            "Epoch 95: val_loss did not improve from 5.95548\n",
            "7/7 [==============================] - 0s 29ms/step - loss: 0.8013 - Note_loss: 0.3779 - Offset_loss: 0.0436 - Volume_loss: 0.2497 - Duration_loss: 0.1301 - val_loss: 25.3317 - val_Note_loss: 16.0722 - val_Offset_loss: 0.3454 - val_Volume_loss: 1.7675 - val_Duration_loss: 7.1465\n",
            "Epoch 96/400\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.7286 - Note_loss: 0.3794 - Offset_loss: 0.0349 - Volume_loss: 0.2316 - Duration_loss: 0.0827\n",
            "Epoch 96: val_loss did not improve from 5.95548\n",
            "7/7 [==============================] - 0s 30ms/step - loss: 0.7286 - Note_loss: 0.3794 - Offset_loss: 0.0349 - Volume_loss: 0.2316 - Duration_loss: 0.0827 - val_loss: 26.0028 - val_Note_loss: 16.6318 - val_Offset_loss: 0.3551 - val_Volume_loss: 1.8498 - val_Duration_loss: 7.1661\n",
            "Epoch 97/400\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.6484 - Note_loss: 0.3291 - Offset_loss: 0.0374 - Volume_loss: 0.1940 - Duration_loss: 0.0878\n",
            "Epoch 97: val_loss did not improve from 5.95548\n",
            "7/7 [==============================] - 0s 30ms/step - loss: 0.6484 - Note_loss: 0.3291 - Offset_loss: 0.0374 - Volume_loss: 0.1940 - Duration_loss: 0.0878 - val_loss: 26.2263 - val_Note_loss: 16.9553 - val_Offset_loss: 0.3146 - val_Volume_loss: 1.8108 - val_Duration_loss: 7.1456\n",
            "Epoch 98/400\n",
            "6/7 [========================>.....] - ETA: 0s - loss: 0.6262 - Note_loss: 0.3074 - Offset_loss: 0.0420 - Volume_loss: 0.2045 - Duration_loss: 0.0723\n",
            "Epoch 98: val_loss did not improve from 5.95548\n",
            "7/7 [==============================] - 0s 31ms/step - loss: 0.6174 - Note_loss: 0.3113 - Offset_loss: 0.0409 - Volume_loss: 0.1960 - Duration_loss: 0.0693 - val_loss: 26.1184 - val_Note_loss: 16.9528 - val_Offset_loss: 0.3123 - val_Volume_loss: 1.7623 - val_Duration_loss: 7.0910\n",
            "Epoch 99/400\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.7048 - Note_loss: 0.2896 - Offset_loss: 0.0355 - Volume_loss: 0.2628 - Duration_loss: 0.1169\n",
            "Epoch 99: val_loss did not improve from 5.95548\n",
            "7/7 [==============================] - 0s 30ms/step - loss: 0.7048 - Note_loss: 0.2896 - Offset_loss: 0.0355 - Volume_loss: 0.2628 - Duration_loss: 0.1169 - val_loss: 26.5793 - val_Note_loss: 17.1727 - val_Offset_loss: 0.3374 - val_Volume_loss: 1.8502 - val_Duration_loss: 7.2189\n",
            "Epoch 100/400\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.6223 - Note_loss: 0.2904 - Offset_loss: 0.0395 - Volume_loss: 0.2183 - Duration_loss: 0.0740\n",
            "Epoch 100: val_loss did not improve from 5.95548\n",
            "7/7 [==============================] - 0s 29ms/step - loss: 0.6223 - Note_loss: 0.2904 - Offset_loss: 0.0395 - Volume_loss: 0.2183 - Duration_loss: 0.0740 - val_loss: 26.7244 - val_Note_loss: 17.2240 - val_Offset_loss: 0.3202 - val_Volume_loss: 1.7685 - val_Duration_loss: 7.4117\n",
            "Epoch 101/400\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.6067 - Note_loss: 0.2942 - Offset_loss: 0.0357 - Volume_loss: 0.2107 - Duration_loss: 0.0662\n",
            "Epoch 101: val_loss did not improve from 5.95548\n",
            "7/7 [==============================] - 0s 38ms/step - loss: 0.6067 - Note_loss: 0.2942 - Offset_loss: 0.0357 - Volume_loss: 0.2107 - Duration_loss: 0.0662 - val_loss: 27.1794 - val_Note_loss: 17.3255 - val_Offset_loss: 0.3194 - val_Volume_loss: 1.9044 - val_Duration_loss: 7.6301\n",
            "Epoch 102/400\n",
            "6/7 [========================>.....] - ETA: 0s - loss: 0.6803 - Note_loss: 0.3181 - Offset_loss: 0.0402 - Volume_loss: 0.2467 - Duration_loss: 0.0752\n",
            "Epoch 102: val_loss did not improve from 5.95548\n",
            "7/7 [==============================] - 0s 32ms/step - loss: 0.6594 - Note_loss: 0.3127 - Offset_loss: 0.0401 - Volume_loss: 0.2351 - Duration_loss: 0.0715 - val_loss: 26.7320 - val_Note_loss: 17.0559 - val_Offset_loss: 0.3187 - val_Volume_loss: 1.8062 - val_Duration_loss: 7.5511\n",
            "Epoch 103/400\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.5891 - Note_loss: 0.2976 - Offset_loss: 0.0345 - Volume_loss: 0.1677 - Duration_loss: 0.0893\n",
            "Epoch 103: val_loss did not improve from 5.95548\n",
            "7/7 [==============================] - 0s 30ms/step - loss: 0.5891 - Note_loss: 0.2976 - Offset_loss: 0.0345 - Volume_loss: 0.1677 - Duration_loss: 0.0893 - val_loss: 27.7678 - val_Note_loss: 17.5035 - val_Offset_loss: 0.3391 - val_Volume_loss: 1.8894 - val_Duration_loss: 8.0358\n",
            "Epoch 104/400\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.6037 - Note_loss: 0.2982 - Offset_loss: 0.0293 - Volume_loss: 0.1873 - Duration_loss: 0.0888\n",
            "Epoch 104: val_loss did not improve from 5.95548\n",
            "7/7 [==============================] - 0s 30ms/step - loss: 0.6037 - Note_loss: 0.2982 - Offset_loss: 0.0293 - Volume_loss: 0.1873 - Duration_loss: 0.0888 - val_loss: 28.6803 - val_Note_loss: 18.2632 - val_Offset_loss: 0.3563 - val_Volume_loss: 1.9475 - val_Duration_loss: 8.1133\n",
            "Epoch 105/400\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.6664 - Note_loss: 0.2491 - Offset_loss: 0.0487 - Volume_loss: 0.2185 - Duration_loss: 0.1501\n",
            "Epoch 105: val_loss did not improve from 5.95548\n",
            "7/7 [==============================] - 0s 29ms/step - loss: 0.6664 - Note_loss: 0.2491 - Offset_loss: 0.0487 - Volume_loss: 0.2185 - Duration_loss: 0.1501 - val_loss: 27.0106 - val_Note_loss: 17.7960 - val_Offset_loss: 0.3722 - val_Volume_loss: 1.9552 - val_Duration_loss: 6.8872\n",
            "Epoch 106/400\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.5808 - Note_loss: 0.2322 - Offset_loss: 0.0460 - Volume_loss: 0.1836 - Duration_loss: 0.1190\n",
            "Epoch 106: val_loss did not improve from 5.95548\n",
            "7/7 [==============================] - 0s 29ms/step - loss: 0.5808 - Note_loss: 0.2322 - Offset_loss: 0.0460 - Volume_loss: 0.1836 - Duration_loss: 0.1190 - val_loss: 26.7816 - val_Note_loss: 17.4979 - val_Offset_loss: 0.3476 - val_Volume_loss: 1.8502 - val_Duration_loss: 7.0859\n",
            "Epoch 107/400\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.6290 - Note_loss: 0.2974 - Offset_loss: 0.0482 - Volume_loss: 0.1960 - Duration_loss: 0.0874\n",
            "Epoch 107: val_loss did not improve from 5.95548\n",
            "7/7 [==============================] - 0s 31ms/step - loss: 0.6290 - Note_loss: 0.2974 - Offset_loss: 0.0482 - Volume_loss: 0.1960 - Duration_loss: 0.0874 - val_loss: 28.2095 - val_Note_loss: 18.1760 - val_Offset_loss: 0.3353 - val_Volume_loss: 1.7550 - val_Duration_loss: 7.9432\n",
            "Epoch 108/400\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.5898 - Note_loss: 0.2740 - Offset_loss: 0.0466 - Volume_loss: 0.2202 - Duration_loss: 0.0490\n",
            "Epoch 108: val_loss did not improve from 5.95548\n",
            "7/7 [==============================] - 0s 33ms/step - loss: 0.5898 - Note_loss: 0.2740 - Offset_loss: 0.0466 - Volume_loss: 0.2202 - Duration_loss: 0.0490 - val_loss: 29.3063 - val_Note_loss: 18.7651 - val_Offset_loss: 0.3402 - val_Volume_loss: 1.9694 - val_Duration_loss: 8.2316\n",
            "Epoch 109/400\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.5205 - Note_loss: 0.2341 - Offset_loss: 0.0356 - Volume_loss: 0.1670 - Duration_loss: 0.0838\n",
            "Epoch 109: val_loss did not improve from 5.95548\n",
            "7/7 [==============================] - 0s 30ms/step - loss: 0.5205 - Note_loss: 0.2341 - Offset_loss: 0.0356 - Volume_loss: 0.1670 - Duration_loss: 0.0838 - val_loss: 28.9516 - val_Note_loss: 18.3622 - val_Offset_loss: 0.3312 - val_Volume_loss: 2.1661 - val_Duration_loss: 8.0921\n",
            "Epoch 110/400\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.5702 - Note_loss: 0.2532 - Offset_loss: 0.0472 - Volume_loss: 0.1989 - Duration_loss: 0.0708\n",
            "Epoch 110: val_loss did not improve from 5.95548\n",
            "7/7 [==============================] - 0s 29ms/step - loss: 0.5702 - Note_loss: 0.2532 - Offset_loss: 0.0472 - Volume_loss: 0.1989 - Duration_loss: 0.0708 - val_loss: 28.5057 - val_Note_loss: 18.1782 - val_Offset_loss: 0.3659 - val_Volume_loss: 2.3039 - val_Duration_loss: 7.6577\n",
            "Epoch 111/400\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.4804 - Note_loss: 0.2131 - Offset_loss: 0.0329 - Volume_loss: 0.1701 - Duration_loss: 0.0643\n",
            "Epoch 111: val_loss did not improve from 5.95548\n",
            "7/7 [==============================] - 0s 29ms/step - loss: 0.4804 - Note_loss: 0.2131 - Offset_loss: 0.0329 - Volume_loss: 0.1701 - Duration_loss: 0.0643 - val_loss: 28.3107 - val_Note_loss: 18.1371 - val_Offset_loss: 0.3644 - val_Volume_loss: 2.3386 - val_Duration_loss: 7.4706\n",
            "Epoch 112/400\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.4701 - Note_loss: 0.2207 - Offset_loss: 0.0466 - Volume_loss: 0.1411 - Duration_loss: 0.0618\n",
            "Epoch 112: val_loss did not improve from 5.95548\n",
            "7/7 [==============================] - 0s 31ms/step - loss: 0.4701 - Note_loss: 0.2207 - Offset_loss: 0.0466 - Volume_loss: 0.1411 - Duration_loss: 0.0618 - val_loss: 29.4126 - val_Note_loss: 18.7853 - val_Offset_loss: 0.3562 - val_Volume_loss: 2.2283 - val_Duration_loss: 8.0428\n",
            "Epoch 113/400\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.5000 - Note_loss: 0.2345 - Offset_loss: 0.0331 - Volume_loss: 0.1444 - Duration_loss: 0.0879\n",
            "Epoch 113: val_loss did not improve from 5.95548\n",
            "7/7 [==============================] - 0s 29ms/step - loss: 0.5000 - Note_loss: 0.2345 - Offset_loss: 0.0331 - Volume_loss: 0.1444 - Duration_loss: 0.0879 - val_loss: 30.8344 - val_Note_loss: 19.6130 - val_Offset_loss: 0.3415 - val_Volume_loss: 2.1671 - val_Duration_loss: 8.7128\n",
            "Epoch 114/400\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.5014 - Note_loss: 0.2010 - Offset_loss: 0.0402 - Volume_loss: 0.1954 - Duration_loss: 0.0649\n",
            "Epoch 114: val_loss did not improve from 5.95548\n",
            "7/7 [==============================] - 0s 30ms/step - loss: 0.5014 - Note_loss: 0.2010 - Offset_loss: 0.0402 - Volume_loss: 0.1954 - Duration_loss: 0.0649 - val_loss: 31.4195 - val_Note_loss: 20.0727 - val_Offset_loss: 0.3369 - val_Volume_loss: 2.2422 - val_Duration_loss: 8.7677\n",
            "Epoch 115/400\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.4802 - Note_loss: 0.2217 - Offset_loss: 0.0312 - Volume_loss: 0.1896 - Duration_loss: 0.0377\n",
            "Epoch 115: val_loss did not improve from 5.95548\n",
            "7/7 [==============================] - 0s 28ms/step - loss: 0.4802 - Note_loss: 0.2217 - Offset_loss: 0.0312 - Volume_loss: 0.1896 - Duration_loss: 0.0377 - val_loss: 31.5139 - val_Note_loss: 20.2605 - val_Offset_loss: 0.3274 - val_Volume_loss: 2.0783 - val_Duration_loss: 8.8477\n",
            "Epoch 116/400\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.5070 - Note_loss: 0.2008 - Offset_loss: 0.0409 - Volume_loss: 0.1908 - Duration_loss: 0.0745\n",
            "Epoch 116: val_loss did not improve from 5.95548\n",
            "7/7 [==============================] - 0s 29ms/step - loss: 0.5070 - Note_loss: 0.2008 - Offset_loss: 0.0409 - Volume_loss: 0.1908 - Duration_loss: 0.0745 - val_loss: 30.9819 - val_Note_loss: 19.7462 - val_Offset_loss: 0.3320 - val_Volume_loss: 2.0973 - val_Duration_loss: 8.8065\n",
            "Epoch 117/400\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.4696 - Note_loss: 0.2342 - Offset_loss: 0.0416 - Volume_loss: 0.1303 - Duration_loss: 0.0635\n",
            "Epoch 117: val_loss did not improve from 5.95548\n",
            "7/7 [==============================] - 0s 30ms/step - loss: 0.4696 - Note_loss: 0.2342 - Offset_loss: 0.0416 - Volume_loss: 0.1303 - Duration_loss: 0.0635 - val_loss: 31.1656 - val_Note_loss: 19.6339 - val_Offset_loss: 0.3734 - val_Volume_loss: 2.3447 - val_Duration_loss: 8.8137\n",
            "Epoch 118/400\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.4721 - Note_loss: 0.2381 - Offset_loss: 0.0419 - Volume_loss: 0.1395 - Duration_loss: 0.0526\n",
            "Epoch 118: val_loss did not improve from 5.95548\n",
            "7/7 [==============================] - 0s 29ms/step - loss: 0.4721 - Note_loss: 0.2381 - Offset_loss: 0.0419 - Volume_loss: 0.1395 - Duration_loss: 0.0526 - val_loss: 31.7155 - val_Note_loss: 19.8454 - val_Offset_loss: 0.3670 - val_Volume_loss: 1.9888 - val_Duration_loss: 9.5143\n",
            "Epoch 119/400\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.4656 - Note_loss: 0.2209 - Offset_loss: 0.0368 - Volume_loss: 0.1499 - Duration_loss: 0.0580\n",
            "Epoch 119: val_loss did not improve from 5.95548\n",
            "7/7 [==============================] - 0s 28ms/step - loss: 0.4656 - Note_loss: 0.2209 - Offset_loss: 0.0368 - Volume_loss: 0.1499 - Duration_loss: 0.0580 - val_loss: 30.7992 - val_Note_loss: 19.2458 - val_Offset_loss: 0.3766 - val_Volume_loss: 1.9533 - val_Duration_loss: 9.2236\n",
            "Epoch 120/400\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.4631 - Note_loss: 0.2515 - Offset_loss: 0.0272 - Volume_loss: 0.1312 - Duration_loss: 0.0532\n",
            "Epoch 120: val_loss did not improve from 5.95548\n",
            "7/7 [==============================] - 0s 28ms/step - loss: 0.4631 - Note_loss: 0.2515 - Offset_loss: 0.0272 - Volume_loss: 0.1312 - Duration_loss: 0.0532 - val_loss: 30.5296 - val_Note_loss: 19.5048 - val_Offset_loss: 0.3539 - val_Volume_loss: 1.9640 - val_Duration_loss: 8.7069\n",
            "Epoch 121/400\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.4151 - Note_loss: 0.1844 - Offset_loss: 0.0379 - Volume_loss: 0.1377 - Duration_loss: 0.0549\n",
            "Epoch 121: val_loss did not improve from 5.95548\n",
            "7/7 [==============================] - 0s 29ms/step - loss: 0.4151 - Note_loss: 0.1844 - Offset_loss: 0.0379 - Volume_loss: 0.1377 - Duration_loss: 0.0549 - val_loss: 29.6542 - val_Note_loss: 18.9507 - val_Offset_loss: 0.3072 - val_Volume_loss: 1.5264 - val_Duration_loss: 8.8699\n",
            "Epoch 122/400\n",
            "6/7 [========================>.....] - ETA: 0s - loss: 0.4258 - Note_loss: 0.2010 - Offset_loss: 0.0316 - Volume_loss: 0.1485 - Duration_loss: 0.0446\n",
            "Epoch 122: val_loss did not improve from 5.95548\n",
            "7/7 [==============================] - 0s 30ms/step - loss: 0.4125 - Note_loss: 0.1944 - Offset_loss: 0.0311 - Volume_loss: 0.1423 - Duration_loss: 0.0446 - val_loss: 30.4526 - val_Note_loss: 18.9109 - val_Offset_loss: 0.3205 - val_Volume_loss: 1.8338 - val_Duration_loss: 9.3874\n",
            "Epoch 123/400\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.4522 - Note_loss: 0.1695 - Offset_loss: 0.0295 - Volume_loss: 0.2119 - Duration_loss: 0.0413\n",
            "Epoch 123: val_loss did not improve from 5.95548\n",
            "7/7 [==============================] - 0s 29ms/step - loss: 0.4522 - Note_loss: 0.1695 - Offset_loss: 0.0295 - Volume_loss: 0.2119 - Duration_loss: 0.0413 - val_loss: 31.2825 - val_Note_loss: 19.2282 - val_Offset_loss: 0.3609 - val_Volume_loss: 2.2824 - val_Duration_loss: 9.4111\n",
            "Epoch 124/400\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.3864 - Note_loss: 0.1844 - Offset_loss: 0.0313 - Volume_loss: 0.1301 - Duration_loss: 0.0406\n",
            "Epoch 124: val_loss did not improve from 5.95548\n",
            "7/7 [==============================] - 0s 27ms/step - loss: 0.3864 - Note_loss: 0.1844 - Offset_loss: 0.0313 - Volume_loss: 0.1301 - Duration_loss: 0.0406 - val_loss: 32.1511 - val_Note_loss: 19.7080 - val_Offset_loss: 0.3705 - val_Volume_loss: 2.4233 - val_Duration_loss: 9.6493\n",
            "Epoch 125/400\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.4346 - Note_loss: 0.2069 - Offset_loss: 0.0341 - Volume_loss: 0.1318 - Duration_loss: 0.0617\n",
            "Epoch 125: val_loss did not improve from 5.95548\n",
            "7/7 [==============================] - 0s 30ms/step - loss: 0.4346 - Note_loss: 0.2069 - Offset_loss: 0.0341 - Volume_loss: 0.1318 - Duration_loss: 0.0617 - val_loss: 31.6291 - val_Note_loss: 19.9325 - val_Offset_loss: 0.3658 - val_Volume_loss: 2.3852 - val_Duration_loss: 8.9456\n",
            "Epoch 126/400\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.4289 - Note_loss: 0.2119 - Offset_loss: 0.0294 - Volume_loss: 0.1531 - Duration_loss: 0.0345\n",
            "Epoch 126: val_loss did not improve from 5.95548\n",
            "7/7 [==============================] - 0s 36ms/step - loss: 0.4289 - Note_loss: 0.2119 - Offset_loss: 0.0294 - Volume_loss: 0.1531 - Duration_loss: 0.0345 - val_loss: 31.6251 - val_Note_loss: 20.1339 - val_Offset_loss: 0.3806 - val_Volume_loss: 2.5300 - val_Duration_loss: 8.5807\n",
            "Epoch 127/400\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.4385 - Note_loss: 0.2019 - Offset_loss: 0.0343 - Volume_loss: 0.1455 - Duration_loss: 0.0567\n",
            "Epoch 127: val_loss did not improve from 5.95548\n",
            "7/7 [==============================] - 0s 32ms/step - loss: 0.4385 - Note_loss: 0.2019 - Offset_loss: 0.0343 - Volume_loss: 0.1455 - Duration_loss: 0.0567 - val_loss: 31.4552 - val_Note_loss: 19.7382 - val_Offset_loss: 0.3818 - val_Volume_loss: 2.4307 - val_Duration_loss: 8.9046\n",
            "Epoch 128/400\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.4590 - Note_loss: 0.2193 - Offset_loss: 0.0277 - Volume_loss: 0.1493 - Duration_loss: 0.0627\n",
            "Epoch 128: val_loss did not improve from 5.95548\n",
            "7/7 [==============================] - 0s 29ms/step - loss: 0.4590 - Note_loss: 0.2193 - Offset_loss: 0.0277 - Volume_loss: 0.1493 - Duration_loss: 0.0627 - val_loss: 31.3996 - val_Note_loss: 19.7282 - val_Offset_loss: 0.3787 - val_Volume_loss: 2.3702 - val_Duration_loss: 8.9226\n",
            "Epoch 129/400\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.3877 - Note_loss: 0.1705 - Offset_loss: 0.0237 - Volume_loss: 0.1445 - Duration_loss: 0.0490\n",
            "Epoch 129: val_loss did not improve from 5.95548\n",
            "7/7 [==============================] - 0s 29ms/step - loss: 0.3877 - Note_loss: 0.1705 - Offset_loss: 0.0237 - Volume_loss: 0.1445 - Duration_loss: 0.0490 - val_loss: 32.3860 - val_Note_loss: 20.9524 - val_Offset_loss: 0.3834 - val_Volume_loss: 2.1188 - val_Duration_loss: 8.9314\n",
            "Epoch 130/400\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.4950 - Note_loss: 0.1924 - Offset_loss: 0.0476 - Volume_loss: 0.1578 - Duration_loss: 0.0973\n",
            "Epoch 130: val_loss did not improve from 5.95548\n",
            "7/7 [==============================] - 0s 29ms/step - loss: 0.4950 - Note_loss: 0.1924 - Offset_loss: 0.0476 - Volume_loss: 0.1578 - Duration_loss: 0.0973 - val_loss: 33.2735 - val_Note_loss: 21.5499 - val_Offset_loss: 0.3964 - val_Volume_loss: 2.1301 - val_Duration_loss: 9.1971\n",
            "Epoch 131/400\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.4299 - Note_loss: 0.1933 - Offset_loss: 0.0450 - Volume_loss: 0.1269 - Duration_loss: 0.0647\n",
            "Epoch 131: val_loss did not improve from 5.95548\n",
            "7/7 [==============================] - 0s 31ms/step - loss: 0.4299 - Note_loss: 0.1933 - Offset_loss: 0.0450 - Volume_loss: 0.1269 - Duration_loss: 0.0647 - val_loss: 34.6173 - val_Note_loss: 21.7541 - val_Offset_loss: 0.4040 - val_Volume_loss: 2.2897 - val_Duration_loss: 10.1695\n",
            "Epoch 132/400\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.4809 - Note_loss: 0.2703 - Offset_loss: 0.0408 - Volume_loss: 0.1310 - Duration_loss: 0.0388\n",
            "Epoch 132: val_loss did not improve from 5.95548\n",
            "7/7 [==============================] - 0s 30ms/step - loss: 0.4809 - Note_loss: 0.2703 - Offset_loss: 0.0408 - Volume_loss: 0.1310 - Duration_loss: 0.0388 - val_loss: 34.6167 - val_Note_loss: 21.4115 - val_Offset_loss: 0.3845 - val_Volume_loss: 2.1704 - val_Duration_loss: 10.6503\n",
            "Epoch 133/400\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.4271 - Note_loss: 0.1938 - Offset_loss: 0.0287 - Volume_loss: 0.1292 - Duration_loss: 0.0754\n",
            "Epoch 133: val_loss did not improve from 5.95548\n",
            "7/7 [==============================] - 0s 32ms/step - loss: 0.4271 - Note_loss: 0.1938 - Offset_loss: 0.0287 - Volume_loss: 0.1292 - Duration_loss: 0.0754 - val_loss: 33.8319 - val_Note_loss: 20.9877 - val_Offset_loss: 0.3635 - val_Volume_loss: 2.1453 - val_Duration_loss: 10.3355\n",
            "Epoch 134/400\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.3221 - Note_loss: 0.1159 - Offset_loss: 0.0369 - Volume_loss: 0.1195 - Duration_loss: 0.0497\n",
            "Epoch 134: val_loss did not improve from 5.95548\n",
            "7/7 [==============================] - 0s 32ms/step - loss: 0.3221 - Note_loss: 0.1159 - Offset_loss: 0.0369 - Volume_loss: 0.1195 - Duration_loss: 0.0497 - val_loss: 33.4673 - val_Note_loss: 21.1817 - val_Offset_loss: 0.3499 - val_Volume_loss: 2.1969 - val_Duration_loss: 9.7388\n",
            "Epoch 135/400\n",
            "6/7 [========================>.....] - ETA: 0s - loss: 0.3620 - Note_loss: 0.1522 - Offset_loss: 0.0302 - Volume_loss: 0.1419 - Duration_loss: 0.0377\n",
            "Epoch 135: val_loss did not improve from 5.95548\n",
            "7/7 [==============================] - 0s 31ms/step - loss: 0.3583 - Note_loss: 0.1542 - Offset_loss: 0.0288 - Volume_loss: 0.1391 - Duration_loss: 0.0361 - val_loss: 34.6845 - val_Note_loss: 21.9800 - val_Offset_loss: 0.3209 - val_Volume_loss: 2.2040 - val_Duration_loss: 10.1796\n",
            "Epoch 136/400\n",
            "6/7 [========================>.....] - ETA: 0s - loss: 0.5181 - Note_loss: 0.2603 - Offset_loss: 0.0282 - Volume_loss: 0.1673 - Duration_loss: 0.0622\n",
            "Epoch 136: val_loss did not improve from 5.95548\n",
            "7/7 [==============================] - 0s 41ms/step - loss: 0.4956 - Note_loss: 0.2488 - Offset_loss: 0.0274 - Volume_loss: 0.1601 - Duration_loss: 0.0592 - val_loss: 33.0186 - val_Note_loss: 20.9686 - val_Offset_loss: 0.3532 - val_Volume_loss: 2.1733 - val_Duration_loss: 9.5234\n",
            "Epoch 137/400\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.3867 - Note_loss: 0.1692 - Offset_loss: 0.0332 - Volume_loss: 0.1575 - Duration_loss: 0.0268\n",
            "Epoch 137: val_loss did not improve from 5.95548\n",
            "7/7 [==============================] - 0s 48ms/step - loss: 0.3867 - Note_loss: 0.1692 - Offset_loss: 0.0332 - Volume_loss: 0.1575 - Duration_loss: 0.0268 - val_loss: 32.2603 - val_Note_loss: 20.2319 - val_Offset_loss: 0.3754 - val_Volume_loss: 2.3289 - val_Duration_loss: 9.3241\n",
            "Epoch 138/400\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.5109 - Note_loss: 0.2272 - Offset_loss: 0.0439 - Volume_loss: 0.1828 - Duration_loss: 0.0571\n",
            "Epoch 138: val_loss did not improve from 5.95548\n",
            "7/7 [==============================] - 0s 48ms/step - loss: 0.5109 - Note_loss: 0.2272 - Offset_loss: 0.0439 - Volume_loss: 0.1828 - Duration_loss: 0.0571 - val_loss: 33.1305 - val_Note_loss: 20.8171 - val_Offset_loss: 0.4124 - val_Volume_loss: 2.2652 - val_Duration_loss: 9.6358\n",
            "Epoch 139/400\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.3707 - Note_loss: 0.1411 - Offset_loss: 0.0490 - Volume_loss: 0.1234 - Duration_loss: 0.0572\n",
            "Epoch 139: val_loss did not improve from 5.95548\n",
            "7/7 [==============================] - 0s 52ms/step - loss: 0.3707 - Note_loss: 0.1411 - Offset_loss: 0.0490 - Volume_loss: 0.1234 - Duration_loss: 0.0572 - val_loss: 34.4217 - val_Note_loss: 21.7807 - val_Offset_loss: 0.4020 - val_Volume_loss: 2.4309 - val_Duration_loss: 9.8081\n",
            "Epoch 140/400\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.4174 - Note_loss: 0.1568 - Offset_loss: 0.0505 - Volume_loss: 0.1692 - Duration_loss: 0.0410\n",
            "Epoch 140: val_loss did not improve from 5.95548\n",
            "7/7 [==============================] - 0s 44ms/step - loss: 0.4174 - Note_loss: 0.1568 - Offset_loss: 0.0505 - Volume_loss: 0.1692 - Duration_loss: 0.0410 - val_loss: 33.3383 - val_Note_loss: 21.4312 - val_Offset_loss: 0.3796 - val_Volume_loss: 2.4667 - val_Duration_loss: 9.0609\n",
            "Epoch 141/400\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.3932 - Note_loss: 0.1375 - Offset_loss: 0.0345 - Volume_loss: 0.1813 - Duration_loss: 0.0399\n",
            "Epoch 141: val_loss did not improve from 5.95548\n",
            "7/7 [==============================] - 0s 45ms/step - loss: 0.3932 - Note_loss: 0.1375 - Offset_loss: 0.0345 - Volume_loss: 0.1813 - Duration_loss: 0.0399 - val_loss: 33.1914 - val_Note_loss: 20.9367 - val_Offset_loss: 0.3660 - val_Volume_loss: 2.3350 - val_Duration_loss: 9.5536\n",
            "Epoch 142/400\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.4627 - Note_loss: 0.2223 - Offset_loss: 0.0370 - Volume_loss: 0.1733 - Duration_loss: 0.0301\n",
            "Epoch 142: val_loss did not improve from 5.95548\n",
            "7/7 [==============================] - 0s 41ms/step - loss: 0.4627 - Note_loss: 0.2223 - Offset_loss: 0.0370 - Volume_loss: 0.1733 - Duration_loss: 0.0301 - val_loss: 33.8790 - val_Note_loss: 21.3832 - val_Offset_loss: 0.3809 - val_Volume_loss: 2.3711 - val_Duration_loss: 9.7437\n",
            "Epoch 143/400\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.3553 - Note_loss: 0.1473 - Offset_loss: 0.0316 - Volume_loss: 0.1046 - Duration_loss: 0.0720\n",
            "Epoch 143: val_loss did not improve from 5.95548\n",
            "7/7 [==============================] - 0s 48ms/step - loss: 0.3553 - Note_loss: 0.1473 - Offset_loss: 0.0316 - Volume_loss: 0.1046 - Duration_loss: 0.0720 - val_loss: 34.4327 - val_Note_loss: 21.8540 - val_Offset_loss: 0.3674 - val_Volume_loss: 2.3446 - val_Duration_loss: 9.8666\n",
            "Epoch 144/400\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.4992 - Note_loss: 0.2662 - Offset_loss: 0.0353 - Volume_loss: 0.1414 - Duration_loss: 0.0563\n",
            "Epoch 144: val_loss did not improve from 5.95548\n",
            "7/7 [==============================] - 0s 42ms/step - loss: 0.4992 - Note_loss: 0.2662 - Offset_loss: 0.0353 - Volume_loss: 0.1414 - Duration_loss: 0.0563 - val_loss: 34.2587 - val_Note_loss: 22.0243 - val_Offset_loss: 0.3751 - val_Volume_loss: 2.2905 - val_Duration_loss: 9.5688\n",
            "Epoch 145/400\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.3658 - Note_loss: 0.1510 - Offset_loss: 0.0374 - Volume_loss: 0.1232 - Duration_loss: 0.0541\n",
            "Epoch 145: val_loss did not improve from 5.95548\n",
            "7/7 [==============================] - 0s 32ms/step - loss: 0.3658 - Note_loss: 0.1510 - Offset_loss: 0.0374 - Volume_loss: 0.1232 - Duration_loss: 0.0541 - val_loss: 34.2030 - val_Note_loss: 22.1258 - val_Offset_loss: 0.3867 - val_Volume_loss: 2.3472 - val_Duration_loss: 9.3434\n",
            "Epoch 146/400\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.3987 - Note_loss: 0.2331 - Offset_loss: 0.0237 - Volume_loss: 0.1073 - Duration_loss: 0.0347\n",
            "Epoch 146: val_loss did not improve from 5.95548\n",
            "7/7 [==============================] - 0s 38ms/step - loss: 0.3987 - Note_loss: 0.2331 - Offset_loss: 0.0237 - Volume_loss: 0.1073 - Duration_loss: 0.0347 - val_loss: 35.6553 - val_Note_loss: 22.3020 - val_Offset_loss: 0.3766 - val_Volume_loss: 2.2716 - val_Duration_loss: 10.7051\n",
            "Epoch 147/400\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.3861 - Note_loss: 0.1467 - Offset_loss: 0.0278 - Volume_loss: 0.1261 - Duration_loss: 0.0854\n",
            "Epoch 147: val_loss did not improve from 5.95548\n",
            "7/7 [==============================] - 0s 31ms/step - loss: 0.3861 - Note_loss: 0.1467 - Offset_loss: 0.0278 - Volume_loss: 0.1261 - Duration_loss: 0.0854 - val_loss: 36.6735 - val_Note_loss: 22.5224 - val_Offset_loss: 0.3723 - val_Volume_loss: 1.9801 - val_Duration_loss: 11.7987\n",
            "Epoch 148/400\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.3493 - Note_loss: 0.1188 - Offset_loss: 0.0397 - Volume_loss: 0.1453 - Duration_loss: 0.0454\n",
            "Epoch 148: val_loss did not improve from 5.95548\n",
            "7/7 [==============================] - 0s 31ms/step - loss: 0.3493 - Note_loss: 0.1188 - Offset_loss: 0.0397 - Volume_loss: 0.1453 - Duration_loss: 0.0454 - val_loss: 35.2587 - val_Note_loss: 22.5981 - val_Offset_loss: 0.3903 - val_Volume_loss: 1.9750 - val_Duration_loss: 10.2953\n",
            "Epoch 149/400\n",
            "6/7 [========================>.....] - ETA: 0s - loss: 0.5084 - Note_loss: 0.2180 - Offset_loss: 0.0345 - Volume_loss: 0.1479 - Duration_loss: 0.1079\n",
            "Epoch 149: val_loss did not improve from 5.95548\n",
            "7/7 [==============================] - 0s 31ms/step - loss: 0.4978 - Note_loss: 0.2148 - Offset_loss: 0.0346 - Volume_loss: 0.1456 - Duration_loss: 0.1028 - val_loss: 33.9260 - val_Note_loss: 21.2324 - val_Offset_loss: 0.3845 - val_Volume_loss: 1.9743 - val_Duration_loss: 10.3348\n",
            "Epoch 150/400\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.4701 - Note_loss: 0.2117 - Offset_loss: 0.0441 - Volume_loss: 0.1270 - Duration_loss: 0.0872\n",
            "Epoch 150: val_loss did not improve from 5.95548\n",
            "7/7 [==============================] - 0s 31ms/step - loss: 0.4701 - Note_loss: 0.2117 - Offset_loss: 0.0441 - Volume_loss: 0.1270 - Duration_loss: 0.0872 - val_loss: 33.6662 - val_Note_loss: 20.4135 - val_Offset_loss: 0.3813 - val_Volume_loss: 2.0199 - val_Duration_loss: 10.8514\n",
            "Epoch 151/400\n",
            "6/7 [========================>.....] - ETA: 0s - loss: 0.3790 - Note_loss: 0.1575 - Offset_loss: 0.0362 - Volume_loss: 0.1297 - Duration_loss: 0.0556\n",
            "Epoch 151: val_loss did not improve from 5.95548\n",
            "7/7 [==============================] - 0s 33ms/step - loss: 0.3772 - Note_loss: 0.1598 - Offset_loss: 0.0365 - Volume_loss: 0.1256 - Duration_loss: 0.0552 - val_loss: 35.1259 - val_Note_loss: 21.4216 - val_Offset_loss: 0.3892 - val_Volume_loss: 2.1764 - val_Duration_loss: 11.1387\n",
            "Epoch 152/400\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.3450 - Note_loss: 0.1469 - Offset_loss: 0.0311 - Volume_loss: 0.1296 - Duration_loss: 0.0374\n",
            "Epoch 152: val_loss did not improve from 5.95548\n",
            "7/7 [==============================] - 0s 30ms/step - loss: 0.3450 - Note_loss: 0.1469 - Offset_loss: 0.0311 - Volume_loss: 0.1296 - Duration_loss: 0.0374 - val_loss: 35.6444 - val_Note_loss: 21.8419 - val_Offset_loss: 0.3634 - val_Volume_loss: 2.2514 - val_Duration_loss: 11.1877\n",
            "Epoch 153/400\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.3612 - Note_loss: 0.1861 - Offset_loss: 0.0327 - Volume_loss: 0.0981 - Duration_loss: 0.0443\n",
            "Epoch 153: val_loss did not improve from 5.95548\n",
            "7/7 [==============================] - 0s 31ms/step - loss: 0.3612 - Note_loss: 0.1861 - Offset_loss: 0.0327 - Volume_loss: 0.0981 - Duration_loss: 0.0443 - val_loss: 35.0397 - val_Note_loss: 21.5496 - val_Offset_loss: 0.3723 - val_Volume_loss: 2.3273 - val_Duration_loss: 10.7906\n",
            "Epoch 154/400\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.3436 - Note_loss: 0.1299 - Offset_loss: 0.0238 - Volume_loss: 0.1381 - Duration_loss: 0.0517\n",
            "Epoch 154: val_loss did not improve from 5.95548\n",
            "7/7 [==============================] - 0s 29ms/step - loss: 0.3436 - Note_loss: 0.1299 - Offset_loss: 0.0238 - Volume_loss: 0.1381 - Duration_loss: 0.0517 - val_loss: 34.5647 - val_Note_loss: 21.5799 - val_Offset_loss: 0.4058 - val_Volume_loss: 2.3097 - val_Duration_loss: 10.2693\n",
            "Epoch 155/400\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.3717 - Note_loss: 0.1561 - Offset_loss: 0.0464 - Volume_loss: 0.1097 - Duration_loss: 0.0595\n",
            "Epoch 155: val_loss did not improve from 5.95548\n",
            "7/7 [==============================] - 0s 37ms/step - loss: 0.3717 - Note_loss: 0.1561 - Offset_loss: 0.0464 - Volume_loss: 0.1097 - Duration_loss: 0.0595 - val_loss: 35.4387 - val_Note_loss: 22.2177 - val_Offset_loss: 0.3904 - val_Volume_loss: 2.2794 - val_Duration_loss: 10.5513\n",
            "Epoch 156/400\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.2754 - Note_loss: 0.1111 - Offset_loss: 0.0338 - Volume_loss: 0.1078 - Duration_loss: 0.0226\n",
            "Epoch 156: val_loss did not improve from 5.95548\n",
            "7/7 [==============================] - 0s 31ms/step - loss: 0.2754 - Note_loss: 0.1111 - Offset_loss: 0.0338 - Volume_loss: 0.1078 - Duration_loss: 0.0226 - val_loss: 36.6799 - val_Note_loss: 22.5106 - val_Offset_loss: 0.3847 - val_Volume_loss: 2.2202 - val_Duration_loss: 11.5645\n",
            "Epoch 157/400\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.2932 - Note_loss: 0.1044 - Offset_loss: 0.0320 - Volume_loss: 0.1262 - Duration_loss: 0.0306\n",
            "Epoch 157: val_loss did not improve from 5.95548\n",
            "7/7 [==============================] - 0s 30ms/step - loss: 0.2932 - Note_loss: 0.1044 - Offset_loss: 0.0320 - Volume_loss: 0.1262 - Duration_loss: 0.0306 - val_loss: 36.2918 - val_Note_loss: 22.0273 - val_Offset_loss: 0.4037 - val_Volume_loss: 2.2526 - val_Duration_loss: 11.6081\n",
            "Epoch 158/400\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.3330 - Note_loss: 0.1225 - Offset_loss: 0.0288 - Volume_loss: 0.1462 - Duration_loss: 0.0356\n",
            "Epoch 158: val_loss did not improve from 5.95548\n",
            "7/7 [==============================] - 0s 29ms/step - loss: 0.3330 - Note_loss: 0.1225 - Offset_loss: 0.0288 - Volume_loss: 0.1462 - Duration_loss: 0.0356 - val_loss: 35.5022 - val_Note_loss: 21.8708 - val_Offset_loss: 0.3854 - val_Volume_loss: 2.3393 - val_Duration_loss: 10.9067\n",
            "Epoch 159/400\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.2887 - Note_loss: 0.0706 - Offset_loss: 0.0332 - Volume_loss: 0.1265 - Duration_loss: 0.0583\n",
            "Epoch 159: val_loss did not improve from 5.95548\n",
            "7/7 [==============================] - 0s 31ms/step - loss: 0.2887 - Note_loss: 0.0706 - Offset_loss: 0.0332 - Volume_loss: 0.1265 - Duration_loss: 0.0583 - val_loss: 36.2945 - val_Note_loss: 22.3455 - val_Offset_loss: 0.3778 - val_Volume_loss: 2.5741 - val_Duration_loss: 10.9971\n",
            "Epoch 160/400\n",
            "6/7 [========================>.....] - ETA: 0s - loss: 0.2188 - Note_loss: 0.0765 - Offset_loss: 0.0340 - Volume_loss: 0.0759 - Duration_loss: 0.0324\n",
            "Epoch 160: val_loss did not improve from 5.95548\n",
            "7/7 [==============================] - 0s 32ms/step - loss: 0.2407 - Note_loss: 0.0875 - Offset_loss: 0.0390 - Volume_loss: 0.0755 - Duration_loss: 0.0387 - val_loss: 36.9951 - val_Note_loss: 22.4355 - val_Offset_loss: 0.3615 - val_Volume_loss: 2.8466 - val_Duration_loss: 11.3515\n",
            "Epoch 161/400\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.3334 - Note_loss: 0.1563 - Offset_loss: 0.0263 - Volume_loss: 0.1093 - Duration_loss: 0.0415\n",
            "Epoch 161: val_loss did not improve from 5.95548\n",
            "7/7 [==============================] - 0s 28ms/step - loss: 0.3334 - Note_loss: 0.1563 - Offset_loss: 0.0263 - Volume_loss: 0.1093 - Duration_loss: 0.0415 - val_loss: 37.2017 - val_Note_loss: 22.4572 - val_Offset_loss: 0.3665 - val_Volume_loss: 2.7313 - val_Duration_loss: 11.6467\n",
            "Epoch 162/400\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.2736 - Note_loss: 0.1042 - Offset_loss: 0.0340 - Volume_loss: 0.1023 - Duration_loss: 0.0332\n",
            "Epoch 162: val_loss did not improve from 5.95548\n",
            "7/7 [==============================] - 0s 32ms/step - loss: 0.2736 - Note_loss: 0.1042 - Offset_loss: 0.0340 - Volume_loss: 0.1023 - Duration_loss: 0.0332 - val_loss: 37.4151 - val_Note_loss: 22.7109 - val_Offset_loss: 0.3928 - val_Volume_loss: 2.5001 - val_Duration_loss: 11.8113\n",
            "Epoch 163/400\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.2232 - Note_loss: 0.1026 - Offset_loss: 0.0350 - Volume_loss: 0.0680 - Duration_loss: 0.0176\n",
            "Epoch 163: val_loss did not improve from 5.95548\n",
            "7/7 [==============================] - 0s 30ms/step - loss: 0.2232 - Note_loss: 0.1026 - Offset_loss: 0.0350 - Volume_loss: 0.0680 - Duration_loss: 0.0176 - val_loss: 37.3736 - val_Note_loss: 22.9168 - val_Offset_loss: 0.4345 - val_Volume_loss: 2.3120 - val_Duration_loss: 11.7103\n",
            "Epoch 164/400\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.3189 - Note_loss: 0.1413 - Offset_loss: 0.0319 - Volume_loss: 0.1115 - Duration_loss: 0.0342\n",
            "Epoch 164: val_loss did not improve from 5.95548\n",
            "7/7 [==============================] - 0s 30ms/step - loss: 0.3189 - Note_loss: 0.1413 - Offset_loss: 0.0319 - Volume_loss: 0.1115 - Duration_loss: 0.0342 - val_loss: 36.1821 - val_Note_loss: 22.7669 - val_Offset_loss: 0.3872 - val_Volume_loss: 2.4006 - val_Duration_loss: 10.6274\n",
            "Epoch 165/400\n",
            "6/7 [========================>.....] - ETA: 0s - loss: 0.2037 - Note_loss: 0.0765 - Offset_loss: 0.0284 - Volume_loss: 0.0807 - Duration_loss: 0.0182\n",
            "Epoch 165: val_loss did not improve from 5.95548\n",
            "7/7 [==============================] - 0s 32ms/step - loss: 0.2014 - Note_loss: 0.0755 - Offset_loss: 0.0279 - Volume_loss: 0.0800 - Duration_loss: 0.0180 - val_loss: 35.9917 - val_Note_loss: 22.7811 - val_Offset_loss: 0.3805 - val_Volume_loss: 2.4732 - val_Duration_loss: 10.3569\n",
            "Epoch 166/400\n",
            "6/7 [========================>.....] - ETA: 0s - loss: 0.2651 - Note_loss: 0.0865 - Offset_loss: 0.0353 - Volume_loss: 0.0863 - Duration_loss: 0.0570\n",
            "Epoch 166: val_loss did not improve from 5.95548\n",
            "7/7 [==============================] - 0s 32ms/step - loss: 0.2663 - Note_loss: 0.0869 - Offset_loss: 0.0347 - Volume_loss: 0.0904 - Duration_loss: 0.0542 - val_loss: 37.2960 - val_Note_loss: 23.0234 - val_Offset_loss: 0.3757 - val_Volume_loss: 2.5499 - val_Duration_loss: 11.3470\n",
            "Epoch 167/400\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.2135 - Note_loss: 0.0936 - Offset_loss: 0.0331 - Volume_loss: 0.0693 - Duration_loss: 0.0175\n",
            "Epoch 167: val_loss did not improve from 5.95548\n",
            "7/7 [==============================] - 0s 30ms/step - loss: 0.2135 - Note_loss: 0.0936 - Offset_loss: 0.0331 - Volume_loss: 0.0693 - Duration_loss: 0.0175 - val_loss: 37.5802 - val_Note_loss: 22.7945 - val_Offset_loss: 0.3577 - val_Volume_loss: 2.5681 - val_Duration_loss: 11.8599\n",
            "Epoch 168/400\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.2224 - Note_loss: 0.0683 - Offset_loss: 0.0274 - Volume_loss: 0.1105 - Duration_loss: 0.0162\n",
            "Epoch 168: val_loss did not improve from 5.95548\n",
            "7/7 [==============================] - 0s 31ms/step - loss: 0.2224 - Note_loss: 0.0683 - Offset_loss: 0.0274 - Volume_loss: 0.1105 - Duration_loss: 0.0162 - val_loss: 37.5397 - val_Note_loss: 22.3162 - val_Offset_loss: 0.3448 - val_Volume_loss: 2.6808 - val_Duration_loss: 12.1979\n",
            "Epoch 169/400\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.3089 - Note_loss: 0.1557 - Offset_loss: 0.0290 - Volume_loss: 0.0893 - Duration_loss: 0.0349\n",
            "Epoch 169: val_loss did not improve from 5.95548\n",
            "7/7 [==============================] - 0s 33ms/step - loss: 0.3089 - Note_loss: 0.1557 - Offset_loss: 0.0290 - Volume_loss: 0.0893 - Duration_loss: 0.0349 - val_loss: 36.8451 - val_Note_loss: 22.2946 - val_Offset_loss: 0.3494 - val_Volume_loss: 2.6230 - val_Duration_loss: 11.5780\n",
            "Epoch 170/400\n",
            "6/7 [========================>.....] - ETA: 0s - loss: 0.2155 - Note_loss: 0.0613 - Offset_loss: 0.0384 - Volume_loss: 0.0942 - Duration_loss: 0.0216\n",
            "Epoch 170: val_loss did not improve from 5.95548\n",
            "7/7 [==============================] - 0s 32ms/step - loss: 0.2151 - Note_loss: 0.0601 - Offset_loss: 0.0373 - Volume_loss: 0.0943 - Duration_loss: 0.0233 - val_loss: 36.3452 - val_Note_loss: 22.6858 - val_Offset_loss: 0.3700 - val_Volume_loss: 2.5547 - val_Duration_loss: 10.7347\n",
            "Epoch 171/400\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.3206 - Note_loss: 0.1177 - Offset_loss: 0.0321 - Volume_loss: 0.1477 - Duration_loss: 0.0230\n",
            "Epoch 171: val_loss did not improve from 5.95548\n",
            "7/7 [==============================] - 0s 29ms/step - loss: 0.3206 - Note_loss: 0.1177 - Offset_loss: 0.0321 - Volume_loss: 0.1477 - Duration_loss: 0.0230 - val_loss: 37.5009 - val_Note_loss: 23.4685 - val_Offset_loss: 0.3662 - val_Volume_loss: 2.6367 - val_Duration_loss: 11.0294\n",
            "Epoch 172/400\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.2034 - Note_loss: 0.0596 - Offset_loss: 0.0282 - Volume_loss: 0.0854 - Duration_loss: 0.0302\n",
            "Epoch 172: val_loss did not improve from 5.95548\n",
            "7/7 [==============================] - 0s 32ms/step - loss: 0.2034 - Note_loss: 0.0596 - Offset_loss: 0.0282 - Volume_loss: 0.0854 - Duration_loss: 0.0302 - val_loss: 40.0141 - val_Note_loss: 24.5409 - val_Offset_loss: 0.3823 - val_Volume_loss: 2.9848 - val_Duration_loss: 12.1061\n",
            "Epoch 173/400\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.3010 - Note_loss: 0.0872 - Offset_loss: 0.0262 - Volume_loss: 0.1253 - Duration_loss: 0.0622\n",
            "Epoch 173: val_loss did not improve from 5.95548\n",
            "7/7 [==============================] - 0s 31ms/step - loss: 0.3010 - Note_loss: 0.0872 - Offset_loss: 0.0262 - Volume_loss: 0.1253 - Duration_loss: 0.0622 - val_loss: 38.8045 - val_Note_loss: 24.0331 - val_Offset_loss: 0.3753 - val_Volume_loss: 2.9441 - val_Duration_loss: 11.4520\n",
            "Epoch 174/400\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.2302 - Note_loss: 0.0827 - Offset_loss: 0.0282 - Volume_loss: 0.1013 - Duration_loss: 0.0181\n",
            "Epoch 174: val_loss did not improve from 5.95548\n",
            "7/7 [==============================] - 0s 32ms/step - loss: 0.2302 - Note_loss: 0.0827 - Offset_loss: 0.0282 - Volume_loss: 0.1013 - Duration_loss: 0.0181 - val_loss: 38.1762 - val_Note_loss: 23.8096 - val_Offset_loss: 0.3807 - val_Volume_loss: 2.8314 - val_Duration_loss: 11.1544\n",
            "Epoch 175/400\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.2383 - Note_loss: 0.0913 - Offset_loss: 0.0250 - Volume_loss: 0.0735 - Duration_loss: 0.0485\n",
            "Epoch 175: val_loss did not improve from 5.95548\n",
            "7/7 [==============================] - 0s 32ms/step - loss: 0.2383 - Note_loss: 0.0913 - Offset_loss: 0.0250 - Volume_loss: 0.0735 - Duration_loss: 0.0485 - val_loss: 39.9237 - val_Note_loss: 24.4610 - val_Offset_loss: 0.3630 - val_Volume_loss: 2.8779 - val_Duration_loss: 12.2218\n",
            "Epoch 176/400\n",
            "6/7 [========================>.....] - ETA: 0s - loss: 0.2460 - Note_loss: 0.0917 - Offset_loss: 0.0409 - Volume_loss: 0.0797 - Duration_loss: 0.0338\n",
            "Epoch 176: val_loss did not improve from 5.95548\n",
            "7/7 [==============================] - 0s 32ms/step - loss: 0.2433 - Note_loss: 0.0915 - Offset_loss: 0.0399 - Volume_loss: 0.0797 - Duration_loss: 0.0321 - val_loss: 41.1869 - val_Note_loss: 24.9508 - val_Offset_loss: 0.3577 - val_Volume_loss: 2.8279 - val_Duration_loss: 13.0505\n",
            "Epoch 177/400\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.1901 - Note_loss: 0.0733 - Offset_loss: 0.0221 - Volume_loss: 0.0799 - Duration_loss: 0.0149\n",
            "Epoch 177: val_loss did not improve from 5.95548\n",
            "7/7 [==============================] - 0s 30ms/step - loss: 0.1901 - Note_loss: 0.0733 - Offset_loss: 0.0221 - Volume_loss: 0.0799 - Duration_loss: 0.0149 - val_loss: 40.4053 - val_Note_loss: 24.3175 - val_Offset_loss: 0.3544 - val_Volume_loss: 2.7340 - val_Duration_loss: 12.9994\n",
            "Epoch 178/400\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.2433 - Note_loss: 0.0945 - Offset_loss: 0.0243 - Volume_loss: 0.0938 - Duration_loss: 0.0307\n",
            "Epoch 178: val_loss did not improve from 5.95548\n",
            "7/7 [==============================] - 0s 38ms/step - loss: 0.2433 - Note_loss: 0.0945 - Offset_loss: 0.0243 - Volume_loss: 0.0938 - Duration_loss: 0.0307 - val_loss: 39.0241 - val_Note_loss: 23.7880 - val_Offset_loss: 0.3453 - val_Volume_loss: 2.8039 - val_Duration_loss: 12.0870\n",
            "Epoch 179/400\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.3050 - Note_loss: 0.0941 - Offset_loss: 0.0373 - Volume_loss: 0.1415 - Duration_loss: 0.0321\n",
            "Epoch 179: val_loss did not improve from 5.95548\n",
            "7/7 [==============================] - 0s 33ms/step - loss: 0.3050 - Note_loss: 0.0941 - Offset_loss: 0.0373 - Volume_loss: 0.1415 - Duration_loss: 0.0321 - val_loss: 39.2881 - val_Note_loss: 24.2927 - val_Offset_loss: 0.3579 - val_Volume_loss: 2.7023 - val_Duration_loss: 11.9352\n",
            "Epoch 180/400\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.2911 - Note_loss: 0.1683 - Offset_loss: 0.0296 - Volume_loss: 0.0777 - Duration_loss: 0.0156\n",
            "Epoch 180: val_loss did not improve from 5.95548\n",
            "7/7 [==============================] - 0s 30ms/step - loss: 0.2911 - Note_loss: 0.1683 - Offset_loss: 0.0296 - Volume_loss: 0.0777 - Duration_loss: 0.0156 - val_loss: 40.7467 - val_Note_loss: 25.0240 - val_Offset_loss: 0.3607 - val_Volume_loss: 2.7019 - val_Duration_loss: 12.6600\n",
            "Epoch 181/400\n",
            "6/7 [========================>.....] - ETA: 0s - loss: 0.2794 - Note_loss: 0.1133 - Offset_loss: 0.0231 - Volume_loss: 0.1065 - Duration_loss: 0.0364\n",
            "Epoch 181: val_loss did not improve from 5.95548\n",
            "7/7 [==============================] - 0s 32ms/step - loss: 0.2729 - Note_loss: 0.1082 - Offset_loss: 0.0230 - Volume_loss: 0.1031 - Duration_loss: 0.0386 - val_loss: 41.5201 - val_Note_loss: 25.0689 - val_Offset_loss: 0.3572 - val_Volume_loss: 2.8603 - val_Duration_loss: 13.2337\n",
            "Epoch 182/400\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.2908 - Note_loss: 0.1209 - Offset_loss: 0.0308 - Volume_loss: 0.0919 - Duration_loss: 0.0471\n",
            "Epoch 182: val_loss did not improve from 5.95548\n",
            "7/7 [==============================] - 0s 31ms/step - loss: 0.2908 - Note_loss: 0.1209 - Offset_loss: 0.0308 - Volume_loss: 0.0919 - Duration_loss: 0.0471 - val_loss: 37.8761 - val_Note_loss: 22.6142 - val_Offset_loss: 0.3366 - val_Volume_loss: 2.6430 - val_Duration_loss: 12.2822\n",
            "Epoch 183/400\n",
            "6/7 [========================>.....] - ETA: 0s - loss: 0.2564 - Note_loss: 0.1472 - Offset_loss: 0.0284 - Volume_loss: 0.0555 - Duration_loss: 0.0254\n",
            "Epoch 183: val_loss did not improve from 5.95548\n",
            "7/7 [==============================] - 0s 32ms/step - loss: 0.2596 - Note_loss: 0.1442 - Offset_loss: 0.0277 - Volume_loss: 0.0552 - Duration_loss: 0.0325 - val_loss: 36.4230 - val_Note_loss: 21.7154 - val_Offset_loss: 0.3717 - val_Volume_loss: 2.3141 - val_Duration_loss: 12.0218\n",
            "Epoch 184/400\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.2210 - Note_loss: 0.0832 - Offset_loss: 0.0360 - Volume_loss: 0.0656 - Duration_loss: 0.0362\n",
            "Epoch 184: val_loss did not improve from 5.95548\n",
            "7/7 [==============================] - 0s 31ms/step - loss: 0.2210 - Note_loss: 0.0832 - Offset_loss: 0.0360 - Volume_loss: 0.0656 - Duration_loss: 0.0362 - val_loss: 37.9954 - val_Note_loss: 22.3373 - val_Offset_loss: 0.3843 - val_Volume_loss: 2.3855 - val_Duration_loss: 12.8883\n",
            "Epoch 185/400\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.2035 - Note_loss: 0.0587 - Offset_loss: 0.0386 - Volume_loss: 0.0698 - Duration_loss: 0.0364\n",
            "Epoch 185: val_loss did not improve from 5.95548\n",
            "7/7 [==============================] - 0s 32ms/step - loss: 0.2035 - Note_loss: 0.0587 - Offset_loss: 0.0386 - Volume_loss: 0.0698 - Duration_loss: 0.0364 - val_loss: 38.2222 - val_Note_loss: 22.5378 - val_Offset_loss: 0.3606 - val_Volume_loss: 2.2739 - val_Duration_loss: 13.0500\n",
            "Epoch 186/400\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.2599 - Note_loss: 0.1001 - Offset_loss: 0.0250 - Volume_loss: 0.0970 - Duration_loss: 0.0379\n",
            "Epoch 186: val_loss did not improve from 5.95548\n",
            "7/7 [==============================] - 0s 31ms/step - loss: 0.2599 - Note_loss: 0.1001 - Offset_loss: 0.0250 - Volume_loss: 0.0970 - Duration_loss: 0.0379 - val_loss: 36.4814 - val_Note_loss: 22.0377 - val_Offset_loss: 0.3484 - val_Volume_loss: 2.2593 - val_Duration_loss: 11.8360\n",
            "Epoch 187/400\n",
            "6/7 [========================>.....] - ETA: 0s - loss: 0.2756 - Note_loss: 0.1224 - Offset_loss: 0.0318 - Volume_loss: 0.0697 - Duration_loss: 0.0516\n",
            "Epoch 187: val_loss did not improve from 5.95548\n",
            "7/7 [==============================] - 0s 34ms/step - loss: 0.2756 - Note_loss: 0.1213 - Offset_loss: 0.0340 - Volume_loss: 0.0690 - Duration_loss: 0.0512 - val_loss: 36.3473 - val_Note_loss: 22.0273 - val_Offset_loss: 0.3432 - val_Volume_loss: 2.3674 - val_Duration_loss: 11.6093\n",
            "Epoch 188/400\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.2953 - Note_loss: 0.1551 - Offset_loss: 0.0312 - Volume_loss: 0.0686 - Duration_loss: 0.0405\n",
            "Epoch 188: val_loss did not improve from 5.95548\n",
            "7/7 [==============================] - 0s 30ms/step - loss: 0.2953 - Note_loss: 0.1551 - Offset_loss: 0.0312 - Volume_loss: 0.0686 - Duration_loss: 0.0405 - val_loss: 38.3637 - val_Note_loss: 23.0886 - val_Offset_loss: 0.3584 - val_Volume_loss: 2.7796 - val_Duration_loss: 12.1371\n",
            "Epoch 189/400\n",
            "6/7 [========================>.....] - ETA: 0s - loss: 0.2292 - Note_loss: 0.0853 - Offset_loss: 0.0257 - Volume_loss: 0.0807 - Duration_loss: 0.0375\n",
            "Epoch 189: val_loss did not improve from 5.95548\n",
            "7/7 [==============================] - 0s 43ms/step - loss: 0.2240 - Note_loss: 0.0853 - Offset_loss: 0.0247 - Volume_loss: 0.0784 - Duration_loss: 0.0356 - val_loss: 40.3424 - val_Note_loss: 24.6146 - val_Offset_loss: 0.3668 - val_Volume_loss: 3.1549 - val_Duration_loss: 12.2061\n",
            "Epoch 190/400\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.3072 - Note_loss: 0.1272 - Offset_loss: 0.0223 - Volume_loss: 0.1346 - Duration_loss: 0.0231\n",
            "Epoch 190: val_loss did not improve from 5.95548\n",
            "7/7 [==============================] - 0s 44ms/step - loss: 0.3072 - Note_loss: 0.1272 - Offset_loss: 0.0223 - Volume_loss: 0.1346 - Duration_loss: 0.0231 - val_loss: 41.2410 - val_Note_loss: 25.5808 - val_Offset_loss: 0.3525 - val_Volume_loss: 2.9535 - val_Duration_loss: 12.3542\n",
            "Epoch 191/400\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.3236 - Note_loss: 0.1258 - Offset_loss: 0.0325 - Volume_loss: 0.1504 - Duration_loss: 0.0148\n",
            "Epoch 191: val_loss did not improve from 5.95548\n",
            "7/7 [==============================] - 0s 42ms/step - loss: 0.3236 - Note_loss: 0.1258 - Offset_loss: 0.0325 - Volume_loss: 0.1504 - Duration_loss: 0.0148 - val_loss: 41.8810 - val_Note_loss: 26.1284 - val_Offset_loss: 0.3868 - val_Volume_loss: 2.8922 - val_Duration_loss: 12.4736\n",
            "Epoch 192/400\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.4398 - Note_loss: 0.2014 - Offset_loss: 0.0438 - Volume_loss: 0.1307 - Duration_loss: 0.0639\n",
            "Epoch 192: val_loss did not improve from 5.95548\n",
            "7/7 [==============================] - 0s 43ms/step - loss: 0.4398 - Note_loss: 0.2014 - Offset_loss: 0.0438 - Volume_loss: 0.1307 - Duration_loss: 0.0639 - val_loss: 40.1421 - val_Note_loss: 25.1316 - val_Offset_loss: 0.4063 - val_Volume_loss: 2.5629 - val_Duration_loss: 12.0413\n",
            "Epoch 193/400\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.2722 - Note_loss: 0.0792 - Offset_loss: 0.0419 - Volume_loss: 0.1359 - Duration_loss: 0.0153\n",
            "Epoch 193: val_loss did not improve from 5.95548\n",
            "7/7 [==============================] - 0s 50ms/step - loss: 0.2722 - Note_loss: 0.0792 - Offset_loss: 0.0419 - Volume_loss: 0.1359 - Duration_loss: 0.0153 - val_loss: 39.8276 - val_Note_loss: 24.7599 - val_Offset_loss: 0.3954 - val_Volume_loss: 2.5603 - val_Duration_loss: 12.1120\n",
            "Epoch 194/400\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.2827 - Note_loss: 0.1202 - Offset_loss: 0.0333 - Volume_loss: 0.1008 - Duration_loss: 0.0284\n",
            "Epoch 194: val_loss did not improve from 5.95548\n",
            "7/7 [==============================] - 0s 43ms/step - loss: 0.2827 - Note_loss: 0.1202 - Offset_loss: 0.0333 - Volume_loss: 0.1008 - Duration_loss: 0.0284 - val_loss: 39.4793 - val_Note_loss: 24.3027 - val_Offset_loss: 0.3553 - val_Volume_loss: 2.5481 - val_Duration_loss: 12.2732\n",
            "Epoch 195/400\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.2549 - Note_loss: 0.1094 - Offset_loss: 0.0343 - Volume_loss: 0.0915 - Duration_loss: 0.0197\n",
            "Epoch 195: val_loss did not improve from 5.95548\n",
            "7/7 [==============================] - 0s 42ms/step - loss: 0.2549 - Note_loss: 0.1094 - Offset_loss: 0.0343 - Volume_loss: 0.0915 - Duration_loss: 0.0197 - val_loss: 39.5654 - val_Note_loss: 24.1123 - val_Offset_loss: 0.3499 - val_Volume_loss: 2.3973 - val_Duration_loss: 12.7059\n",
            "Epoch 196/400\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.3713 - Note_loss: 0.1187 - Offset_loss: 0.0425 - Volume_loss: 0.1358 - Duration_loss: 0.0743\n",
            "Epoch 196: val_loss did not improve from 5.95548\n",
            "7/7 [==============================] - 0s 48ms/step - loss: 0.3713 - Note_loss: 0.1187 - Offset_loss: 0.0425 - Volume_loss: 0.1358 - Duration_loss: 0.0743 - val_loss: 40.9995 - val_Note_loss: 25.1419 - val_Offset_loss: 0.3568 - val_Volume_loss: 2.4253 - val_Duration_loss: 13.0754\n",
            "Epoch 197/400\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.2843 - Note_loss: 0.1278 - Offset_loss: 0.0235 - Volume_loss: 0.1217 - Duration_loss: 0.0113\n",
            "Epoch 197: val_loss did not improve from 5.95548\n",
            "7/7 [==============================] - 1s 94ms/step - loss: 0.2843 - Note_loss: 0.1278 - Offset_loss: 0.0235 - Volume_loss: 0.1217 - Duration_loss: 0.0113 - val_loss: 41.8293 - val_Note_loss: 25.6778 - val_Offset_loss: 0.3466 - val_Volume_loss: 2.3756 - val_Duration_loss: 13.4293\n",
            "Epoch 198/400\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.3356 - Note_loss: 0.1366 - Offset_loss: 0.0347 - Volume_loss: 0.0748 - Duration_loss: 0.0895\n",
            "Epoch 198: val_loss did not improve from 5.95548\n",
            "7/7 [==============================] - 0s 42ms/step - loss: 0.3356 - Note_loss: 0.1366 - Offset_loss: 0.0347 - Volume_loss: 0.0748 - Duration_loss: 0.0895 - val_loss: 39.6446 - val_Note_loss: 24.3887 - val_Offset_loss: 0.3519 - val_Volume_loss: 2.3739 - val_Duration_loss: 12.5301\n",
            "Epoch 199/400\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.3871 - Note_loss: 0.1297 - Offset_loss: 0.0515 - Volume_loss: 0.1039 - Duration_loss: 0.1020\n",
            "Epoch 199: val_loss did not improve from 5.95548\n",
            "7/7 [==============================] - 0s 30ms/step - loss: 0.3871 - Note_loss: 0.1297 - Offset_loss: 0.0515 - Volume_loss: 0.1039 - Duration_loss: 0.1020 - val_loss: 38.3135 - val_Note_loss: 23.2601 - val_Offset_loss: 0.3377 - val_Volume_loss: 2.0955 - val_Duration_loss: 12.6203\n",
            "Epoch 200/400\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.2990 - Note_loss: 0.1133 - Offset_loss: 0.0275 - Volume_loss: 0.0991 - Duration_loss: 0.0590\n",
            "Epoch 200: val_loss did not improve from 5.95548\n",
            "7/7 [==============================] - 0s 30ms/step - loss: 0.2990 - Note_loss: 0.1133 - Offset_loss: 0.0275 - Volume_loss: 0.0991 - Duration_loss: 0.0590 - val_loss: 39.2824 - val_Note_loss: 23.4565 - val_Offset_loss: 0.3295 - val_Volume_loss: 2.2375 - val_Duration_loss: 13.2589\n",
            "Epoch 201/400\n",
            "1/7 [===>..........................] - ETA: 0s - loss: 0.3038 - Note_loss: 0.1283 - Offset_loss: 0.0074 - Volume_loss: 0.0807 - Duration_loss: 0.0874"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-27-5030a7876aa0>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0minput_note_reshaped\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_step_reshaped\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_volume_reshaped\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_duration_reshaped\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0moutput_note_reshaped\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_step_reshaped\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_volume_reshaped\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_duration_reshaped\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m400\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcp_callback\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1781\u001b[0m                         ):\n\u001b[1;32m   1782\u001b[0m                             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1783\u001b[0;31m                             \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1784\u001b[0m                             \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1785\u001b[0m                                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    829\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 831\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    832\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    833\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    865\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    866\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 867\u001b[0;31m       return tracing_compilation.call_function(\n\u001b[0m\u001b[1;32m    868\u001b[0m           \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_no_variable_creation_config\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    869\u001b[0m       )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m   \u001b[0mbound_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m   \u001b[0mflat_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munpack_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbound_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m   return function._call_flat(  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m    140\u001b[0m       \u001b[0mflat_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m   )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1262\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1263\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1264\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inference_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflat_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1265\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1266\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36mflat_call\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    215\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mflat_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mSequence\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m     \u001b[0;34m\"\"\"Calls with tensor inputs and returns the structured output.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m     \u001b[0mflat_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    218\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpack_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflat_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    250\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mrecord\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_recording\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    251\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_bound_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 252\u001b[0;31m             outputs = self._bound_context.call_function(\n\u001b[0m\u001b[1;32m    253\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m                 \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/context.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1477\u001b[0m     \u001b[0mcancellation_context\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcancellation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1478\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcancellation_context\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1479\u001b[0;31m       outputs = execute.execute(\n\u001b[0m\u001b[1;32m   1480\u001b[0m           \u001b[0mname\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1481\u001b[0m           \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     ]\n\u001b[0;32m---> 60\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     61\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     62\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#prend une séquence de notes, volume, durées\n",
        "pattern_note = input_note[0]\n",
        "pattern_offset = input_offset[0]\n",
        "pattern_volume = input_volume[0]\n",
        "pattern_duration = input_duration[0]\n",
        "pattern_step = input_step[0]"
      ],
      "metadata": {
        "id": "S7L6Fyy1pFBa"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pattern_step"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eGzZVJsX2-0J",
        "outputId": "d09f74d3-c8b9-4791-a7bb-5a26cb9cc2c1"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0., 0., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 0., 2.,\n",
              "       2., 2., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1.,\n",
              "       1., 0., 2., 2., 2., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0.])"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# prediction time\n",
        "prediction_output = []\n",
        "\n",
        "for i in tqdm(range(200)):\n",
        "\n",
        "    #on reshape les input à prédire\n",
        "    note_prediction_input = numpy.reshape(pattern_note, (1, len(pattern_note), -1))\n",
        "    volume_prediction_input = numpy.reshape(pattern_volume, (1, len(pattern_volume), -1))\n",
        "    duration_prediction_input = numpy.reshape(pattern_duration, (1, len(pattern_duration), -1))\n",
        "    offset_prediction_input = numpy.reshape(pattern_offset, (1, len(pattern_offset), 1))\n",
        "    step_prediction_input = numpy.reshape(pattern_step, (1, len(pattern_step), 1))\n",
        "\n",
        "    #prédit ici\n",
        "    prediction = model.predict([note_prediction_input, offset_prediction_input, volume_prediction_input, duration_prediction_input], verbose=0)\n",
        "\n",
        "    # prédis la note en récupérant l'index max du softmax et en faisant la transofr inverse\n",
        "    # à partir du one hot train sur les notes\n",
        "\n",
        "    temperature = 1.0\n",
        "\n",
        "    note_softmax = prediction[0]\n",
        "    adjusted_softmax = note_softmax / temperature\n",
        "    adjusted_softmax = adjusted_softmax / np.sum(adjusted_softmax)\n",
        "    note_soft = tf.random.categorical(note_softmax, num_samples=1)[0][0]\n",
        "    notes_pred = np.zeros(len(pattern_note[0]))\n",
        "    #notes_pred[np.argmax(adjusted_softmax)] = 1\n",
        "    notes_pred[np.argmax(prediction[0])] = 1\n",
        "    #notes_pred[note_soft] = 1\n",
        "    result_note = oh_notes.inverse_transform(notes_pred.reshape(1, -1))\n",
        "    pattern_note = numpy.concatenate([pattern_note, [notes_pred]])\n",
        "    pattern_note = pattern_note[1:]\n",
        "\n",
        "    \"\"\"\n",
        "    offset_predict = prediction[1][0][0]\n",
        "    pattern_offset = numpy.concatenate([pattern_offset, prediction[1][0]])\n",
        "    pattern_offset = pattern_offset[1:]\n",
        "    \"\"\"\n",
        "    step_predict = prediction[1][0][0]\n",
        "    pattern_step = numpy.concatenate([pattern_step, prediction[1][0]])\n",
        "    pattern_step = pattern_step[1:]\n",
        "\n",
        "    # la même avec le volume\n",
        "    volume_pred = np.zeros(len(pattern_volume[1]))\n",
        "    volume_pred[np.argmax(prediction[2])] = 1\n",
        "    result_volume = oh_volume.inverse_transform(volume_pred.reshape(1, -1))\n",
        "    pattern_volume = numpy.concatenate([pattern_volume, [volume_pred]])\n",
        "    pattern_volume = pattern_volume[1:]\n",
        "\n",
        "    # la même avec la durée\n",
        "    duration_pred = np.zeros(len(pattern_duration[0]))\n",
        "    duration_pred[np.argmax(prediction[3])] = 1\n",
        "    result_duration = oh_duration.inverse_transform(duration_pred.reshape(1, -1))\n",
        "    pattern_duration = numpy.concatenate([pattern_duration, [duration_pred]])\n",
        "    pattern_duration = pattern_duration[1:]\n",
        "\n",
        "    # comme on prédit un mot associé au volume, on associe au mot une valeur/intensité\n",
        "    #(manque des catégories)\n",
        "    volume_encoded = result_volume[0][0]\n",
        "    volume_decoded = dict_volume_class[volume_encoded]\n",
        "\n",
        "    # la même avec la durée\n",
        "    #(manque des catégories)\n",
        "    duration_encoded = result_duration[0][0]\n",
        "    duration_decoded = dict_duration_class[duration_encoded]\n",
        "\n",
        "\n",
        "    #on ajoute la note, le volyme et la durée\n",
        "    prediction_output.append([result_note[0][0], step_predict, volume_decoded, duration_decoded])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1C2Vt-MH0nm_",
        "outputId": "b2b67154-0292-451b-e6be-9c7dacadd0c8"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 200/200 [00:23<00:00,  8.65it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prediction_output"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PD7StEvwxzXl",
        "outputId": "c57a1bfb-1590-4790-a963-1bbb089a006f"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['A3', 0.026755834, 90, 1.5],\n",
              " ['REST', 0.026755834, 90, 1.5],\n",
              " ['D5', 0.20250493, 90, 1.5],\n",
              " ['D5', 0.2569381, 90, 4.6875],\n",
              " ['F#4', 0.35265663, 90, 4.6875],\n",
              " ['A3', 0.30729347, 90, 4.6875],\n",
              " ['F#3', 0.16479316, 90, 4.6875],\n",
              " ['A3', 0.06224662, 90, 1.5],\n",
              " ['G2', 0.2072951, 10, 1.5],\n",
              " ['D5', 0.24373868, 90, 1.5],\n",
              " ['A4', 0.23869759, 90, 0.5],\n",
              " ['E4', 0.43851355, 90, 4.6875],\n",
              " ['A3', 0.24824369, 90, 4.6875],\n",
              " ['C#4', 0.22131045, 90, 4.6875],\n",
              " ['D2', 0.2351011, 90, 4.6875],\n",
              " ['REST', 0.032175288, 10, 4.6875],\n",
              " ['REST', 0.026755834, 10, 4.6875],\n",
              " ['G3', 1.8885927, 70, 4.6875],\n",
              " ['B3', 2.1477208, 90, 4.6875],\n",
              " ['E2', 0.026755834, 90, 1.5],\n",
              " ['REST', 0.026755834, 10, 1.5],\n",
              " ['F#2', 0.1914566, 90, 1.5],\n",
              " ['F#2', 0.04017391, 90, 1.5],\n",
              " ['F#2', 0.15471682, 90, 1.5],\n",
              " ['A4', 0.33771315, 90, 0.75],\n",
              " ['D5', 0.44606772, 90, 4.6875],\n",
              " ['A3', 0.40030065, 128, 4.6875],\n",
              " ['F#4', 0.38920566, 128, 4.6875],\n",
              " ['A2', 0.2517572, 90, 4.6875],\n",
              " ['A3', 0.29706195, 90, 1.5],\n",
              " ['G2', 0.55150837, 70, 1.5],\n",
              " ['A3', 0.49478057, 70, 4.6875],\n",
              " ['C#4', 0.60762024, 70, 4.6875],\n",
              " ['E4', 0.7770995, 70, 4.6875],\n",
              " ['D2', 0.4829228, 70, 4.6875],\n",
              " ['REST', 0.026755834, 10, 4.6875],\n",
              " ['G3', 2.069159, 70, 4.6875],\n",
              " ['B3', 2.1611493, 70, 4.6875],\n",
              " ['E2', 0.026755834, 90, 1.5],\n",
              " ['REST', 0.026755834, 10, 1.5],\n",
              " ['F#2', 0.2266612, 90, 1.5],\n",
              " ['F#2', 0.026755834, 90, 1.5],\n",
              " ['F#2', 0.09761942, 90, 1.5],\n",
              " ['A4', 0.28661135, 90, 4.6875],\n",
              " ['A3', 0.30742368, 90, 4.6875],\n",
              " ['A3', 0.19093435, 90, 4.6875],\n",
              " ['F#3', 0.17977585, 90, 4.6875],\n",
              " ['D2', 0.096318595, 90, 4.6875],\n",
              " ['REST', 0.08266191, 10, 4.6875],\n",
              " ['B3', 1.185252, 70, 4.6875],\n",
              " ['E2', 0.75212353, 90, 1.5],\n",
              " ['REST', 0.026755834, 10, 1.5],\n",
              " ['F#2', 0.22873122, 90, 1.5],\n",
              " ['F#2', 0.09577967, 90, 1.5],\n",
              " ['F#2', 0.18654609, 90, 1.5],\n",
              " ['A4', 0.34009916, 90, 0.75],\n",
              " ['A3', 0.28076264, 90, 4.6875],\n",
              " ['A3', 0.26080105, 90, 4.6875],\n",
              " ['F#3', 0.29000923, 90, 4.6875],\n",
              " ['D2', 0.26128283, 90, 4.6875],\n",
              " ['REST', 0.17763232, 10, 4.6875],\n",
              " ['REST', 0.55445284, 70, 4.6875],\n",
              " ['B3', 1.5091817, 70, 4.6875],\n",
              " ['E2', 0.026755834, 90, 1.5],\n",
              " ['REST', 0.026755834, 10, 1.5],\n",
              " ['F#2', 0.026755834, 90, 1.5],\n",
              " ['F#2', 0.026755834, 90, 1.5],\n",
              " ['F#2', 0.15641898, 90, 1.5],\n",
              " ['D5', 0.3631681, 90, 4.6875],\n",
              " ['D5', 0.38534725, 90, 4.6875],\n",
              " ['A3', 0.21005473, 90, 4.6875],\n",
              " ['A2', 0.15255462, 90, 4.6875],\n",
              " ['A2', 0.24889, 90, 1.5],\n",
              " ['G2', 0.4737555, 70, 1.5],\n",
              " ['A3', 0.4677526, 70, 1.5],\n",
              " ['A3', 0.2967688, 70, 4.6875],\n",
              " ['C#4', 0.4155392, 70, 4.6875],\n",
              " ['E4', 0.7313053, 70, 4.6875],\n",
              " ['D2', 0.51178735, 70, 4.6875],\n",
              " ['REST', 0.11293449, 10, 4.6875],\n",
              " ['E3', 1.6340562, 70, 4.6875],\n",
              " ['B3', 2.3262873, 70, 4.6875],\n",
              " ['E2', 0.8701071, 90, 1.5],\n",
              " ['REST', 0.026755834, 10, 1.5],\n",
              " ['F#2', 0.23105752, 90, 1.5],\n",
              " ['F#2', 0.026755834, 90, 1.5],\n",
              " ['F#2', 0.13398139, 90, 1.5],\n",
              " ['D5', 0.36572775, 90, 4.6875],\n",
              " ['D5', 0.4212081, 90, 4.6875],\n",
              " ['A3', 0.20249534, 90, 4.6875],\n",
              " ['A3', 0.08674983, 90, 4.6875],\n",
              " ['A2', 0.08155849, 90, 1.5],\n",
              " ['G2', 0.27938852, 90, 1.5],\n",
              " ['A3', 0.24403903, 70, 4.6875],\n",
              " ['A3', 0.24774149, 90, 4.6875],\n",
              " ['C#4', 0.5185432, 70, 4.6875],\n",
              " ['F#3', 0.48186532, 70, 4.6875],\n",
              " ['D2', 0.45498994, 70, 4.6875],\n",
              " ['REST', 0.061629094, 10, 4.6875],\n",
              " ['G3', 1.6661353, 70, 4.6875],\n",
              " ['B3', 2.0021484, 70, 4.6875],\n",
              " ['E2', 0.026755834, 90, 1.5],\n",
              " ['REST', 0.026755834, 10, 1.5],\n",
              " ['F#2', 0.2128219, 90, 1.5],\n",
              " ['F#2', 0.03525781, 90, 1.5],\n",
              " ['F#2', 0.11450737, 90, 1.5],\n",
              " ['A4', 0.30456498, 90, 4.6875],\n",
              " ['A3', 0.2803375, 90, 4.6875],\n",
              " ['A3', 0.2069692, 90, 4.6875],\n",
              " ['F#3', 0.21790722, 90, 4.6875],\n",
              " ['D2', 0.14835303, 90, 4.6875],\n",
              " ['REST', 0.098587535, 10, 4.6875],\n",
              " ['REST', 0.72003645, 10, 4.6875],\n",
              " ['B3', 1.8721445, 90, 4.6875],\n",
              " ['E2', 0.22304033, 90, 1.5],\n",
              " ['REST', 0.026755834, 10, 1.5],\n",
              " ['F#2', 0.09422449, 90, 1.5],\n",
              " ['F#2', 0.03613414, 90, 1.5],\n",
              " ['F#2', 0.15480052, 90, 1.5],\n",
              " ['A4', 0.32713583, 90, 0.75],\n",
              " ['D5', 0.42116898, 90, 4.6875],\n",
              " ['A3', 0.3994858, 128, 4.6875],\n",
              " ['A3', 0.3942781, 128, 4.6875],\n",
              " ['A2', 0.46628866, 90, 1.5],\n",
              " ['A2', 0.65407807, 70, 1.5],\n",
              " ['A3', 0.69322896, 70, 1.5],\n",
              " ['A3', 0.53674424, 70, 4.6875],\n",
              " ['C#4', 0.70880824, 70, 4.6875],\n",
              " ['E4', 0.8223152, 70, 4.6875],\n",
              " ['D2', 0.54738736, 70, 4.6875],\n",
              " ['REST', 0.026755834, 10, 4.6875],\n",
              " ['G3', 2.0341463, 70, 4.6875],\n",
              " ['B3', 2.223651, 70, 4.6875],\n",
              " ['E2', 0.026755834, 90, 1.5],\n",
              " ['REST', 0.026755834, 10, 1.5],\n",
              " ['F#2', 0.23273472, 90, 1.5],\n",
              " ['F#2', 0.026755834, 90, 1.5],\n",
              " ['F#2', 0.096634656, 90, 1.5],\n",
              " ['A4', 0.3006139, 90, 4.6875],\n",
              " ['A3', 0.32811442, 90, 4.6875],\n",
              " ['A3', 0.19958547, 90, 4.6875],\n",
              " ['F#3', 0.19308561, 90, 4.6875],\n",
              " ['D2', 0.09924058, 90, 4.6875],\n",
              " ['REST', 0.08105975, 10, 4.6875],\n",
              " ['B3', 1.1602287, 70, 4.6875],\n",
              " ['E2', 0.5739265, 90, 1.5],\n",
              " ['REST', 0.026755834, 10, 1.5],\n",
              " ['F#2', 0.22759795, 90, 1.5],\n",
              " ['F#2', 0.09651514, 90, 1.5],\n",
              " ['F#2', 0.1854854, 90, 1.5],\n",
              " ['A4', 0.34122744, 90, 0.75],\n",
              " ['A3', 0.2736009, 90, 4.6875],\n",
              " ['A3', 0.25230035, 90, 4.6875],\n",
              " ['F#3', 0.2857002, 90, 4.6875],\n",
              " ['D2', 0.2556782, 90, 4.6875],\n",
              " ['REST', 0.17554973, 10, 4.6875],\n",
              " ['REST', 0.46312433, 10, 4.6875],\n",
              " ['B3', 1.6911309, 70, 4.6875],\n",
              " ['E2', 0.068783075, 90, 1.5],\n",
              " ['E2', 0.026755834, 10, 1.5],\n",
              " ['F#2', 0.18189873, 90, 1.5],\n",
              " ['F#2', 0.04675167, 90, 1.5],\n",
              " ['F#2', 0.12966424, 90, 1.5],\n",
              " ['A4', 0.32940844, 90, 0.75],\n",
              " ['D5', 0.44032142, 90, 4.6875],\n",
              " ['A3', 0.32049164, 128, 4.6875],\n",
              " ['A3', 0.31615666, 90, 4.6875],\n",
              " ['A2', 0.3288354, 90, 1.5],\n",
              " ['G2', 0.5724836, 70, 1.5],\n",
              " ['A3', 0.573119, 70, 4.6875],\n",
              " ['C#4', 0.6518127, 70, 4.6875],\n",
              " ['E4', 0.7816376, 70, 4.6875],\n",
              " ['D2', 0.5388753, 70, 4.6875],\n",
              " ['REST', 0.026755834, 10, 4.6875],\n",
              " ['G3', 2.0602138, 70, 4.6875],\n",
              " ['B3', 2.1529605, 70, 4.6875],\n",
              " ['E2', 0.026755834, 90, 1.5],\n",
              " ['REST', 0.026755834, 10, 1.5],\n",
              " ['F#2', 0.20303395, 90, 1.5],\n",
              " ['F#2', 0.026755834, 90, 1.5],\n",
              " ['F#2', 0.10008117, 90, 1.5],\n",
              " ['A4', 0.30104735, 90, 4.6875],\n",
              " ['A3', 0.31383398, 90, 4.6875],\n",
              " ['A3', 0.2033428, 90, 4.6875],\n",
              " ['F#3', 0.19871262, 90, 4.6875],\n",
              " ['D2', 0.098713696, 90, 4.6875],\n",
              " ['REST', 0.082937345, 10, 4.6875],\n",
              " ['B3', 1.1407609, 70, 4.6875],\n",
              " ['E2', 0.59122837, 90, 1.5],\n",
              " ['REST', 0.026755834, 10, 1.5],\n",
              " ['F#2', 0.2045774, 90, 1.5],\n",
              " ['F#2', 0.051734604, 90, 1.5],\n",
              " ['F#2', 0.18865675, 90, 1.5],\n",
              " ['A4', 0.35110605, 90, 0.75],\n",
              " ['A3', 0.28824857, 90, 4.6875],\n",
              " ['A3', 0.28406218, 90, 4.6875],\n",
              " ['F#3', 0.3033133, 90, 4.6875],\n",
              " ['D2', 0.26886168, 90, 4.6875],\n",
              " ['REST', 0.17770788, 10, 4.6875],\n",
              " ['REST', 0.5127692, 70, 4.6875]]"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from music21.duration import Duration\n"
      ],
      "metadata": {
        "id": "91w43lwl5urg"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "offset = 0\n",
        "output_notes = []\n",
        "# on passes des prédicitons à un format écoutable à l'oreille\n",
        "\n",
        "prev_start = 0\n",
        "# pour chaque note prédite\n",
        "for note_p in prediction_output:\n",
        "    pattern = note_p[0]\n",
        "    # si note = chord\n",
        "    if ('+' in pattern) or pattern.isdigit():\n",
        "        notes_in_chord = pattern.split('+')\n",
        "        notes = []\n",
        "        for current_note in notes_in_chord:\n",
        "            new_note = note.Note(int(current_note))\n",
        "            new_note.storedInstrument = instrument.Piano()\n",
        "            notes.append(new_note)\n",
        "        new_chord = chord.Chord(notes)\n",
        "        new_chord.offset = prev_start + note_p[1]\n",
        "        # met le volume associé\n",
        "        new_chord.volume.velocity = note_p[2]\n",
        "        # met la durée associée\n",
        "        new_chord.duration = Duration(note_p[3])\n",
        "        output_notes.append(new_chord)\n",
        "    # si note est un rest\n",
        "    elif('REST'in pattern):\n",
        "      note_rest = note.Rest()\n",
        "      note_rest.offset = prev_start + note_p[1]\n",
        "      # durée associée (pas de volume car silencieux)\n",
        "      note_rest.duration = Duration(note_p[3])\n",
        "      output_notes.append(note_rest)\n",
        "    else:\n",
        "        new_note = note.Note(pattern)\n",
        "        new_note.offset = prev_start + note_p[1]\n",
        "        new_note.volume.velocity = note_p[2]\n",
        "        new_note.duration = Duration(note_p[3])\n",
        "        new_note.storedInstrument = instrument.Piano()\n",
        "        output_notes.append(new_note)\n",
        "    prev_start = prev_start + note_p[1]\n",
        "    # increase offset each iteration so that notes do not stack\n",
        "    #offset += 0.5"
      ],
      "metadata": {
        "id": "BxktumUV0H22"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#into midi\n",
        "midi_stream = stream.Stream(output_notes)\n",
        "midi_stream.write('midi', fp='test_outputminecraft6.mid')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "I5W_QMyyn7BA",
        "outputId": "9efcffc9-72dd-4a0b-df93-e9d6600f7889"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'test_outputminecraft6.mid'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    }
  ]
}